[{"id": "counting", "title": "Counting", "url": "part1/counting", "text": "\n \nCounting\n\nAlthough you may have thought you had a pretty good grasp on the notion of counting at the age of\nthree, it turns out that you had to wait until now to learn how to really count. Aren\u2019t you glad you\ntook this class now?! But seriously, counting is like\nthe foundation of a house (where the house is all the great things we will do later in this book, such\nas machine learning). Houses are awesome. Foundations, on the other hand, are pretty much just\nconcrete in a hole. But don\u2019t make a house without a foundation. It won\u2019t turn out well.\nCounting with Steps\n\n\nDefinition: Step Rule of Counting (aka Product Rule of Counting)\nIf an experiment has two parts, where the first part can result in one of $m$ outcomes and the second part\ncan result in one of $n$ outcomes regardless of the outcome of the first part, then the total number of\noutcomes for the experiment is $m \\cdot n$.\n\n\nRewritten using set notation, the Step Rule of Counting states that if an experiment with two parts has an outcome\nfrom set $A$ in the first part, where $|A| = m$, and an outcome from set $B$ in the second part (where the number of outcomes in $B$ is the same regardless of the\noutcome of the first part), where $|B| = n$, then the total number of outcomes of the experiment is $|A||B| = m \\cdot n $.\n\n\nSimple Example: \n\t\tConsider a hash table with 100 buckets. Two arbitrary strings are independently hashed and added to the\ntable. How many possible ways are there for the strings to be stored in the table?\nEach string can be hashed to one of 100 buckets. Since the results of hashing the first string do not impact the\nhash of the second, there are 100 * 100 = 10,000 ways that the two strings may be stored in the hash table.\n\n\n\nPeter Norvig, the author of the cannonical text book \"Artificial Intelligence\" made the following compelling point on why computer scientists need to know how to count. To start, lets set a baseline for a really big number: The number of atoms in the observable universe, often estimated to be around 10 to the 80th power ($10^{80}$). There\ncertainly are a lot of atoms in the universe. As a leading expert said,\n\n\t\u201cSpace is big. Really big. You just won\u2019t believe how vastly, hugely, mind-bogglingly big it is.\nI mean, you may think it\u2019s a long way down the road to the chemist, but that\u2019s just peanuts to\nspace.\u201d - Douglas Adams\nThis number is often used to demonstrate tasks that computers will never be able to solve. Problems can\nquickly grow to an absurd size, and we can understand why using the Step Rule of Counting.\nThere is an art project to display every possible picture.\nSurely that would take a long time, because there must be many possible pictures. But how many? We will\nassume the color model known as True Color, in which each pixel can be one of $2^{24}$ \u2248 17 million distinct\ncolors.\nHow many distinct pictures can you generate from (a) a smart phone camera shown with 12 million pixels, (b) a\ngrid with 300 pixels, and (c) a grid with just 12 pixels?\n\n\n\n\n\n\n\tAnswer: We can use the steps rule of counting. An image can be created one pixel at a time, step by step. Each time we chose a pixel you can select its color out of 17 million choices. An array of $n$ pixels produces (17 million)$^n$ different pictures. (17 million)$^{12}$ \u2248 $10^{86}$, so the tiny\n12-pixel grid produces a million times more pictures than the number of atoms in the universe! How about\nthe 300 pixel array? It can produce $10^{2167}$ pictures. You may think the number of atoms in the universe is big,\nbut that\u2019s just peanuts to the number of pictures in a 300-pixel array. And 12M pixels? $10^{86696638}$ pictures.\n\t\n\n\nExample: Unique states of Go\nFor example a Go board has 19 \u00d7 19 points where a user can place a stone. Each of the points can be empty or occupied\nby black or white stone. By the Step Rule of Counting, we can compute the number of unique board\nconfigurations.\nIn go there are 19x19 points. Each point can have a black stone, white stone, or no stone at all.\n Here we are going to construct the board one point at a time, step by step. Each time we add a point we have a unique choice where we can decide to make the point one of three options:\n {Black, White, No Stone}. Using this construction we can apply the Step Rule of Counting. If there was only one point, there would be three unique board configurations. If there were four points you would have $3 \\cdot 3 \\cdot 3 \\cdot 3 = 81$ unique combinations. In Go there are $3^{(19\u00d719)} \u2248 10^{172}$ possible board positions. The way we constructed our board didn't take into account which ones were illegal by the rules of Go. It turns out that \"only\" about\n$10^{170}$ of those positions are legal. That is about the square of the number of atoms in the universe. In otherwords: if there was another universe of atoms for every single atom, only then would there be as many atoms\nin the universe as there are unique configurations of a Go board. \n\n\tAs a computer scientist this sort of result can be very important. While computers are powerful, an algorithm which needed to store each configuration of the board would not be a reasonable approach. No computer can store more information than atoms in the universe squared!\n\t\n\n\nThe above argument might leave you feeling like some problems are incredibly hard as a result of the product\nrule of counting. Let\u2019s take a moment to talk about how the product rule of counting can help! Most logrithmic\ntime algorithms leverage this principle. \n\n\tImagine you are building a machine learning system that needs to learn from data and you want to synthetically generate 10 million unique data points for it. How many steps would you need to encode to get to 10 million? Assuming that at each step you have a binary choice, the number of unique data points you produce will be $2^n$ by the Steps Rule of counting. If we chose $n$ such that $\\log_{2} 10,000,000 < n$. You would only need to encode $n=24$ binary decisions.\n\t\n\n\nExample: Rolling two dice. Two 6-sided dice , with faces numbered 1 through 6, are rolled. How many possible\noutcomes of the roll are there?\n\nSolution: \n\t\tNote that we are not concerned with the total value of the two die (\"die\" is the singular form of \"dice\"), but rather the set of\nall explicit outcomes of the rolls. Since the first die can come up with 6 possible values and the\nsecond die similarly can have 6 possible values (regardless of what appeared on the first die), the\ntotal number of potential outcomes is 36 (= 6 \u00d7 6). These possible outcomes are explicitly listed\nbelow as a series of pairs, denoting the values rolled on the pair of dice:\n\n\n\n\n\n\n\nCounting with or\n\n\tIf you want to consider the total number of unique outcomes, when outcomes can come from source $A$ or source $B$, then the equation you use depends on whether or not there are outcomes which are both in $A$ and $B$. If not, you can use the simpler \"Mutually Exclusive Counting\" rule. Otherwise you need to use the slightly more involved Inclusiong Exclusion rule.\n\n\n\nDefinition: Mutually Exclusive Counting\nIf the outcome of an experiment can either be drawn from set $A$ or set $B$, and sets $A$ and $B$, where none of\nthe outcomes in set $A$ is the same as the any of the outcomes in set $B$ (called mutual exclusion),\nthen there are $|A \\or B| = |A|+|B|$ possible outcomes of the experiment.\n\n\n\n\nExample: Sum of Routes. A route finding algorithm needs to find routes from Nairobi to Dar Es Salaam. It finds routes that either pass through Mt Kilimanjaro or Mombasa. There are 20 routes that pass through Mt Kilimanjaro, 15 routes that pass through Mombasa and 0 routes which pass through both Mt Kilimanjaro and Mombasa. How many routes are there total?\n\nSolution: \n\t\tRoutes can come from either Mt Kilimanjaro or Mombasa. The two sets of routes are mutually exclusive as there are zero routes which are in both groups. As such the total number of routes is addition: 20 + 15 = 35.\n\t\n\n\n\tIf you can show that two groups are mutually exclusive counting becomes simple addition. Of course not all sets are mutually exclusive. In the example above, imagine there had been a single route which went through both Mt Kilimanjaro and Mombasa. We would have double counted that routes because it would be included in both the sets. If sets are not mutually exclusive, counting the or is still addition, we simply need to take into account any double counting.\n\t\n\n\nDefinition: Inclusion  Exclusion Counting\nIf the outcome of an experiment can either be drawn from set $A$ or set $B$, and sets $A$ and $B$ may potentially\noverlap (i.e., it is not the case that $A$ and $B$ are mutually exclusive), then the number of outcomes of the experiment is\n$|A \\or B| = |A|+|B| \u2212|A \\and B|$.\n\n\nNote that the Inclusion-Exclusion Principle generalizes the Sum Rule of Counting for arbitrary sets $A$ and\n$B$. In the case where $A \\and B = \u2205$, the Inclusion-Exclusion Principle gives the same result as the Sum Rule of\nCounting since $|A \\and B| = 0$.\n\n\nExample: An 8-bit string (one byte) is sent over a network. The valid set of strings recognized by\nthe receiver must either start with \"01\" or end with \"10\". How many such strings are there?\n\nSolution: \n\t\tThe potential bit strings that match the receiver\u2019s criteria can either be the 64 strings that\nstart with \"01\" (since that last 6 bits are left unspecified, allowing for $2^6 = 64$ possibilities) or the 64\nstrings that end with \"10\" (since the first 6 bits are unspecified). Of course, these two sets overlap,\nsince strings that start with \"01\" and end with \"10\" are in both sets. There are $2^4$ = 16 such strings\n(since the middle 4 bits can be arbitrary). Casting this description into corresponding set notation,\nwe have: $|A|$ = 64, $|B|$ = 64, and $|A \\and B|$ = 16, so by the Inclusion-Exclusion Principle, there are\n64 + 64 \u2212 16 = 112 strings that match the specified receiver\u2019s criteria.\n\t\n\n\n"}, {"id": "combinatorics", "title": "Combinatorics", "url": "part1/combinatorics", "text": "\n \nCombinatorics\n\nCounting problems can be approached from the basic building blocks described in the first section: Counting. However some counting problems are so ubiquitous in the world of probability that it is worth knowing a few\nhigher level counting abstractions. When solving problems, if you can find the analogy from these canonical\nexamples you can build off of the corresponding combinatorics formulas:\n\nPermutations of Distinct Objects\nPermutations with Indistinct Objects\nCombinations with Distinct Objects\nBucketing into Containers\nBucketing into Fixed Sized Containers\n\nWhile these are by no means the only common counting paradigms, it is a helpful set.\n\nPermutations of Distinct Objects\n\n\nDefinition: Permutation Rule\nA permutation is an ordered arrangement of n distinct object. Those $n$ objects can\nbe permuted in $n \\cdot (n \u2013 1) \\cdot (n \u2013 2)  \\cdots 2  \\cdot 1 = n!$ ways.\n\n\nThis changes slightly if you are permuting a subset of distinct objects, or if some of your objects\nare indistinct. We will handle those cases shortly! Note that unique is a synonym for distinct.\n\n\nExample: How many unique orderings of characters are possible for the string \"BAYES\"?\nSolution: Since the order of characters is important, we are considering all permutations of the 5 distinct\ncharacters B, A, Y, E, and S: $5! = 120$.\n\t\n\n\n\nExample: a smart-phone has a 4-digit passcode. Suppose there are 4 smudges over 4 digits on\nthe screen. How many distinct passcodes are possible?\nSolution: Since the order of digits in the code is important, we should use permutations. And since\nthere are exactly four smudges we know that each number in the passcode is distinct. Thus, we can plug in the\npermutation formula: 4! = 24.\n\t\n\nPermutations of Indistinct Objects\n\n\nDefinition: Permutations of In-Distinct Objects\nGenerally when there are $n$ objects and:\n\n$n_1$ are the same (indistinguishable) and\n$n_2$ are the same and\n...\n$n_r$ are the same, then the number of distinct permutations is:\n\n\n$$\n\\text{Number of unique orderings} = \\frac{n!}{n_1!n_2!\\cdots n_r!}\n$$\n\n\n\n\nExample: How many distinct bit strings can be formed from three 0\u2019s and two 1\u2019s?\nSolution: 5 total digits would give 5! permutations. But that is assuming the 0\u2019s and 1\u2019s are\ndistinguishable (to make that explicit, let\u2019s give each one a subscript). Here are the $3! \\cdot 2! = 12$ different ways that we could have arrived at the identical string \"01100\" if we thought of each 0 and 1 as unique.\n\n\n\n\n\nSince identical digits are indistinguishable, all the listed permutations are the same. For any given\npermutation, there are 3! ways of rearranging the 0\u2019s and 2! ways of rearranging the 1\u2019s (resulting in\nindistinguishable strings). We have over-counted. Using the formula for permutations of indistinct\nobjects, we can correct for the over-counting:\n\n\n$$\n\\text{Total} = \\frac{5!}{3! \\cdot 2!} = \\frac{120}{6 \\cdot 2}\n= 10\n$$\n\n\n\n\n\nExample: How many distinct orderings of characters are possible for the string \"MISSISSIPPI\"?\n\n\n\nIn the case of the string \"MISSISSIPPI\", we should separate the characters into four distinct groups of indistinct characters: one \"M\", four \"I\"s, four \"S\"s, and two \"P\"s. The number of distinct orderings as: $$\\frac{11!}{1!4!4!2!} = 34,650$$\n\t\n\n\n\nExample: Consider the 4-digit passcode smart-phone from before. How many distinct passcodes are possible if there are 3 smudges over 3 digits on the screen?\n\nSolution: One of 3 digits is repeated, but we don't know which one. We can solve this by making three cases, one for each digit that could be repeated (each with the same number of permutations). Let $A, B, C$ represent the 3 digits, with $C$ repeated twice. We can initially pretend the two $C$'s are distinct $[A,B,C_1,C_2]$. Then each case will have 4! permutations:  \nHowever, then we need to eliminate the double-counting of the permutations of the identical digits (one $A$, one $B$, and two $C$'s): $$\\frac{4!}{2!\\cdot 1!\\cdot 1!}$$\nAdding up the three cases for the different repeated digits gives\n$$3 \\cdot \\frac{4!}{2!\\cdot 1!\\cdot 1!} = 3 \\cdot 12 = 36$$\n\n\nPart B: What if there are 2 smudges over 2 digits on the screen?\n\n\nSolution: There are two possibilities: 2 digits used twice each, or 1 digit used 3 times, and other digit used once.\n$$\n\\frac{4!}{2!\\cdot 2!} + 2 \\cdot \\frac{4!}{3!\\cdot 1!} = 6 + (2 \\cdot 4) = 6 + 8 = 14\n$$\n\n\n\n\tYou can use the power of computers to enumerate all permutations. Here is sample python which uses the built in itertools library:\n\t\n>>> import itertools\n\n# get all 4! = 24 permutations of 1,2,3,4 as a list:\n>>> list(itertools.permutations([1,2,3,4]))\n[(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2), (2, 1, 3, 4), (2, 1, 4, 3), (2, 3, 1, 4), (2, 3, 4, 1), (2, 4, 1, 3), (2, 4, 3, 1), (3, 1, 2, 4), (3, 1, 4, 2), (3, 2, 1, 4), (3, 2, 4, 1), (3, 4, 1, 2), (3, 4, 2, 1), (4, 1, 2, 3), (4, 1, 3, 2), (4, 2, 1, 3), (4, 2, 3, 1), (4, 3, 1, 2), (4, 3, 2, 1)]\n\n# get all 3!/2! = 3 unique permutations of 1,1,2 as a set:\n>>> set(itertools.permutations([1,1,2]))\n{(1, 2, 1), (2, 1, 1), (1, 1, 2)}\nCombinations of Distinct Objects\n\n\nDefinition: Combinations\nA combination is an unordered selection of r objects from a set of n objects. If all objects\nare distinct, and objects are not \"replaced\" once selected, then the number of ways of making the selection is:\n\n\t$$\n\t\\text{Number of unique selections} = \\frac{n!}{r!(n-r!)} = {n \\choose r}\n\t$$\n\n\n\n\n\tHere are all the $10 = {5 \\choose 3}$ ways of choosing three items from a list of 5 unique numbers:\n\t# Get all ways of chosing three numbers from [1,2,3,4,5]\n>>> list(itertools.combinations([1,2,3,4,5], 3))\n[(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5), (2, 3, 4), (2, 3, 5), (2, 4, 5), (3, 4, 5)]\n\nNotice how order doesn't matter. Since (1, 2, 3) is in the set of combinations, we don't also include (3, 2, 1) as this is considered to be the same selection. Note that this formula does not work if some of the objects are indistinct form one another.\nHow did we get the formula $\\frac{n!}{r!(n-r!)}$? Consider this general way to select $r$ unordered objects from a set of $n$\nobjects, e.g., \u201c7 choose 3\u201d:\n\nFirst consider permutations of all $n$ objects. There are $n!$ ways to do that.\nThen select the first $r$ in the permutation. There is one way to do that.\nNote that the order of $r$ selected objects is irrelevant. There are $r!$ ways to permute them. The\nselection remains unchanged.\n Note that the order of $(n \u2212 r)$ unselected objects is irrelevant. There are $(n \u2212 r)!$ ways to\npermute them. The selection remains unchanged.\n\t\n\n\t$$\n\t\\text{Total} = \\frac{n!}{r! \\cdot (n-r)!} = {n \\choose r}\n\t$$\n\n\n\nExample: In the Hunger Games, how many ways are there of choosing 2 villagers from district 12, which has a population of 8,000?\n\nSolution: This is a straightforward combinations problem. ${8000 \\choose 2} = $31,996,000.\n\n\n\n\nPart A: How many ways are there to select 3 books from a set of 6?\nSolution: If each of the books are distinct, then this is another straightforward combination problem. There are $\\binom{6}{3} = \\frac{6!}{3!3!} = 20$ ways.\n\n\nPart B: How many ways are there to select 3 books if there are two books that should not both be chosen together? For example, if you are choosing 3 out of 6 probability books, don't choose both the 8th and 9th edition of the Ross textbook).\n\\paragraph{Solution:} This problem is easier to solve if we split it up into cases. Consider the following three different cases:\n\n\nCase 1: Select the 8th Ed. and 2 other non-9th Ed.: There are $\\binom{4}{2}$ ways of doing so.\n\nCase 2: Select the 9th Ed. and 2 other non-8th Ed.: There are $\\binom{4}{2}$ ways of doing so.\n\nCase 3: Select 3 from the books that are neither the 8th nor the 8th edition:\tThere are $\\binom{4}{3}$ ways of doing so.\n\nUsing our old friend the Sum Rule of Counting, we can add the cases:\n$$\n\\text{Total} = 2 \\cdot \\binom{4}{2} + \\binom{4}{3} = 16\n$$\n\nAlternatively, we could have calculated all the ways of selecting 3 books from 6, and then subtract the \"forbidden'' ones (i.e., the selections that break the constraint). \n\n\nForbidden Case: Select 8th edition and 9th edition and 1 other book. There are $\\binom{4}{1}$ ways of doing so (which equals 4).\n\nTotal = All possibilities - forbidden = 20 - 4 = 16\n\n\nTwo different ways to get the same right answer!\n\n\nBucketing / Group Assignment\n\nIn this section we are going to be counting the many different ways that we can think of stuffing elements into containers. (It turns out that Jacob Bernoulli was into voting and ancient Rome. And in ancient Rome they used urns for ballot boxes. For this reason many books introduce this through counting ways to put balls in urns.) This \"bucketing\" or \"group assignment\" process is a useful metaphor for many counting problems.\n\n\nProblem: Say you want to put $n$ distinguishable balls into $r$ urns. (No! Wait! Don't say that!) Okay, fine. No urns. Say we are going to put $n$ strings into $r$ buckets of a hash table where all outcomes are equally likely. How many possible ways are there of doing this?\n\nSolution: You can think of this as $n$ independent experiments each with $r$ outcomes. Using our friend the General Principle of Counting, this comes out to $r^n$.\n\n\n\n\n\tWhile the previous example allowed us to put $n$ distinguishable objects into $r$ distinct groups, the more interesting problem is to work with $n$ indistinguishable objects. This task has a direct analogy to the number of ways to solve the following positive integer equation:\n\n\nDivider Method:\nSuppose you want to place $n$ indistinguishable items into $r$ containers. The divider method works by imagining that you are going to solve this problem by sorting two types of objects, your $n$ original elements and $(r - 1)$ dividers. Thus, you are permuting $n + r - 1$ objects, $n$ of which are same (your elements) and $r - 1$ of which are same (the dividers). Thus the total number of outcomes is:\n\n$${}\\frac{(n+r-1)!}{n!(r-1)!}  = \\binom{n+r-1}{n} = \\binom{n+r-1}{r-1}$$\n\n\n\n\nProblem: Say you want to put $n$ distinguishable balls into $r$ urns. (No! Wait! Don't say that!) Okay, fine. No urns. Say we are going to put $n$ strings into $r$ buckets of a hash table where all outcomes are equally likely. How many possible ways are there of doing this?\n\nSolution: You can think of this as $n$ independent experiments each with $r$ outcomes. Using our friend the General Principle of Counting, this comes out to $r^n$.\n\n\n\n\nPart A: Say you are a startup incubator and you have \\$10 million to invest in 4 companies (in \\$1 million increments). How many ways can you allocate this money?\nSolution: This is just like putting 10 balls into 4 urns. Using the Divider Method we get:\n\n$$\n\\text{Total ways}= \\binom{10+4-1}{10}  = \\binom{13}{10} = 286\n$$\n\nThis problem is analogous to solving the integer equation $x_1 + x_2 + x_3 + x_4 = 10$, where $x_i$ represents the investment in company $i$ such that $x_i \\geq 0$ for all $i = 1, 2, 3, 4$.\n\nPart B: What if you know you want to invest at least \\$3 million in Company 1?\nSolution: There is one way to give \\$3 million to Company 1. The number of ways of investing the remaining money is the same as putting 7 balls into 4 urns.\n\n$$\n\\text{Total Ways} = \\binom{7+4-1}{7}  = \\binom{10}{7} = 120\n$$\n\nThis problem is analogous to solving the integer equation $x_1 + x_2 + x_3 + x_4 = 10$, where $x_1 \\geq 3$ and $x_2, x_3, x_4 \\geq 0$. To translate this problem into the integer solution equation that we can solve via the divider method, we need to adjust the bounds on $x_1$ such that the problem becomes $x_1 + x_2 + x_3 + x_4 = 7$, where $x_i$ is defined as in Part A.\n\n\nPart C:  What if you don't have to invest all \\$10 M?  (The economy is tight, say, and you might want to save your money.)\nSolution: Imagine that you have an extra company: yourself. Now you are investing \\$10 million in 5 companies. Thus, the answer is the same as putting 10 balls into 5 urns.\n\n$$\n\\text{Total}= \\binom{10+5-1}{10}  = \\binom{14}{10} = 1001\n$$\n\nThis problem is analogous to solving the integer equation $x_1 + x_2 + x_3 + x_4 + x_5 = 10$, such that $x_i \\geq 0$ for all $i = 1, 2, 3, 4, 5$.\n\n\n\nBucketing into Fixed Sized Containers\n\n\nBucketing into Fixed Sized Containers: If $n$ objects are distinct, then the number of ways of putting them into $r$ groups of objects, such that group $i$ has size $n_i$, and $\\sum_{i=1}^{r} n_i = n$, is:\n$$\\frac{n!}{n_1!n_2!\\cdots n_r!} = \\binom{n}{n_1, n_2, \\dots, n_r}$$\n\nwhere $\\binom{n}{n_1, n_2, \\dots, n_r}$ is special notation called the multinomial coefficient.\n\n\n\nYou may have noticed that this is the exact same formula as \"Permutations With Indistinct Objects\". There is a deap parallel. One way to imagine assigning objects into their groups would be to imagine the groups themselves as objects. You have one object per \"slot\" in a group. So if there were two slots in group 1, three slots in group 2, and one slot in group 3 you could have six objects (1, 1, 2, 2, 2, 3). Each unique permutation can be used to make a unique assignment. \n\n\n\nProblem: Company Camazon has 13 distinct new servers that they would like to assign to 3 datacenters, where Datacenter A, B, and C have 6, 4, and 3 empty server racks, respectively. How many different divisions of the servers are possible?\n\n\n\nSolution: This is a straightforward application of our multinomial coefficient representation. Setting $n_1 = 6, n_2 = 4, n_3 = 3$, $\\binom{13}{6,4,3} = 60,060$.\n\nAnother way to do this problem would be from first principles of combinations as a multipart experiment. We first select the $6$ servers to be assigned to Datacenter A, in $\\binom{13}{6}$ ways. Now out of the $7$ servers remaining, we select the $4$ servers to be assigned to Datacenter B, in $\\binom{7}{4}$ ways. Finally, we select the $3$ servers out of the remaining $3$ servers, in $\\binom{3}{3}$ ways. By the Product Rule of Counting, the total number of ways to assign all servers would be $\\binom{13}{6} \\binom{7}{4} \\binom{3}{3} = \\frac{13!}{6!4!3!} = 60,060$.\n\n\n\n"}, {"id": "probability", "title": "Definition of Probability", "url": "part1/probability", "text": "              \nDefinition of Probability\n\nWhat does it mean when someone makes a claim like \"the probability that you find a pearl in an oyster is 1 in 5,000?\" or \"the probability that it will rain tomorrow is 52%?\nEvents and Experiments\nWhen we speak about probabilities, there is always an implied context, which we formally call the \"experiment\". For example: flipping two coins is something that probability folks would call an experiment. In order to precisely speak about probability, we must first define two  sets: the set of all possible outcomes of an experiment, and the subset that we consider to be our event (what is a set?).\n\n\nDefinition: Sample Space, $S$ A Sample Space is set of all possible outcomes of an experiment. For example:\n\n Coin flip: $S$ = {Heads, Tails}\n Flipping two coins: $S$ = {(H, H), (H, T), (T, H), (T, T)}\n Roll of 6-sided die: $S$ = {1, 2, 3, 4, 5, 6}\n The number of emails you receive in a day: $S = \\{x|x \u2208 \u2124, x \u2265 0\\}$ (non-neg. ints)\n YouTube hours in a day: $S = \\{x|x \u2208 \u211d,0 \u2264 x \u2264 24\\}$\n\n\n\n\n\nDefinition: Event, $E$ An Event is some subset of $S$ that we ascribe meaning to. In set notation ($E \u2286 S$).For example:\n\n Coin flip is heads: $E$ = {Heads}\n Greater than 1 head on 2 coin flips = {(H, H), (H, T), (T, H)}\n Roll of die is 3 or less: E = {1, 2, 3}\n You receive less than 20 emails in a day: $E = \\{x|x \u2208 Z,0 \u2264 x < 20\\}$ (non-neg. ints)\n Wasted day (\u2265 5 YouTube hours): $E = \\{x|x \u2208 R, 5 \u2264 x \u2264 24\\}$\n\nEvents can be represented as capital letters such as $E$ or $F$.\n\n\n[todo] In the world of probability, events are binary: they either happen or they don't.\nDefinition of Probability\nIt wasn't until the 20th century that humans figured out a way to precisely define what the word probability means:\n$$ \\p(\\text{Event}) \n  = \\lim_{n \\rightarrow \\infty}\n    \\frac\n        {\\text{count}(\\text{Event})}\n        {n} \n    $$\nIn English this reads: lets say you perform $n$ trials of an \"experiment\" which could result in a particular \"Event\" occuring. The probability of the event occuring, $\\p(\\text{Event})$,\nis the ratio of trials that result in the event, written as $\\text{count}(\\text{Event})$, to the number of trials performed, $n$.  In the limit, as your number of trials\napproaches infinity, the ratio will converve to the true probability. People also apply other semantics to the concept of a probability. One\ncommon meaning ascribed is that $\\p(E)$ is a measure of the chance of event E occurring. \n\n\nMeasure of uncertainty: It is tempting to think of probability as representing some natural randomness in the world. That might be the case. But perhaps the world isn't random. I propose a deeper way of thinking about probability. There is so much that we as humans don't know, and probability is our robust language for expressing my belief that an event will happen given my limited knowledge.\nThis interpretation acknowledges that your own uncertainty of an event. Perhaps if you knew the position of every water molecule, you could perfectly predict tomorrow's weather. But we don't have such knowledge and as such we use probability to talk about the chance of rain tomorrow given the information that we have access to.\nOrigins of probabilities: The different interpretations of probability are reflected in the many origins of probabilities that you will encounter in the wild (and not so wild) world. Some probabilities are calculated analytically using mathematical\nproofs. Some probabilities are calculated from data, experiments or simulations. Some probabilities are just\nmade up to represent a belief. Most probabilities are generated from a combination of the above. For example, someone will make up a prior belief, that\nbelief will be mathematically updated using data and evidence. Here is an example of calculating a probability from data: \n\n\n\nProbabilities and simulations: Another way to compute probabilities is via simulation. For some complex problems where the probabilities are too hard to compute analytically you can run\nsimulations using your computer.\nIf your simulations generate believable trials from the sample space, then the probability of an event E is\napproximately equal to the fraction of simulations that produced an outcome from E. Again, by the definition\nof probability, as your number of simulations approaches infinity, the estimate becomes more accurate.\n\n\nProbabilities and percentages: You might hear people refer to a probability as a percent. That the probability of rain tomorrow is 32%. The proper way to state this would be to say that 0.32 is the probability of rain. Percentages are simply probabilities multiplied by 100. \"percent\" is latin for \"out of one hundred\".  \n\n\nProblem: Use the definition of probability to approximate the answer to the question: \"What is the probability a new-born elephant child is male?\" Contrary to what you might think the gender outcomes of a newborn elephant are not equally likely between male and female. You have data from a report in Animal Reproductive Science which states that 3,070 elephants were born in Myanmar of which 2,180 were male [1]. Humans also don't have a 50/50 sex ratio at birth [2].\nAnswer:\n\tThe Experiment is: A single elephant birth in Myanmar. The sample space is the set of possible sexes assigned at birth, {Male, Female, Intersex}. $E$ is the event that a new-born elephan child is male, which in set notation is the subset {Male} of the sample space. The outcomes are not equally likely.\n By the definition of probability, the ratio of trials that result in the event to the number of trials will tend to our desired probability:\n$$ \\begin{aligned} \\p(\\text{Born Male}) &= \\p(E) \\\\\n\t\t&= \\lim_{n \\rightarrow \\infty}\\frac{\\text{count}(E)}{n} \\\\\n\t    &\\approx \\frac{2,180}{3,070} \\\\\n\t    &\\approx 0.710\\end{aligned}$$\nSince 3,000 is quite a bit less than infinity, this is an approximation. It turns out, however, to be a rather good one. A few important notes: there is no garuntee that our estimate applies to elephants outside Myanmar. Later in the class we will develop language for \"how confident we can be in a number like 0.71 after 3,000 trials?\" Using tools from later in class we can say that we have 98% confidence that the true probability is within 0.02 of 0.710.\n\nAxioms of Probability\nHere are some basic truths about probabilities that we accept as axioms:\n\n\n\n\nAxiom 1: $0 \u2264 \\p(E) \u2264 1$\nAll probabilities are numbers between 0 and 1.\n\n\nAxiom 2: $\\p(S) = 1$\nAll outcomes must be from the Sample Space.\n\n\nAxiom 3: If $E$ and $F$ are mutually exclusive, then $\\p(E \\text{ or } F) = \\p(E) + \\p(F)$\n The probability of \"or\" for mutually exclusive events\n\n\n\n\nThese three axioms are formally called the Kolmogorov axioms and they are considered to be the foundation of probability theory. They are also useful identities!\nYou can convince yourself of the first axiom by thinking about the math definition of probability. As you\nperform trials of an experiment it is not possible to get more events than trials (thus probabilities are less than\n1) and its not possible to get less than 0 occurrences of the event (thus probabilities are greater than 0).\nThe second axiom makes sense too. If your event is the sample space, then each trial must produce\nthe event. This is sort of like saying; the probability of you eating cake (event) if you eat cake (sample\nspace that is the same as the event) is 1.\n\nThe third axiom is more complex and in this textbook we dedicate an entire chapter to understanding it: Probability of or. It applies to events that have a special property called \"mutual exclusion\": the events do not share any outcomes.\n\n\nThese axioms have great historical significance. In the early 1900s it was not clear if probability was somehow different than other fields of math -- perhaps the set of techniques and systems of proofs from other fields of mathematics couldn't apply.  Kolmogorov's great success was to show to the world that the tools of mathematics did infact apply to probability. From the foundation provided by this set of axioms mathematicians built the edifice of probability theory.\nProvable Identities\nWe often refer to these as corollaries that are directly provable from the three\naxioms given above.\n\n\n\n\nIdentity 1: $\\p(E\\c) = 1 - \\p(E)$\nThe probability of event E not happening\n\n\nIdentity 2: If $E \u2286 F$, then $\\p(E) \u2264 \\p(F)$\nEvents which are subsets\n\n\n\n\nThis first identity is especially useful. For any event, you can calculate the probability of the event not occuring which we write in probability notation as $E\\c$, if you know the probability of it occuring -- and vice versa. We can also use this identity to show you what it looks like to prove a theorem in probability.\n\nProof: $\\p(E\\c) = 1 - \\p(E)$\n\n$$\n\\begin{align}\n\\p(S) &= \\p(E \\or E\\c) && \\text{$E$ or $E\\c$ covers every outcome in the sample space} \\\\\n\\p(S) &= \\p(E) + \\p(E\\c) && \\text{Events $E$ and $E\\c$ are mututally exclusive} \\\\\n1 &= \\p(E) + \\p(E\\c) && \\text{Axiom 2 of probability} \\\\\n\\p(E\\c) &= 1 - \\p(E) && \\text{By re-arranging}\n\\end{align}\n$$\n\n"}, {"id": "probability", "title": "Definition of Probability", "url": "part1/probability", "text": "\nExample: Probability in the limit\nHere we use the definition of probability to calculate the probability of event $E$, rolling a \"5\" or a \"6\" on a fair six-sided dice. Hit the \"Run trials\" button to start running trials of the experiment \"roll dice\". Notice how $\\p(E)$, converges to $2/6$ or 0.33 repeating.\nEvent $E$: Rolling a 5 or 6 on a six-sided dice.\n\n\n Run trials\nDice outcome: \n\n\n\n\n\n\n\n$n= $ 0\n$\\text{count}(E) = $  0\n\n\n\t\t\t$ \\p(E) \n  \\approx \n    \\frac\n        {\\text{count}(E)}\n        {n} \n     =\n    $\n\t\t\t\n\n\n\n"}, {"id": "equally_likely", "title": "Equally Likely Outcomes", "url": "part1/equally_likely", "text": "\n \nEqually Likely Outcomes\n\nSome sample spaces have equally likely outcomes. We like those sample spaces, because there is a way\nto calculate probability questions about those sample spaces simply by counting. Here are a few examples\nwhere there are equally likely outcomes:\n\n\nCoin flip: S = {Head, Tails}\n\tFlipping two coins: S = {(H, H), (H, T), (T, H), (T, T)}\n\tRoll of 6-sided die: S = {1, 2, 3, 4, 5, 6}\n\t\n\nBecause every outcome is equally likely, and the probability of the sample space must be 1, we can prove\nthat each outcome must have probability:\n$$\n\\p(\\text{an outcome}) = \\frac{1}{|S|}\n$$\nWhere |S| is the size of the sample space, or, put in other words, the total number of outcomes of the experiment. Of course this is only true in the special case where every outcome has the same likelihood. \n\n\nDefinition: Probability of Equally Likely Outcomes \n\n\t\tIf $S$ is a sample space with equally likely outcomes, for an\nevent $E$ that is a subset of the outcomes in $S$:\n$$\n\\begin{align}\n\\p(E) &= \\frac{\\text{number of outcomes in $E$}}{\\text{number of outcomes in $S$}} \n= \\frac{|E|}{|S|}\n\\end{align}\n$$\n\n\t\n\nThere is some art form to setting up a problem to calculate a probability based on the equally likely outcome\nrule. (1) The first step is to explicitly define your sample space and to argue that all outcomes in your sample\nspace are equally likely. (2) Next, you need to count the number of elements in the sample space and (3)\nfinally you need to count the size of the event space. The event space must be all elements of the sample\nspace that you defined in part (1). The first step leaves you with a lot of choice! For example you can decide\nto make indistinguishable objects distinct, as long as your calculation of the size of the event space makes the\nexact same assumptions.\n\n\nExample: What is the probability that the sum of two die is equal to 7?\nBuggy Solution: You could define your sample space to be all the possible sum values of two die (2 through 12).\nHowever this sample space fails the \u201cequally likely\u201d test. You are not equally likely to have a sum of 2 as you\nare to have a sum of 7.\nSolution: Consider the sample space from the previous chapter where we thought of the die as distinct and\nenumerated all of the outcomes in the sample space. The first number is the roll on die 1 and the second\nnumber is the roll on die 2. Note that (1, 2) is distinct from (2, 1). Since each outcome is equally likely, and the sample space has exactly 36 outcomes, the likelihood of any one outcome is $\\frac{1}{36}$. Here is a visualization of all outcomes:\n\n\n\n(1,1)(1,2)(1,3)(1,4)(1,5)(1,6)\n(2,1)(2,2)(2,3)(2,4)(2,5)(2,6)\n(3,1)(3,2)(3,3)(3,4)(3,5)(3,6)\n(4,1)(4,2)(4,3)(4,4)(4,5)(4,6)\n(5,1)(5,2)(5,3)(5,4)(5,5)(5,6)\n(6,1)(6,2)(6,3)(6,4)(6,5)(6,6)\n\n\nThe event (sum of dice is 7) is the subset of the sample space where the sum of the two dice is 7. Each outcome in the event is highlighted in blue. There are 6 such outcomes: (1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1). Notice that (1, 6) is a different outcome than (6, 1). To make the outcomes equally likely we had to make the die distinct.\n\t$$\n\t\\begin{align}\n\t\\p(\\text{Sum of two dice is 7}) \n\t&= \\frac{|E|}{|S|}\n\t&& \\text{Since outcomes are equally likely} \\\\\n\t&= \\frac{6}{36} = \\frac{1}{6}\n\t&& \\text{There are 6 outcomes in the event}\n\t\\end{align}\n\t$$\n\n\n\n\nInterestingly, this idea also applies to continuous sample spaces. Consider the sample space of all the outcomes of the computer function \"random\" which produces a real valued number between 0 and 1, where all\nreal valued numbers are equally likely. Now consider the event $E$ that the number generated is in the range\n[0.3 to 0.7]. Since the sample space is equally likely, $\\p(E)$ is the ratio of the size of $E$ to the size of $S$. In this\ncase $\\p(E) = \\frac{0.4}{1} = 0.4$.\n"}, {"id": "prob_or", "title": "Probability of <b>or</b>", "url": "part1/prob_or", "text": " \nProbability of or\n\nThe equation for calculating the probability of either event E or event F happening, written  $\\p(E \\or F)$ or equivalently as $\\p(E \u222a F)$, is deeply analogous\nto counting the size of two sets. As in counting, the equation that you can use  depends on whether or not the events are \"mutually exclusive\". If events are mutually exclusive, it is very straightforward to calculate the probability of either event happening. Otherwise, you need the more complex \"inclusion exclusion\" formula.\nMutually Exclusive Events\nTwo events: $E$, $F$ are considered to be mutually exclusive (in set notation $E \u2229 F = \u2205$) if there are no outcomes that are\nin both events (recall that an event is a set of outcomes which is a subset of the sample\nspace). In English, mutually exclusive means that two events can't both happen.\nMutual exclusion can be visualized. Consider the following visual sample space where each outcome is a\nhexagon. The set of all the fifty hexagons is the full sample space:\n\n\n\nExample of two events: $E$, $F$, which are mutually exclusive.\n\n\nBoth events $E$ and $F$ are subsets of the same sample space. Visually, we can note that\nthe two sets do not overlap. They are mutually exclusive: there is no outcome that is in both sets.\n\n\nDefinition: Probability of or for mututally exclusive events\nIf two events: $E$, $F$ are mutually exclusive then the probability of $E$ or $F$ occuring is:\n\t\t\t$$\n\t\t\t\\p(E \\or F) = \\p(E) + \\p(F)\n\t\t\t$$\n\t\t\nThis property applies regardless of how you calculate the probability of $E$ or $F$.\nMoreover, the idea extends to more than two events. Lets say you have $n$ events $E_1, E_2, \\dots E_n$ where each\nevent is mutually exclusive of one another (in other words, no outcome is in more than one event). Then:\n$$\n\t\t\t\\p(E_1 \\or E_2 \\or \\dots \\or E_n) = \\p(E_1) + \\p(E_2) + \\dots + \\p(E_n) = \\sum_{i=1}^n \\p(E_i)\n\t\t\t$$\n\n\nYou may have noticed that this is one of the axioms of probability. Though it might seem intuitive, it is one of three rules that we accept without proof.\n\nCaution: Mutual exclusion only makes it easier to calculate the probability of $E \\or F$ not other ways of combining events, such as $E \\and F$. \n\nAt this point we know how to compute the probability of the \"or\" of events if and only if they have the mutual exclusion property. What if they don't?\n$\\p(\\or)$ for Non-mutually Exclusive Events\nUnfortunately, not all events are mutually exclusive. If you want to calculate $\\p(E \\or F)$ where the events $E$\nand F are not mutually exclusive you can not simply add the probabilities. As a simple sanity check, consider the event $E$: getting heads on a coin flip, where $\\p(E) = 0.5$. Now imagine the sample space $S$, getting either a heads or a tails on a coin flip. These events are not mutually exclusive (the outcome heads is in both). If you incorrectly assumed they were mutually exclusive and tried to calculate $\\p(E \\or S)$ you would get this buggy derivation:\n\n\nBuggy derivation: Incorrectly assuming mutual exclusion\nCalculate the probability of $E$, getting an even number on a dice role (2, 4 or 6), or $F$, getting three or less (1, 2, 3) on the same dice role.\n\t$$\n\t\\begin{align}\n\t\\p(E \\or F) &= \\p(E) + \\p(F) && \\text{Incorrectly assumes mutual exclusion} \\\\\n\t&= 0.5 + 0.5 && \\text{substitute the probabilities of $E$ and $S$} \\\\\n\t&= 1.0 && \\text{uh oh!}\n\t\\end{align}\n\t$$\n\tThe probability can't be one since the outcome 5 is neither three or less nor even. The problem is that we double counted the probability of getting a 2, and the fix is to subtract out the probability of that doubly counted case.\n\nWhat went wrong? If two events are not mutually exclusive, simply adding their probabilities double counts the probability of any outcome which is in both events. There is a formula for calculating or of two non-mutually exclusive events: it is called the \"inclusion exclusion\" principle.\n\n\n\nDefinition: Inclusion Exclusion principle\nFor any two events: E, F:\n$$\n\\p(E \\or F) = \\p(E) + \\p(F) \u2212 \\p(E \\and F)\n$$\nThis formula does have a version for more than two events, but it gets rather complex. For three events, $E$, $F$, and $G$ the formula is:\n\t$$\n\t\\begin{align}\n\t\\p(E \\or F \\or G) =& \\text{ }\\p(E) + \\p(F) + \\p(G) \\\\\n& \u2212\\p(E \\and F) \u2212 \\p(E \\and G)\u2212P(F \\and G) \\\\\n& +\\p(E \\and F \\and G)\n\t\\end{align}\n\t$$\n\nFor $n$ events, $E_1, E_2, \\dots E_n$: build a running sum. Add all the probabilities of the events on their own. Then subtract all pairs of events. Then add all subsets of 3 events. Then subtract all subset of 4 events. Continue this process, up until $n$, adding the subsets if the size of subsets is odd, else subtracting them. The alternating addition and subtraction is where the name inclusion exclusion comes from. This is a complex process and you should first check if there is an easier way to calculate your probability.\n\n\nNote that the inclusion exclusion principle also applies for mutually exclusive events. If two events are mutually exclusive $\\p(E \\and F) = 0$ since its not possible for both $E$ and $F$ to occur. As such the formula $\\p(E) + \\p(F) - \\p(E \\and F)$ reduces to $\\p(E) + \\p(F)$.\n\n\tThe formulas for calculating the or of events that are not mutually exclusive often requires calculating the probability of the and of events. Learn more in the next section:\n\t\n\n"}, {"id": "cond_prob", "title": "Conditional Probability", "url": "part1/cond_prob", "text": "\n \nConditional Probability\n\nIn English, a conditional probability states \"what is the chance of an event $E$ happening given that I have\nalready observed some other event $F$\". It is a critical idea in machine learning and probability because it\nallows us to update our probabilities in the face of new evidence.\nWhen you condition on an event happening you are entering the universe where that event has taken place.\nMathematically, if you condition on $F$, then $F$ becomes your new sample space. In the universe where $F$ has\ntaken place, all rules of probability still hold!\n\n\nDefinition: Conditional Probability.\nThe probability of E given that (aka conditioned on) event F already happened:\n$$\n\\p(E |F) = \\frac{\\p(E \\and F)}{\\p(F)}\n$$\n\n\n\n\n\t Let's use a visualization to get an intuition for why the conditional probability formula is true. Again consider events $E$ and $F$\t\nwhich have outcomes that are subsets of a sample space with 50 equally likely outcomes, each one drawn as\na hexagon:\n\n\n\n\n\n\n\n\tConditioning on $F$ means that we have entered the world where $F$ has happened (and $F$, which has 14\nequally likely outcomes, has become our new sample space). Given that event $F$ has occurred, the conditional\nprobability that event $E$ occurs is the subset of the outcomes of E that are consistent with $F$. In this case we\ncan visually see that those are the three outcomes in $E \\and F$. Thus we have the:\n$$\n\\p(E |F) = \\frac{\\p(E \\and F)}{\\p(F)} = \\frac{3/50}{14/50} = \\frac{3}{14} \\approx 0.21\n$$\n\nEven though the visual example (with equally likely outcome spaces) is useful for gaining intuition, conditional probability applies regardless of whether the sample space has equally likely outcomes!\n\n\n\nDefinition: The chain rule.\nThe formula in the definition of conditional probability can be re-arranged to derive a general way of calculating the probability of the and of any two events:\n$$\n\\p(E \\and F) = \\p(E | F) \\cdot \\p(F)\n$$\n\nOf course there is nothing special about $E$ that says it should go first. Equivalently:\n\t$$\n\t\\p(E \\and F) = \\p(F \\and E) =  \\p(F | E) \\cdot \\p(E)\n\t$$\n\nWe call this formula the \"chain rule.\" Intuitively it states that the probability of observing events $E$ and $F$ is the\nprobability of observing $F$, multiplied by the probability of observing $E$, given that you have observed $F$.\nIt generalizes to more than two events:\n$$\n\\begin{align}\n\\p(E_1 \\and E_2 \\and \\dots \\and E_n) = &\\p(E_1) \\cdot \\p(E_2|E_1) \\cdot \\p(E_3 |E_1 \\and E_2) \\dots  \\\\  &\\p(E_n|E_1 \\dots E_{n\u22121})\n\\end{align}\n$$\n\t\n\nDifference between and and conditionals\nThe Conditional Paradigm\nWhen you condition on an event you enter the universe where that event has taken place. In that new universe\nall the laws of probability still hold. Thus, as long as you condition consistently on the same event, every one of\nthe tools we have learned still apply. Let\u2019s look at a few of our old friends when we condition consistently on\nan event (in this case $G$):\n\n\n\n\nName of Rule\nOriginal Rule\nRule Conditioned on $G$\n\n\n\n\nAxiom of probability 1\n$0 \u2264 \\p(E) \u2264 1$\n$0 \u2264 \\p(E|G) \u2264 1$\n\n\nAxiom of probability 2\n$\\p(S) = 1$\n$\\p(S | G) = 1$\n\n\nAxiom of probability 3\n$\\p(E \\or F) = \\p(E) + \\p(F)$ for mutually exclusive events\n$\\p(E \\or F | G) = \\p(E | G) + \\p(F | G)$ for mutually exclusive events\n\n\nIdentity 1\n$\\p(E\\c) = 1 - \\p(E)$\n$\\p(E\\c | G) = 1 - \\p(E |G)$\n\n\n\n\nConditioning on Multiple Events\nThe conditional paradigm also applies to the definition of conditional probability! Again if we consistently condition on some event $G$ occuring, the rule still holds:\n\t\t$$\n\\p(E |F, G) = \\frac{\\p(E \\and F | G)}{\\p(F | G)}\n\t\t$$\nThe term $\\p(E | F, G)$ is new notation for conditioning on multiple events.  You should read that term as \"The probability of E occuring, given that both F and G have occured\". This equation states that the definition for conditional probability of $E | F$ still applies in the universe where $G$ has occured. Do you think that  $\\p(E |F, G)$ should be equal to $\\p(E |F)$? The answer is: sometimes yes and sometimes no. \n\n\t\n\n\n"}, {"id": "independence", "title": "Independence", "url": "part1/independence", "text": "\n \nIndependence\n\nSo far we have talked about mutual exclusion as an important \"property\" that two or more events can have. In this chapter we will introduce you to a second property: independence. Independence is perhaps one of the most important properties to consider! Like for mutual exclusion, if you can establish that this property applies (either by logic, or by declaring it as an assumption) it will make analytic probability calculations much easier!\n\n\n\n\nDefinition: Independence\nTwo events are said to be independent if knowing the outcome of one event does not change your belief about whether or not the other event will occur. For example, you might say that two separate dice rolls are independent of one another: the outcome of the first dice gives you no information about the outcome of the second -- and vice versa. \n\n\t$$\n\t\\p(E | F) = \\p(E)\n\t$$\n\n\tThis definition is symmetric. If $E$ is independent of $F$, then $F$ is independent of $E$:\n\t$$\n\t\\p(F | E) = \\p(F)\n$$\n\n\nHow to establish independence\n\n\tHow can you show that two or more events are independent? The default option is to show it mathematically. If you can show that $\\p(E | F) = \\p(E)$ then you have proven that the two events are indepedent. When working with probabilities that come from data,\nvery few things will exactly match the mathematical definition of independence. That can happen for two reasons:\nfirst, events that are calculated from data or simulation are not perfectly precise and it can be impossible to know if a discreptancy between $\\p(E)$ and $\\p(E |F)$ is due to innacuracy in estimating probabilities, or dependence of events. Second, in our complex\nworld many things actually influence each other, even if just a tiny amount. Despite that we often make the\nwrong, but useful, independence assumption. Since independence makes it so much easier for humans and machines to calculate composite probabilities, you may declare the events to be independent. It could mean your resulting calculation is slightly incorrect -- but this \"modelling assumption\" might make it feasible to come up with a result.\n\nIndependence is a property which is often \"assumed\" if you think it is reasonable that one event is unlikely to influence your belief that the other will occur (or if the influence is negligable). Let's worth through a few examples to better understand:\n\n\nConditional Independence\nWe saw earlier that the laws of probability still held if you consistently conditioned on an event. While the rules stay the same, the independence property might change. Events that were dependent can become independent when conditioning on an event. Events that were independent can become dependent.\n\n"}, {"id": "prob_and", "title": "Probability of <b>and</b>", "url": "part1/prob_and", "text": "\n \n\nProbability of and\n\nThe probability of the and of two events, say $E$ and $F$, written $\\p(E \\and F)$, is the probability of both events happening. You might see equivalent notations $\\p(EF)$, $\\p(E \u2229 F)$ and $\\p(E,F)$ to mean the probability of and. How you calculate the probability of event $E$ and event $F$ happening\ndepends on whether or not the events are \"independent\". In the same way that mutual exclusion makes it easy to calculate the probability of the or of events, independence is a property that makes it easy to calculate the and of events.\nIndependent Events\nIf events are independent then calculating the probability of and becomes simple multiplication:\n\n\n\nDefinition: Probability of and for independent events.\nIf two events: $E$, $F$ are independent then the probability of $E$ and $F$ occuring is:\n\t\t\t$$\n\t\t\t\\p(E \\and F) = \\p(E) \\cdot \\p(F)\n\t\t\t$$\n\t\t\nThis property applies regardless of how the probabilities of $E$ and $F$ were calculated and\nwhether or not the events are mutually exclusive. \n The independence principle extends to more than two\nevents. For $n$ events $E_1, E_2, \\dots E_n$ that are mutually independent of one another -- the independence equation also holds for all subsets of the events.\n$$\n\\p(E_1 \\and E_2 \\and \\dots \\and E_n) = \\prod_{i=1}^n \\p(E_i)\n$$\n\n\n\n\n\n\tWe can prove this equation by combining the definition of conditional probability and the definition of independence.\n\t\nProof: If $E$ is independent of $F$ then $\\p(E \\and F) = \\p(E) \\cdot \\p(F)$\n\t$$\n\t\\begin{align}\n\t\\p(E|F) &= \\frac{\\p(E \\and F)}{\\p(F)} && \\text{Definition of }\n\t\\href{ {{pathToLang}}part1/cond_prob/}{\\text{conditional probability}} \n\t\\\\\n\t\\p(E) &=  \\frac{\\p(E \\and F)}{\\p(F)} && \\text{Definition of }\n\t\\href{ {{pathToLang}}part1/independence/}{\\text{independence}} \\\\\n\t\\p(E \\and F) &= \\p(E) \\cdot \\p(F) && \\text{Rearranging terms}\n\t\\end{align}\n\t$$\n\n\nSee the chapter on independence to learn about when you can assume that two events are independent\nDependent Events\nEvents which are not independent are called dependent events. How can you calculate the and of dependent events? If your events are mutually exclusive you might be able to use a technique called DeMorgan's law, which we cover in a latter chapter. For the probability of and in dependent events there is a direct formula called the chain rule  which we cover in the next chapter: Conditional Probability.\n\n"}, {"id": "law_total", "title": "Law of Total Probability", "url": "part1/law_total", "text": "\n \nLaw of Total Probability\n\nAn astute person once observed that when looking at a picture, like the one we say for conditional probability:\n\n\n\n\n\n\nthat event $E$ can be\nthought of as having two parts, the part that is in $F$, $(E \\and F)$, and the part that isn\u2019t, $(E \\and F\\c)$.\nThis is true\nbecause $F$ and $F\\c$ are (a) mutually exclusive sets of outcomes which (b) together cover the entire sample space.\nAfter further investigation this proved to be mathematically true, and there was much rejoicing:\n\n$$\\p(E) = \\p(E \\and F) + \\p(E \\and F\\c)$$\nThis observation proved to be particularly useful when it was combined with the chain rule and gave rise to a\ntool so useful, it was given the big name, law of total probability.\n\n\nThe Law of Total Probability\nIf we combine our above observation with the chain rule, we get a very useful formula:\n$$\n\\p(E) = \\p(E | F) \\p(F) + \\p(E | F\\c) \\p(F\\c)\n$$\n\nThere is a more general version of the rule. If you can divide your sample space into any number of\nmutually exclusive events: $B_1, B_2, \\dots B_n$ such that every outcome in sample space fall into one of those\nevents, then:\n$$\n\\begin{align}\n\\p(E) \n&= \\sum_{i=1}^n \\p(E \\and B_i) && \\text{Extension of our observation}\\\\\n&= \\sum_{i=1}^n \\p(E | B_i) \\p(B_i) && \\text{Using chain rule on each term}\n\\end{align}\n$$\n\n\n\n\tWe can build intuition for the general version of the law of total probability in a similar way. If we can divide a sample space into a set of several mutually exclusive sets (where the $\\or$ of all the sets covers the entire sample space) then any event can be solved for by thinking of the likelihood of the event and each of the mutually exclusive sets.\n\n\n\n\n\n\n\n\tIn the image above, you could compute $\\p(E)$ to be equal to $\\p\\Big[(E \\and B_1) \\text{ }\\or \\text{ }(E \\and B_2) \\dots\\big]$. Of course this is worth mentioning because there are many real world cases where the sample space can be discretized into several mutual exclusive events. As an example, if you were thinking about the probability of the location of an object on earth, you could discretize the area over which you are tracking into a grid. \n\t\n\n"}, {"id": "bayes_theorem", "title": "Bayes' Theorem", "url": "part1/bayes_theorem", "text": "\n \n Bayes' Theorem\n\nBayes' Theorem is one of the most ubiquitous results in probability for computer scientists. In a nutshell, Bayes' theorem  provides a way to convert a conditional probability from one direction, say $\\p(E|F)$, to the other direction, $\\p(F|E)$. \n\n\tBayes' theorem is a mathematical identity which we can\nderive ourselves. Start with the definition of conditional probability and then expanding the $\\and$ term using the chain rule:\n\n\n$$\n\\begin{align}\n\\p(F|E) \n&= \\frac{\\p(F \\and E)}{\\p(E)} && \\text{Def of }\n\\href{ {{pathToLang}}part1/cond_prob/}{\\text{conditional probability}}\n\n  \\\\\n&= \\frac{\\p(E | F) \\cdot \\p(F)}{\\p(E)} && \\text{Substitute the }\n\\href{ {{pathToLang}}part1/cond_prob/#chain_rule}{\\text{chain rule}} \\text{ for $\\p(F \\and E)$}\n\\end{align}\n$$\n\n\nThis theorem makes no assumptions about $E$ or $F$ so it will apply for any two events. Bayes' theorem  is exceptionally useful because it turns out to be the ubiquitous way to answer the question: \"how can I update a belief about something,  which is not directly observable, given evidence.\" This is for good reason. For many \"noisy\" measurements it is straightforward to estimate the probability of the noisy observation given the true state of the world. However, what you would really like to know is the conditional probability the other way around: what is the probability of the true state of the world given evidence.  There are countless real world situations that fit this situation:\n\n\n\nExample 1: Medical tests\nWhat you want to know: Probability of a disease given a test result\nWhat is easy to know: Probability of a test result given the true state of disease\nCausality: We believe that diseases influences test results\n\n\nExample 2: Student ability\nWhat you want to know: Student knowledge of a subject given their answers\nWhat is easy to know: Likelihood of answers given a student's knowledge of a subject\nCausality: We believe that ability influences answers \n\n\nExample 3: Cell phone location\nWhat you want to know: Where is a cell phone, given noisy measure of distance to tower\nWhat is easy to know: Error in noisy measure, given the true distance to tower\nCausality: We believe that cell phone location influences distance measure\n\n\n\n\tThere is a pattern here: in each example we care about knowing some unobservable -- or hard to observe -- state of the world. This state of the world \"causes\" some easy-to-observe evidence. For example: having the flu (something we would like to know) causes a fever (something we can easily observe), not the other way around. We often call the unobservable state the \"belief\" and the observable state the \"evidence\". For that reason lets rename the events! Lets call the unobservable thing we want to know $B$ for belief. Lets call the thing we have evidence of $E$ for evidence. This makes is clear that Bayes' theorem allows us to calculate an updated belief given evidence: $\\p(B | E)$\n\n\n\n\nDefinition: Bayes' Theorem \n The most common form of Bayes' Theorem is \n\t\tBayes' Theorem Classic:\n\t\t$$\n\t\t\\p(B|E) = \\frac{\\p(E | B) \\cdot \\p(B)}{\\p(E)} \n\t\t$$\n\t\nThere are names for the different terms in the Bayes' Rule formula. The term $\\p(B|E)$  is often called the\n\"posterior\": it is your updated belief of $B$ after you take into account evidence $E$. The term $\\p(B)$ is often called the \"prior\": it was your belief before seeing any evidence. The term $\\p(E|B)$ is called the update and $\\p(E)$ is\noften called the normalization constant.\nThere are several techniques for handling the case where the denominator is not know. One technique is to use the law of total probability to expand out the term, resulting in another formula, called Bayes' Theorem with Law of Total Probability:\n$$\n\\p(B|E) = \\frac{\\p(E | B) \\cdot \\p(B)}{\\p(E|B)\\cdot \\p(B) + \\p(E|B\\c) \\cdot \\p(B\\c)} \n$$\n\nRecall the law of total probability which is responsible for our new denominator:\n$$\n\\begin{align}\n\\p(E) = \\p(E|B)\\cdot \\p(B) + \\p(E|B\\c) \\cdot \\p(B\\c)\n\\end{align}\n$$\n\n\nA common scenario for applying the Bayes' Rule formula is when you want to know the probability of\nsomething \u201cunobservable\u201d given an \u201cobserved\u201d event. For example, you want to know the probability that a\nstudent understands a concept, given that you observed them solving a particular problem. It turns out it is\nmuch easier to first estimate the probability that a student can solve a problem given that they understand the\nconcept and then to apply Bayes' Theorem. Intuitively, you can think about this as updating a belief given\nevidence.\nBayes' Theorem Applied\nSometimes the (correct) results from Bayes' Theorem can be counter intuitive. Here we work through a classic result: Bayes' applied to medical tests. We show a dynamic solution and present a visualization for understanding what is happening.\n\n\nBayes with the General Law of Total Probability\nA classic challenge when applying Bayes' theorm is to calculate the probability of the normalization constant $\\p(E)$ in the denominator of Bayes' Theorem. One common strategy for calculating this probability is to use the law of total probability. Our expanded version of Bayes' Theorem uses the simple version of the total law of probability: $\\p(E) = \\p(E|F)\\p(F) + \\p(E|F^c)\n\t\\p(F^c)$. Sometimes you will want the more expanded version of the law of total probability: $\\p(E) = \\sum_i\\p(E|B_i)\\p(B_i)$. Recall that this only works if the events $B_i$ are mutually exclusive and cover the sample space.\n\t\nFor example say we are trying to track a phone which could be in any one of $n$ discrete\nlocations and we have prior beliefs $\\p(B_1) \\dots \\p(B_n)$ as to whether the phone is in location $B_i$. Now we gain\nsome evidence (such as a particular signal strength from a particular cell tower) that we call $E$ and we need\nto update all of our probabilities to be $\\p(B_i\n|E)$. We should use Bayes' Theorem!\nThe probability of the observation, assuming that the the phone is in location $B_i$, $\\p(E|B_i)$, is something that\ncan be given to you by an expert. In this case the probability of getting a particular signal strength given a\nlocation $B_i$ will be determined by the distance between the cell tower and location $B_i$\n.\nSince we are assuming that the phone must be in exactly one of the locations, we can find the probability of\nany of the event $B_i$ given $E$ by first applying Bayes' Theorem and then applying the general version of the law of\ntotal probability:\n$$\n\\begin{align}\n\\p(B_i | E) &= \\frac{\\p(E|B_i) \\cdot \\p(B_i)}{\\p(E)}\n&& \\text{Bayes Theorem. What to do about $\\p(E)$?} \\\\\n &= \\frac{\\p(E|B_i) \\cdot \\p(B_i)}{\\sum_{i=1}^n \\p(E|B_i) \\cdot \\p(B_i)}\n&& \\text{Use General Law of Total Probability for $\\p(E)$} \\\\\n\\end{align}\n$$\n\n\nUnknown Normalization Constant, $\\p(E)$\nThere are times when we would like to use Bayes' Theorem to update a belief, but we don't know the probability of $E$, $\\p(E)$. All hope is not lost. This term is called the \"normalization constant\" because it is the same regardless of whether or not the event $B$ happens. The most traditional solution is to use the law of total probability: $\\p(E) = \\p(E |B) \\p(B) + \\p(E|B\\c)\\p(B\\c)$. Here are some other useful \"tricks\" for dealing with $\\p(E)$. \n\n\tWe can make the normalization cancel out by calculating the ratio of $\\frac{\\p(B|E)}{\\p(B\\c|E)}$. This fraction tells you how many times more likely it is that $B$ will happen given $E$ than not $B$:\n$$\n\\begin{align}\n\\frac{\\p(B|E)}{\\p(B\\c|E)} \n&= \\frac{\n\t\\frac{\\p(E|B)\\p(B)}{\\p(E)}\n}{\n\t\\frac{\\p(E|B\\c)\\p(B\\c)}{\\p(E)}\n}\n&& \\text{Apply Bayes' Theorm to both terms} \\\\\n&= \\frac{\n\t\\p(E|B)\\p(B)\n}{\n\t\\p(E|B\\c)\\p(B\\c)\n}\n&& \\text{The term $\\p(E)$ cancels}\n\\end{align}\n$$\n\t\n\nWe can always use the fact that either $B$ will happen or it won't when consistently conditioned on $E$:  $\\p(B |E) + \\p(B\\c|E) =1$ to compute $\\p(E)$. Note that this is the simply the first identity of probability, consistently conditioning:\n$$\n\\begin{align}\n1 &= \\p(B|E) + \\p(B\\c|E) \n&& \\text{Either $B$ occurs or it doesn't} \\\\\n\n1 &= \\frac{\\p(E|B)\\p(B)}{\\p(E)}\n + \n\\frac{\\p(E|B\\c)\\p(B\\c)}{\\p(E)}\n&& \\text{Apply Bayes' Theorem to both terms}\n\\\\\n\n1 &= \\frac{1}{\\p(E)} \\cdot \\big[\\p(E|B)\\p(B) + \\p(E|B\\c)\\p(B\\c)\\big]\n&& \\text{Factor out $1/ \\p(E)$} \\\\\n\n\\p(E) &= \\p(E|B)\\p(B) + \\p(E|B\\c)\\p(B\\c)\n&& \\text{Rearrange terms}\n\\end{align}\n$$\nIf you look closely at the last line, you will notice that we have simply found a new way to derive the total law of probability for $E$. The law of total probability is truly a great way of dealing with $\\p(E)$.\n\t\n\n\n"}, {"id": "bayes_theorem", "title": "Bayes' Theorem", "url": "part1/bayes_theorem", "text": "\n\nExample: Probability of a disease given a noisy test\nIn this problem we are going to calculate the probability that a patient has an illness given test-result for the illness. A positive test result means the test thinks the patient has the illness. You know the following information, which is typical for medical tests:\n\nNatural % of population with illness:\n\nProbability of a positive result given the patient has illness\n\nProbability of a positive result given the patient does not have illness\n\n\nThe numbers in this example are from the Mamogram test for breast cancer. The seriousness of cancer underscores the potential for bayesian probability to be applied to important contexts. The natural occurence of breast cancer is 8%. The mamogram test returns a positive result 95% of the time for patients who have breast cancer. The test resturns a positive result 7% of the time for people who do not have breast cancer. In this demo you can enter different input numbers and it will reclaculate.\n\nAnswer\n\n\n\n\t\t\t\t  \tThe probability that the patient has the illness given a positive test result is: \n\n\n\n\nTerms:\n\t\t\t\t\t  \t\t\t\tLet $I$ be the event that the patient has the illness\n\t\t\t\t\t  \t\t\t\tLet $E$ be the event that the test result is positive\n\t\t\t\t\t  \t\t\t\t$\\p(I|E)$ = probability of the illness given a positive test. This is the number we want to calculate.\n\t\t\t\t\t  \t\t\t\t$\\p(E|I)$ = probability of a positive result given illness = \n\t\t\t\t\t  \t\t\t\t$\\p(E|I\\c)$ = probability of a positive result given no illness = \n\t\t\t\t\t  \t\t\t\t$\\p(I)$ = natural probability of the illness = \n\nBayes Theorem:\n\t\t\t\t\t  \t\n\t\t\t\t\t  \t\tIn this problem we know $\\p(E|I)$ and $\\p(E|I\\c)$ but we want to know $\\p(I|E)$. We can apply Bayes Theorem to turn our knowledge of one conditional into knowledge of the reverse.\n\t\t\t\t\t  \t\n\n\t\t\t\t\t  \t\t$$\\begin{align}\\p(I|E) &= \\frac{\\p(E|I)P(I)}{\\p(E|I)\\p(I) + \\p(E|I\\c)\\p(I\\c)} && \\text{Bayes' Theorem with Total Prob.}\\end{align}$$\n\t\t\t\t\t  \t\n\t\t\t\t\t  \t\tNow all we need to do is plug values into this formula. The only value we don't explicitly have is $\\p(I\\c)$. But we can simply calculate it since $\\p(I\\c) = 1 - \\p(I)$. Thus:\n\t\t\t\t\t\t\n\n\n\n\n\nNatural Frequency Intuition\n\n\t\t\t\t\t\t\tOne way to build intuition for Bayes Theorem is to think about \"natural frequences\". Let's take another approach at answer the probability question in the above example on belief of illness given a test. In this take, we are going to imagine we have a population of 1000 people. Let's think about how many of those have the illness and test positive and how many don't have the illness and test positive. This visualization is based off the numbers in the fields above. Feel free to change them!\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tThere are many possibilities for how many people have the illness, but one very plaussible number is 1000, the number of people in our population, multiplied by the probability of the disease.\n\n\t\t\t\t\t\t\t$1000 \\times \\p(\\text{Illness})$ people have the illness\n\t\t\t\t\t\t\t$1000 \\times (1- \\p(\\text{Illness}))$ people do not have the illness.\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tWe are going to color people who have the illness in blue and those without the illness in pink (those colors do not imply gender!). \n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tA certain number of people with the illness will test positive (which we will draw in Dark Blue) and a certain number of people without the illness will test positive (which we will draw in Dark Pink):\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\t$1000 \\times \\p(\\text{Illness}) \\times \\p(\\text{Positive}|\\text{Illness})$ people have the illness and test positive\n\t\t\t\t\t\t\t$1000 \\times \\p(\\text{Illness}\\c) \\times \\p(\\text{Positive}|\\text{Illness}\\c)$ people do not have the illness and test positive.\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tHere is the whole population of 1000 people:\n\t\t\t\t\t\t\n\n\n\n\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tThe number of people who test positive and have the illness is ?. \n\t\t\t\t\t\t\tThe number of people who test positive and don't have the illness is ?. \n\t\t\t\t\t\t\tThe total number of people who test positive is ?. \n\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tOut of the subset of people who test positive, the fraction that have the illness is ?/? = ? which is a close approximation of the answer. If instead of using 1000 imaginary people, we had used more, the approximation would have been even closer to the actual answer (which we calculated using Bayes Theorem).\n\t\t\t\t\t\t\n\n\n"}, {"id": "log_probabilities", "title": "Log Probabilities", "url": "part1/log_probabilities", "text": "\n \nLog Probabilities\n\nA log probability $\\log \\p(E)$ is simply the log function applied to a probability. For example if $\\p(E) = 0.00001$ then $\\log \\p(E) = \\log(0.00001) \\approx -11.51$. Note that in this book, the default base is the natural base $e$. There are many reasons why log probabilities are an essential tool for digital probability: (a) computers can be rather limited when representing very small numbers and (b) logs have the wonderful ability to turn multiplication into addition, and computers are much faster at addition. \nYou may have noticed that the log in the above example produced a negative number. Recall that $\\log b = c$, with the implied natural base $e$ is the same as the statement $e ^ c = b$. It says that $c$ is the exponent of $e$ that produces $b$. If $b$ is a number between 0 and 1, what power should you raise $e$ to in order to produce $b$? If you raise $e^0$ it produces 1. To produce a number less than 1, you must raise $e$ to a power less than 0. That is a long way of saying: if you take the log of a probability, the result will be a negative number.\n\n\t$$\n\t\\begin{align}\n\t0 &\\leq  \\p(E) \\leq 1 && \\text{Axiom 1 of probability} \\\\\n\t-\\infty &\\leq \\log \\p(E) \\leq 0 && \\text{Rule for log probabilities}\n\t\\end{align}\n$$\nProducts become Addition\n\nThe product of probabilities $\\p(E)$ and $\\p(F)$ becomes addition in logarithmic space:\n$$\n\\log (\\p(E) \\cdot \\p(F) ) = \\log \\p(E) + \\log \\p(F)\n$$\nThis is especially convenient because computers are much more efficient when adding than when multiplying. It can also make derivations easier to write. This is especially true when you need to multiply many probabilities together:\n\n$$\n\\log \\prod_i \\p(E_i) = \\sum_i \\log \\p(E_i)\n$$\n\n\nRepresenting Very Small Probabilities\n\nComputers have the power to process many events and consider the probability of very unlikely situations. While computers are capable of doing all the computation, the floating point representation means that computers can not represent decimals to perfect precision. In fact, python is unable to represent any probability smaller than 2.225e-308. On the other hand the log of that same number is -307.652 is very easy for a computer to store.\nWhy would you care? Often in the digital world, computers are asked to reason about the probability of data, or a whole dataset. For example, perhaps your data is words and you want to reason about the probability that a given author would write these specific words. While this probability is very small (we are talking about an exact document) it might be larger than the probability that a different author would write a specific document with specific words. For these sort of small probabilities, if you use computers, you would need to use log probabilities.\n\n\n\n\n"}, {"id": "enigma", "title": "Enigma Machine", "url": "examples/enigma", "text": "\n \nEnigma Machine\n\nOne of the very first computers was built to break the Nazi \u201cenigma\u201d codes in WW2. It was a hard problem\nbecause the \u201cenigma\u201d machine, used to make secret codes, had so many unique configurations. Every day the Nazi's would chose a new configuration and if they Allies could figure out the daily configuration, they could read all enemy messages. One solution was to try all configurations until one produced legible German. This begs the question: How many configurations are there?\n\n\n\nThe WW2 machine built to search different enigma configurations.\n\n\nThe enigma machine has three rotors. Each rotor can be set to one of 26 different positions. How many\nunique configurations are there of the three rotors?\n\n\n\t\tUsing the steps rule of counting: $26 \\cdot 26 \\cdot 26 = 26^3 = 17,576$.\n\t\n\nWhats more! The machine has a plug board which could swap the electrical signal for letters. On the plug\nboard, wires can connect any pair of letters to produce a new configuration. A wire can\u2019t connect a letter to itself. Wires are indistinct. A wire from \u2018K\u2019 to \u2019L\u2019\nis not considered distinct from a wire from \u2018L\u2019 to \u2019K\u2019.  We are going to work up to considering any number of wires.\n\n\n\nThe engima plugboard. For electical reasons each letter has two jacks and each plug has two prongs. Semantically this is equivalent to one plug location per letter.\n\n\nOne wire: How many ways are there to place exactly one wire that connects two letters? \n\n\n\t\tChosing 2 letters from 26 is a combination. Using the combination formula: ${26 \\choose 2} = 325$.\n\t\n\n Two wires: How many ways are there to place exactly two wires? Recall that wires are not\nconsidered distinct. Each letter can have at most one wire connected to it, thus you couldn\u2019t have a\nwire connect \u2018K\u2019 to \u2018L\u2019 and another one connect \u2018L\u2019 to \u2018X\u2019\n\n\n\t\t\nThere are ${26 \\choose 2}$\nways to place the first wire and\n${24 \\choose 2}$\nways to place the second wire. However,\nsince the wires are indistinct, we have double counted every possibility. Because every possibility is counted twice we should divide by 2:\n$$\n\\text{Total} = \\frac{ {26 \\choose 2} \\cdot {24 \\choose 2} }{2} = 44,850\n$$ \n\t\n\n Three wires: How many ways are there to place exactly three wires? \n\n\n\t\t\nThere are ${26 \\choose 2}$\nways to place the first wire and\n${24 \\choose 2}$\nways to place the second wire. There are now ${22 \\choose 2}$ ways to place the third. However,\nsince the wires are indistinct, and our step counting implicitly treats them as distinct, we have overcounted each possibility. How many times is each pairing of three letters overcounted? Its the number of permutations of three distinct objects: 3!\n$$\n\\text{Total} = \\frac{ {26 \\choose 2} \\cdot {24 \\choose 2} \\cdot {22 \\choose 2}}{3!} = 3,453,450\n$$ \n\nThere is another way to arrive at the same answer. First we are going to chose the letters to be paired, then we are going to pair them off. There are ${26 \\choose 6}$\nways to select the letters that are\nbeing wired up. We then need to pair off those letters. One way to think about pairing the\nletters off is to first permute them (6! ways) and then pair up the first two letters, the next two,\nthe next two, and so on. For example, if our letters were {A,B,C,D,E,F} and our permutation\nwas BADCEF, then this would correspond to wiring B to A and D to C and E to F. We are \novercounting by a lot. First, we are overcounting by a factor of 3! since the ordering of the pairs\ndoesn\u2019t matter. Second, we are overcounting by a factor of $2 ^ 3$\nsince the ordering of the letters\nwithin each pair doesn\u2019t matter.\n$$\n\\text{Total} = {26 \\choose 6} \\frac{6!}{3! \\cdot 2^3} = 3,453,450\n$$\n\t\n\n\nArbitrary wires: How many ways are there to place $k$ wires, thus connecting $2 \\cdot k$ letters? During WW2 the Germans always used a fixed number of wires. But one fear was that if they discovered the Enigma machine was cracked, they could simply use an arbitrary number of wires.\n\n\t\n\n\t\tThe set of ways to use exactly $i$ wires is mutually exclusive from the set of ways to use exactly $j$ wires if $i \\neq j$ (since no way can use both exactly $i$ and $j$ wires). As such\n$\n\\text{Total} = \\sum_{k=0}^{13} \\text{Total}_k \n$\nWhere Total$_k$ is the number of ways to use exactly $k$ wires. Continuing our logic for ways to used exact number of wires:\n$$\n\\text{Total}_k = \\frac{\\prod_{i=1}^{k} {28 - 2i \\choose 2} }{k!} \n$$\nBringing it all together:\n$$\n\\begin{align}\n\\text{Total} &= \\sum_{k=0}^{13} \\text{Total}_k \\\\\n&= \\sum_{k=0}^{13} \\frac{\\prod_{i=1}^{k} {28 - 2i \\choose 2} }{k!}  \\\\\n&= 532,985,208,200,576 \n\\end{align}\n$$\n\t\n\nThe actual Enigma used in ww2 had exactly 10 wires connecting 20 letters allowing for 150,738,274,937,250 unique configuration. The enigma machine also chose the three rotors from a set of five adding another factor of ${5 \\choose 3} = 60$.\n\nWhen you combine the number of ways of setting the rotars, with the number of ways you could set the plug board you get the total number of configurations of an enigma machine. Thinking of this as two steps we can multiply the two numbers we earlier calculated: 17,576 \u00b7 150,738,274,937,250 \u00b7 60  $\\approx 159 \\cdot 10^{18}$ unique settings. So, Alan Turing and his team at Blechly Park to build a machine which could help test many configurations -- a predecesor to the first computers. \n\n"}, {"id": "serendipity", "title": "Serendipity", "url": "examples/serendipity", "text": "\n \nSerendipity\n\n\n\n\n\n\n\n\n\n\nThe word serendipity comes from the  Persian fairy tale of the Three Princes of Serendip\n\n\n\n\nProblem\n\n\t\t\t\t\tWhat is the probability of a seredipitous encounter with a friend? Imagine you are live in an area with a large general population (eg Stanford with 17,000 students). A small subset of the population are friends. What are the chances that you run into at least one friend if you see a handful of people from the population? Assume that seeing each person from the population is equally likely.\n\t\t\t\t\n\n\n\n\n\nTotal Population\n\n\n\nFriends\n\n\n\nPeople that you see\n\n\nCalculate\n\nAnswer\n\n\t\t\t\t  \tThe probability that you see at least one friend is: \n\n\nTerms\n\n\n\t\t\t\t\t  \t\tFirst lets define some useful terms:\n\t\t\t\t\t  \t\t$p$ = total population = \n\t\t\t\t\t  \t\t$s$ = people seen = \n\t\t\t\t\t  \t\t$f$ = num friends = \n\n\nApproach\n\n\t\t\t\t\t  \t\tSince each way of seing $s$ people is equally likely, we can use the \"Equally Likely Events\" probability calculation: \n\t\t\t\t\t  \t\n\n\t\t\t\t\t  \t\t$P(E) = \\frac{|E|}{|S|}$\n\t\t\t\t\t  \t\n\t\t\t\t\t  \t\tWhere $S$ is the sample set (all the ways of seing $s$ people) and $E$ is the event set (all the ways of seing $s$ people where at least one is a friend).\n\t\t\t\t\t  \t\n\n\t\t\t\t\t\t\tOne way to approach this problem is to directly count all ways you see 1 or more friends. That is hard. You would have to count the ways you could see exactly one friend, then exactly two friends and so on. It is much easier to calculate the ways that you see zero friends. If we can calculate the probability of seeing zero friends our answer is just one minus that number.\n\t\t\t\t\t\t\n\nProb that you don't see friends\n\n\t\t\t\t\t\t\tLet the sample space ($S$) be the set of ways that you could see $s$ people. The size of the sample space is: the total population choose the number of people seen. \n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tThe event space ($E$) is the set of ways that you could see no friends. The size of the event space is: the number of non friends (aka population - friends) choose the number of people seen.\n\t\t\t\t\t\t\nThus the probability of not seeing a friend is:\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\t$\\text{prob(not seen)} = \\frac{ \\left( {\\begin{array}{*{20}c} p - f \\\\ s \\\\ \\end{array}} \\right) } { \\left( {\\begin{array}{*{20}c} p \\\\ s \\\\ \\end{array}} \\right) } $\n\t\t\t\t\t\t\n\nProb that you see friends\n\n\t\t\t\t\t\t\tNow the probability that you see at least one friend is 1 minus the probability that you see no friends.\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\t$\\text{prob(seen)} = 1 - \\frac{ \\left( {\\begin{array}{*{20}c} p - f \\\\ s \\\\ \\end{array}} \\right) } { \\left( {\\begin{array}{*{20}c} p \\\\ s \\\\ \\end{array}} \\right) } $\n\t\t\t\t\t\t\nThat is equal to \n\n\nIsn't that suprising?\n\n\n\n\n\n"}, {"id": "bacteria_evolution", "title": "Bacteria Evolution", "url": "examples/bacteria_evolution", "text": "\n \nBacteria Evolution\n\nA wonderful property of modern life is that we have anti-biotics to kill bacterial infections. However, we only have a fixed number of anti-biotic medicines, and bacteria are evolving to become resistent to our anti-biotics. In this example we are going to use probability to understand evolution of anti-biotic resistence in bacteria.\nImagine you have a population of 1 million infectious bacteria in your gut, 10% of which have a mutation that makes them\nslightly more resistant to anti-biotics. You take a course of anti-biotics. The probability that bacteria with the\nmutation survives is 20%. The probability that bacteria without the mutation survives is 1%.\nWhat is the probability that a randomly chosen bacterium\nsurvives the anti-biotics?\n\n\n\tLet $E$ be the event that our bacterium survives. Let $M$ be the event that a bacteria has the mutataion. By the By Law of Total Probability (LOTP):\n\t$$\n\t\\begin{align}\n\t\\p(E) \n\t\t&= \\p(E \\and M) + \\p(E \\and M\\c)\n\t\t\t&& \\text{LOTP} \\\\ \n\t\t&= \\p(E | M)\\p(M) + \\p(E | M\\c)\\p(M\\c)\n\t\t\t&& \\text{Chain Rule} \\\\ \t\n\t\t&= 0.20 \\cdot 0.10 + 0.01 \\cdot 0.90 \n\t\t\t&& \\text{Substituting} \\\\ \n\t\t&= 0.029\n\t\\end{align}\n\t$$\n\n\nWhat is the probability that a surviving bacterium has the mutation?\n\n\n\tUsing the same events in the last section, this question is asking for $\\p(M | E)$. We aren't givin the conditional probability in that direction, instead we know $P(E|M)$. Such situations call for Bayes' Theorem:\n\t$$\n\t\\begin{align}\n\t\\p(M | E) \n\t\t&=  \\frac{\\p(E|M)\\p(M)}{\\p(E)} \n\t\t\t&& \\text{Bayes} \\\\\n\t\t&=  \\frac{0.20 \\cdot 0.10}{\\p(E)} \n\t\t\t&& \\text{Given} \\\\\n\t\t&=  \\frac{0.20 \\cdot 0.10}{0.029} \n\t\t\t&& \\text{Calculated} \\\\\n\t\t&\\approx  0.69\n\t\\end{align}\n\t$$\n\n\nAfter the course of anti-biotics, 69% of bacteria have the mutation, up from 10% before. If this population is allowed to reproduce you will have a much more resistent set of bacteria!\n"}, {"id": "many_flips", "title": "Many Coin Flips", "url": "examples/many_flips", "text": "\n \nMany Coin Flips\n\nIn this section we are going to consider the number of heads on $n$ coin flips. This thought experiment is going to be a basis for much probability theory! It goes far beyond coin flips.\nSay a coin comes up heads with probability $p$. Most coins are fair and as such come up heads with probability $p=0.5$. There are many events for which coin flips are a great analogy that have different values of $p$ so lets leave $p$ as a variable. You can try simulating coins here. Note that H is short for Heads and T is short for Tails. We think of each coin as distinct:\n\n\n\n\tLet's explore a few probability questions in this domain.\n\nWarmups\n\nWhat is the probability that all $n$ flips are heads?\n\n\n\t\tLets say $n=10$ this question is asking what is the probability of getting:\n\t\tH, H, H, H, H, H, H, H, H, H\n\t\t\n\t\tEach coin flip is independent so we can use the rule for probability of and with independent events. As such, the probability of $n$ heads is  $p$ multiplied by itself $n$ times: $p^n$. If $n=10$ and $p=0.6$ then the probability of $n$ heads is around 0.006.\n\t\n\n\nWhat is the probability that all $n$ flips are tails?\n\n\n\t\tLets say $n=10$ this question is asking what is the probability of getting:\n\t\tT, T, T, T, T, T, T, T, T, T\n\t\t\n\t\tEach coin flip is independent. The probability of tails on any coin flip is $1-p$. Again, since the coin flips are independent, the probability of tails $n$ times on $n$ flips is $(1-p)$ multiplied by itself $n$ times: $(1-p)^n$. If $n=10$ and $p=0.6$ then the probability of $n$ tails is around 0.0001.\n\t\n\n\nFirst $k$ heads then $n-k$ tails\n\n\n\t\tLets say $n=10$ and $k=4$, this question is asking what is the probability of getting:\n\t\tH, H, H, H, T, T, T, T, T, T\n\t\t\n\t\tThe coins are still independent! The first $k$ heads occur with probability $p^k$ the run of $n-k$ tails occurs with probability $(1-p)^{n-k}$. The probability of $k$ heads then $n-k$ tails is the product of those two terms: $p^k \\cdot (1-p)^{n-k}$\n\t\n\nExactly $k$ heads\nNext lets try to figure out the probability of exactly $k$ heads in the $n$ flips. Importantly we don't care where in the $n$ flips that we get the heads, as long as there are $k$ of them. Note that this question is different than the question of first $k$ heads and then $n-k$ tails which requires that the $k$ heads come first! That particular result does generate exactly $k$ coin flips, but there are others.\nThere are many others! In fact any permutation of $k$ heads and $n-k$ tails will satisfy this event. Lets ask the computer to list them all for exactly $k=4$ heads within $n=10$ coin flips. The output region is scrollable:\n\n(H, H, H, H, T, T, T, T, T, T)\n(H, H, H, T, H, T, T, T, T, T)\n(H, H, H, T, T, H, T, T, T, T)\n(H, H, H, T, T, T, H, T, T, T)\n(H, H, H, T, T, T, T, H, T, T)\n(H, H, H, T, T, T, T, T, H, T)\n(H, H, H, T, T, T, T, T, T, H)\n(H, H, T, H, H, T, T, T, T, T)\n(H, H, T, H, T, H, T, T, T, T)\n(H, H, T, H, T, T, H, T, T, T)\n(H, H, T, H, T, T, T, H, T, T)\n(H, H, T, H, T, T, T, T, H, T)\n(H, H, T, H, T, T, T, T, T, H)\n(H, H, T, T, H, H, T, T, T, T)\n(H, H, T, T, H, T, H, T, T, T)\n(H, H, T, T, H, T, T, H, T, T)\n(H, H, T, T, H, T, T, T, H, T)\n(H, H, T, T, H, T, T, T, T, H)\n(H, H, T, T, T, H, H, T, T, T)\n(H, H, T, T, T, H, T, H, T, T)\n(H, H, T, T, T, H, T, T, H, T)\n(H, H, T, T, T, H, T, T, T, H)\n(H, H, T, T, T, T, H, H, T, T)\n(H, H, T, T, T, T, H, T, H, T)\n(H, H, T, T, T, T, H, T, T, H)\n(H, H, T, T, T, T, T, H, H, T)\n(H, H, T, T, T, T, T, H, T, H)\n(H, H, T, T, T, T, T, T, H, H)\n(H, T, H, H, H, T, T, T, T, T)\n(H, T, H, H, T, H, T, T, T, T)\n(H, T, H, H, T, T, H, T, T, T)\n(H, T, H, H, T, T, T, H, T, T)\n(H, T, H, H, T, T, T, T, H, T)\n(H, T, H, H, T, T, T, T, T, H)\n(H, T, H, T, H, H, T, T, T, T)\n(H, T, H, T, H, T, H, T, T, T)\n(H, T, H, T, H, T, T, H, T, T)\n(H, T, H, T, H, T, T, T, H, T)\n(H, T, H, T, H, T, T, T, T, H)\n(H, T, H, T, T, H, H, T, T, T)\n(H, T, H, T, T, H, T, H, T, T)\n(H, T, H, T, T, H, T, T, H, T)\n(H, T, H, T, T, H, T, T, T, H)\n(H, T, H, T, T, T, H, H, T, T)\n(H, T, H, T, T, T, H, T, H, T)\n(H, T, H, T, T, T, H, T, T, H)\n(H, T, H, T, T, T, T, H, H, T)\n(H, T, H, T, T, T, T, H, T, H)\n(H, T, H, T, T, T, T, T, H, H)\n(H, T, T, H, H, H, T, T, T, T)\n(H, T, T, H, H, T, H, T, T, T)\n(H, T, T, H, H, T, T, H, T, T)\n(H, T, T, H, H, T, T, T, H, T)\n(H, T, T, H, H, T, T, T, T, H)\n(H, T, T, H, T, H, H, T, T, T)\n(H, T, T, H, T, H, T, H, T, T)\n(H, T, T, H, T, H, T, T, H, T)\n(H, T, T, H, T, H, T, T, T, H)\n(H, T, T, H, T, T, H, H, T, T)\n(H, T, T, H, T, T, H, T, H, T)\n(H, T, T, H, T, T, H, T, T, H)\n(H, T, T, H, T, T, T, H, H, T)\n(H, T, T, H, T, T, T, H, T, H)\n(H, T, T, H, T, T, T, T, H, H)\n(H, T, T, T, H, H, H, T, T, T)\n(H, T, T, T, H, H, T, H, T, T)\n(H, T, T, T, H, H, T, T, H, T)\n(H, T, T, T, H, H, T, T, T, H)\n(H, T, T, T, H, T, H, H, T, T)\n(H, T, T, T, H, T, H, T, H, T)\n(H, T, T, T, H, T, H, T, T, H)\n(H, T, T, T, H, T, T, H, H, T)\n(H, T, T, T, H, T, T, H, T, H)\n(H, T, T, T, H, T, T, T, H, H)\n(H, T, T, T, T, H, H, H, T, T)\n(H, T, T, T, T, H, H, T, H, T)\n(H, T, T, T, T, H, H, T, T, H)\n(H, T, T, T, T, H, T, H, H, T)\n(H, T, T, T, T, H, T, H, T, H)\n(H, T, T, T, T, H, T, T, H, H)\n(H, T, T, T, T, T, H, H, H, T)\n(H, T, T, T, T, T, H, H, T, H)\n(H, T, T, T, T, T, H, T, H, H)\n(H, T, T, T, T, T, T, H, H, H)\n(T, H, H, H, H, T, T, T, T, T)\n(T, H, H, H, T, H, T, T, T, T)\n(T, H, H, H, T, T, H, T, T, T)\n(T, H, H, H, T, T, T, H, T, T)\n(T, H, H, H, T, T, T, T, H, T)\n(T, H, H, H, T, T, T, T, T, H)\n(T, H, H, T, H, H, T, T, T, T)\n(T, H, H, T, H, T, H, T, T, T)\n(T, H, H, T, H, T, T, H, T, T)\n(T, H, H, T, H, T, T, T, H, T)\n(T, H, H, T, H, T, T, T, T, H)\n(T, H, H, T, T, H, H, T, T, T)\n(T, H, H, T, T, H, T, H, T, T)\n(T, H, H, T, T, H, T, T, H, T)\n(T, H, H, T, T, H, T, T, T, H)\n(T, H, H, T, T, T, H, H, T, T)\n(T, H, H, T, T, T, H, T, H, T)\n(T, H, H, T, T, T, H, T, T, H)\n(T, H, H, T, T, T, T, H, H, T)\n(T, H, H, T, T, T, T, H, T, H)\n(T, H, H, T, T, T, T, T, H, H)\n(T, H, T, H, H, H, T, T, T, T)\n(T, H, T, H, H, T, H, T, T, T)\n(T, H, T, H, H, T, T, H, T, T)\n(T, H, T, H, H, T, T, T, H, T)\n(T, H, T, H, H, T, T, T, T, H)\n(T, H, T, H, T, H, H, T, T, T)\n(T, H, T, H, T, H, T, H, T, T)\n(T, H, T, H, T, H, T, T, H, T)\n(T, H, T, H, T, H, T, T, T, H)\n(T, H, T, H, T, T, H, H, T, T)\n(T, H, T, H, T, T, H, T, H, T)\n(T, H, T, H, T, T, H, T, T, H)\n(T, H, T, H, T, T, T, H, H, T)\n(T, H, T, H, T, T, T, H, T, H)\n(T, H, T, H, T, T, T, T, H, H)\n(T, H, T, T, H, H, H, T, T, T)\n(T, H, T, T, H, H, T, H, T, T)\n(T, H, T, T, H, H, T, T, H, T)\n(T, H, T, T, H, H, T, T, T, H)\n(T, H, T, T, H, T, H, H, T, T)\n(T, H, T, T, H, T, H, T, H, T)\n(T, H, T, T, H, T, H, T, T, H)\n(T, H, T, T, H, T, T, H, H, T)\n(T, H, T, T, H, T, T, H, T, H)\n(T, H, T, T, H, T, T, T, H, H)\n(T, H, T, T, T, H, H, H, T, T)\n(T, H, T, T, T, H, H, T, H, T)\n(T, H, T, T, T, H, H, T, T, H)\n(T, H, T, T, T, H, T, H, H, T)\n(T, H, T, T, T, H, T, H, T, H)\n(T, H, T, T, T, H, T, T, H, H)\n(T, H, T, T, T, T, H, H, H, T)\n(T, H, T, T, T, T, H, H, T, H)\n(T, H, T, T, T, T, H, T, H, H)\n(T, H, T, T, T, T, T, H, H, H)\n(T, T, H, H, H, H, T, T, T, T)\n(T, T, H, H, H, T, H, T, T, T)\n(T, T, H, H, H, T, T, H, T, T)\n(T, T, H, H, H, T, T, T, H, T)\n(T, T, H, H, H, T, T, T, T, H)\n(T, T, H, H, T, H, H, T, T, T)\n(T, T, H, H, T, H, T, H, T, T)\n(T, T, H, H, T, H, T, T, H, T)\n(T, T, H, H, T, H, T, T, T, H)\n(T, T, H, H, T, T, H, H, T, T)\n(T, T, H, H, T, T, H, T, H, T)\n(T, T, H, H, T, T, H, T, T, H)\n(T, T, H, H, T, T, T, H, H, T)\n(T, T, H, H, T, T, T, H, T, H)\n(T, T, H, H, T, T, T, T, H, H)\n(T, T, H, T, H, H, H, T, T, T)\n(T, T, H, T, H, H, T, H, T, T)\n(T, T, H, T, H, H, T, T, H, T)\n(T, T, H, T, H, H, T, T, T, H)\n(T, T, H, T, H, T, H, H, T, T)\n(T, T, H, T, H, T, H, T, H, T)\n(T, T, H, T, H, T, H, T, T, H)\n(T, T, H, T, H, T, T, H, H, T)\n(T, T, H, T, H, T, T, H, T, H)\n(T, T, H, T, H, T, T, T, H, H)\n(T, T, H, T, T, H, H, H, T, T)\n(T, T, H, T, T, H, H, T, H, T)\n(T, T, H, T, T, H, H, T, T, H)\n(T, T, H, T, T, H, T, H, H, T)\n(T, T, H, T, T, H, T, H, T, H)\n(T, T, H, T, T, H, T, T, H, H)\n(T, T, H, T, T, T, H, H, H, T)\n(T, T, H, T, T, T, H, H, T, H)\n(T, T, H, T, T, T, H, T, H, H)\n(T, T, H, T, T, T, T, H, H, H)\n(T, T, T, H, H, H, H, T, T, T)\n(T, T, T, H, H, H, T, H, T, T)\n(T, T, T, H, H, H, T, T, H, T)\n(T, T, T, H, H, H, T, T, T, H)\n(T, T, T, H, H, T, H, H, T, T)\n(T, T, T, H, H, T, H, T, H, T)\n(T, T, T, H, H, T, H, T, T, H)\n(T, T, T, H, H, T, T, H, H, T)\n(T, T, T, H, H, T, T, H, T, H)\n(T, T, T, H, H, T, T, T, H, H)\n(T, T, T, H, T, H, H, H, T, T)\n(T, T, T, H, T, H, H, T, H, T)\n(T, T, T, H, T, H, H, T, T, H)\n(T, T, T, H, T, H, T, H, H, T)\n(T, T, T, H, T, H, T, H, T, H)\n(T, T, T, H, T, H, T, T, H, H)\n(T, T, T, H, T, T, H, H, H, T)\n(T, T, T, H, T, T, H, H, T, H)\n(T, T, T, H, T, T, H, T, H, H)\n(T, T, T, H, T, T, T, H, H, H)\n(T, T, T, T, H, H, H, H, T, T)\n(T, T, T, T, H, H, H, T, H, T)\n(T, T, T, T, H, H, H, T, T, H)\n(T, T, T, T, H, H, T, H, H, T)\n(T, T, T, T, H, H, T, H, T, H)\n(T, T, T, T, H, H, T, T, H, H)\n(T, T, T, T, H, T, H, H, H, T)\n(T, T, T, T, H, T, H, H, T, H)\n(T, T, T, T, H, T, H, T, H, H)\n(T, T, T, T, H, T, T, H, H, H)\n(T, T, T, T, T, H, H, H, H, T)\n(T, T, T, T, T, H, H, H, T, H)\n(T, T, T, T, T, H, H, T, H, H)\n(T, T, T, T, T, H, T, H, H, H)\n(T, T, T, T, T, T, H, H, H, H)\nExactly how many outcomes are there with $k=4$ heads in $n=10$ flips? 210. The answer can be calculated using permutations of indistinct objects: $$N = \\frac{n!}{k! (n-k)!} = {n \\choose k}$$\n\nThe probability of exactly $k=4$ heads is the probability of the or of each of these outcomes. Because we consider each coin to be unique, each of these outcomes is \"mutually exclusive\" and as such if $E_i$ is the outcome from the $i$th row, $$\\p(\\text{exactly $k$ heads}) = \\sum_{i=1}^N \\p(E_i)$$\nThe next question is, what is the probability of each of these outcomes?\nHere is a arbitrarily chosen outcome which satisfies the event of exactly $k=4$ heads in $n=10$ coin flips. In fact it is the one on row 128 in the list above:\n\n\tT, H, T, T, H, T, T, H, H, T\nWhat is the probability of getting the exact sequence of heads and tails in the example above? Each coin flip is still independent, so we multiply $p$ for each heads and $1-p$ for each tails. Let $E_{128}$ be the event of this exact outcome:\n\t$$\\p(E_{128}) = (1-p) \\cdot p \\cdot (1-p) \\cdot (1-p) \\cdot p \\cdot (1-p) \\cdot (1-p) \\cdot p \\cdot p \\cdot (1-p)$$\nIf you rearrange these multiplication terms you get:\n\t$$\n\t\\begin{align}\n\t\\p(E_{128}) &= p \\cdot p \\cdot p \\cdot p \\cdot (1-p) \\cdot (1-p) \\cdot (1-p) \\cdot (1-p) \\cdot (1-p) \\cdot (1-p)\\\\\n\t&= p^4 \\cdot (1-p)^{6}\n\t\\end{align}\n\t$$\nThere is nothing too special about row 128. If you chose any row, you would get $k$ independent heads and $n-k$ independent tails. For any row $i$, $\\p(E_i) = p^n \\cdot (1-p)^{k-n}$. Now we are ready to calculate the probability of exactly $k$ heads:\n\n$$\n\\begin{align}\n\\p(\\text{exactly $k$ heads}) \n\t&= \\sum_{i=1}^N \\p(E_i) && \\text{Mutual Exclusion}\\\\\n\t&= \\sum_{i=1}^N p^k \\cdot (1-p)^{n-k} && \\text{Sub in }\\p(E_i) \\\\\n\t&= N \\cdot p^k \\cdot (1-p)^{n-k} && \\text{Sum $N$ times}  \\\\\n\t&= {n \\choose k} \\cdot p^k \\cdot (1-p)^{n-k} && \\text{Perm of indistinct objects} \n\\end{align}$$\n\nMore than $k$ heads\n\n\tYou can use the formula for exactly $k$ heads to compute other probabilities. For example the probability of more than $k$ heads is:\n\t$$\n\\begin{align}\n\\p(\\text{more than $k$ heads}) \n\t&= \\sum_{i=k+1}^n \\p(\\text{exactly $i$ heads}) && \\text{Mutual Exclusion}\\\\\n\t&= \\sum_{i=k+1}^n {n \\choose i} \\cdot p^i \\cdot (1-p)^{n-i} && \\text{Substitution}\\\\\n\\end{align}$$\n\t\n\n"}, {"id": "many_flips", "title": "Many Coin Flips", "url": "examples/many_flips", "text": "\nCoin Flip Simulator\n\n\nNumber of flips $n$: \n\n\nProbability of heads $p$: \n\n\nNew simulation\n\n\nSimulator results:\n\nTotal number of heads: \n\n\n"}, {"id": "rvs", "title": "Random Variables", "url": "part2/rvs", "text": "\n \nRandom Variables\n\n\nA Random Variables (RV) is a variable that probabilistically takes on a value and they are one of the most important constructs in all of probability theory. You can think of an RV as\nbeing like a variable in a programming language, and in fact random variables are just as important to probability theory as variables are to programming. Random Variables take on values, have types and have domains over\nwhich they are applicable.\nRandom variables work with all of the foundational theory we have build up to this point. We can define events that occur if the random variable takes one values that satisfy\na numerical test (eg does the variable equal 5, is the variable less than 8).\n\nLets look at a first example of a random variable. Say we flip three fair coins. We can define a random variable Y to be the total number\nof \u201cheads\u201d on the three coins. We can ask about the probability of Y taking on different values using the\nfollowing notation:\n\n\n\n\n\nLet $Y$ be the number of heads on three coin flips\n\n\n$\\p(Y = 0)$ = 1/8 (T, T, T)\n\n\n$\\p(Y = 1)$ = 3/8 (H, T, T), (T, H, T), (T, T, H)\n\n\n$\\p(Y = 2)$ = 3/8 (H, H, T), (H, T, H), (T, H, H)\n\n\n$\\p(Y = 3)$ = 1/8 (H, H, H)\n\n\n$\\p(Y \u2265 4)$ = 0\n\n\n\n\nEven though we use the same notation for random variables and for events (both use capitol letters) they\nare distinct concepts. An event is a scenario, a random variable is an object. The scenario where a random\nvariable takes on a particular value (or range of values) is an event. When possible, I will try and use letters\nE,F,G for events and X,Y,Z for random variables.\nUsing random variables is a convenient notation technique that assists in decomposing problems. There are\nmany different types of random variables (indicator, binary, choice, Bernoulli, etc). The two main families of\nrandom variable types are discrete and continuous. Discrete random variables can only take on integer values. Continuous random variables can take on decimal values. We are going to develop our intuitions using discrete random variable and then introduce continuous.\nProperties of random variables\nThere are many properties of a random variable of any random variable some of which we will dive into extensively. Here is a brief summary. Each random variable has:\n\n\n\n\n\nProperty\nNotation Example\nDescription\n\n\n\nMeaning\n\nA semantic description of the random variable\n\n\nSymbol\n$X$\nA letter used to denote the random variable\n\n\nSupport or Range\n$\\{0, 1, \\dots, 3\\}$\nthe values the random variable can take on\n\n\nDistribution Function (PMF or PDF)\n$\\P(X=x)$\nA function which maps values the RV can take on to likelihood.\n\n\nExpectation\n$\\E[X]$\nA weighted average\n\n\nVariance\n$\\var(X)$\nA measure of spread\n\n\nStandard Deviation\n$\\std(X)$\nThe square root of variance\n\n\nMode\n\nThe most likely value of the random variable\n\n\n\nYou should set a goal of deeply understanding what each of these properties mean. There are many more properties than the ones in the table above: properties like entropy, median, skew, kertosis.\n\n\nRandom variables vs Events \n\nRandom variables and events are two different concepts. An event is an outcome, or a set of outcomes, to an experiment. A random variable is a more like an experiment -- it will take on an outcome eventually. Probabilities are over events, so if you want to talk about probability in the context of a random variable, you must construct an event. You can make events by using any of the Relational Operators: \n<, \u2264, >, \u2265, =, or \u2260 (not equal to). This is analogous to coding where you can use relational operators to create boolean expressions from numbers. \n\n\tLets continue our example of the random variable $Y$ which represents the number of heads on three coin flips. Here are some events using the variable $Y$:\n\t\n\t\n\n\nEventMeaningProbability Statement\n\n\n\n\n$Y= 1$$Y$ takes on the value 1 (there was one heads)$\\p(Y=1)$\n\n\n$Y< 2$$Y$ takes on 0 or 1 (note this $Y$ can't be negative)$\\p(Y<2)$\n\n\n$X > Y$$X$ takes on a value greater than the value $Y$ takes on.$\\p(X>Y)$\n\n\n$Y= k$$Y$ takes on a value represented by non-random variable $k$$\\p(Y = k)$\n\n\n\n\nYou will see many examples like this last one, $\\p(Y=k)$, in this text book as well as in scientific and math research papers. It allows us to talk about the likelihood of $Y$ taking on a value, in general. For example, later in this book we will derive that for three coin flips where $Y$ is the number of heads, the probability of getting exactly $y$ heads is:\n$$\n\\begin{align}\n\\P(Y = y) = \\frac{0.75}{y!(3-y)!} && \\text{If } 0 \\leq y \\leq 3\n\\end{align}\n$$\n\tThis statement above is a function which takes in a parameter $y$ as input and returns the numeric probability $\\P(Y=y)$ as output. This particular expression allows us to talk about the probability that the number of heads is 0, 1, 2 or 3 all in one expression. You can plug in any one of those values for $y$ to get the corresponding probability. It is customary to use lower-case symbols for non-random values. The use of an equals sign in the \"event\" can be confusing. For example what does this expression say $\\P(Y = 1) = 0.375$? It says that the probability that \"$Y$ takes on the value 4\" is 0.375. For discrete random variables this function is called the \"probability mass function\" and it is the topic of our next chapter.\n\n"}, {"id": "pmf", "title": "Probability Mass Functions", "url": "part2/pmf", "text": "\n \nProbability Mass Functions\n\nFor a random variable, the most important thing to know is: how likely is each outcome? For a discrete random variable, this information is called the  \"probability mass function\". The probability mass function (or PMF for short) provides the \"mass\" (aka amount) of \"probability\" for each possible assignment of the random variable. \nFormally, the probability mass function (PMF) is a mapping between the values that the random variable could take on and the probability of the random variable taking on said value. In mathematics,\nwe call associations functions. There are many different ways of representing functions: you can write an equation, you can make a graph, you can even store many samples in a list. Lets start by looking at PMFs as graphs where the x-axis is the values\nthat the random variable could take on and the y-axis is the probability of the random variable taking on said\nvalue.\nIn the following example, on the left we show a PMF, as a graph, for the random variable: $X$ = the value of a six sided die roll. On the right we show a constrasting example of a PMF for the ranom variable $X$ = value of the sum of two dice rolls:\n\n\n\n\n\n\n\n\n\nLeft: the PMF of a single 6 sided die roll. Right: the PMF of the sum of two dice rolls.\n\n\n\tThe sum of two dice example in the equally likely probability section.  Again, the information that is provided in these graphs is the likelihood of a random variable taking on different values. In the graph on the right, the value \"$6$\" on the x-axis is associated with the prbability 5/36 on the y-axis. This x-axis refers to the event \"the sum of two dice is 6\", or $Y=6$. The y-axis is saying that the probability of that event is $5/36$. In full: $\\p(Y=6) = 5/36$. The value \"$2$\" is associated with \"1/36\" which tells you that, $\\p(Y=2) = 1/36$, the probability that two dice sum to 2 is 1/36. There is no value associated with \"$1$\" because the sum of two dice can not be 1. If you find this notation confusing, revisit the random variables section.\n\t\n\n\t\tHere is the exact same information in equation form.  :\n\t\t\n\n\t\t\t\t$$\n\t\t\t\t\\begin{align}\n\t\t\t\t\\p(X=x) = \u2159 && \\text{if } 1 \\leq x \\leq 6\n\t\t\t\t\\end{align}\n\t\t\t\t$$\n\t\t\t\n\n\t\t\t\t$$\n\t\t\t\t\\p(Y=y) = \\begin{cases}\n\t\t\t\t\t(y-1)/36 && \\text{if } 1 \\leq y \\leq 7\\\\\n\t\t\t\t\t(13-y)/36 && \\text{if } 8 \\leq y \\leq 12 \n\t\t\t\t\\end{cases}\n\t\t\t\t$$\n\t\t\t\n\n\n\n\t\tAs a final example, here is the PMF for $Y$, the sum of two dice, in python code:\n\t\tdef pmf_sum_two_dice(y):\n    # Returns the probability that the sum of two dice is y\n    if y < 2 or y > 12:\n        return 0\n    if y <= 7:\n        return (y-1) / 36\n    else:\n        return (13-y) / 36\nNotation\n$\\p(Y=y)$ might feel like redundant notation. In probability research papers, and higher level work, mathemeticians often use the shorthand with only the value. They would often write $\\p(y)$ in place of $\\p(Y=y)$. This shorthand assumes that the random variable referred to is the capital version of the value, and that the probability event is that the random variable equals the value $y$. In this book we will often use the full form of the event $\\P(Y=y)$ but will occasionally use the shorthand $\\p(y)$.\nProbabilities Must Sum to 1\n\nFor a variable (call it $X$) to be a proper random variable it must be the case that if you summed up the values of $\\p(X = k)$ for all possible values $k$ that $X$ can take on, the result must be 1:\n$$\n\\sum_{k} \\p(X = k) = 1\n$$\nFor further undertanding lets derive why this is the case. A random variable taking on a value is an event (for example $X = 2$). Each of those events are mutually exclusive because a random variable will take on exactly one value.\n\n\n\nData to Histograms to Probability Mass Functions\nOne suprising way to store a likelihood function (recall that a PMF is the name of the likelihood function for discrete random variables) is simply a list of data. We simulated summing two die 10,000 times to make this example dataset:\n\n\nNote that this data, on its own, represents an approximation for the probability mass function. If you wanted to approximate $\\p(Y=5)$ you could simply count the number of times that \"5\" occurs in your data. This is an approximation based on the definition of probability. Here is the full histogram of the data, a count of times each value occurs:\n\n\n\n\n\nA normalized histogram (where each value is divided by the length of your data list) is an approximation of the PMF. For a dataset of discrete numbers, a histogram shows the count of each value (in this case $y$). By the definition of probability, if you divide this count by the number of experiments run, you arrive at a approximation of the probability of the event $\\p(Y=y)$. In our example, we have 10,000 elements in our dataset. The count of times that 3 occurs is 552. Note that:\n\t$$\\begin{align}\n\t\\frac{\\text{count}(Y=5)}{n} &= \\frac{552}{10000} = 0.0552 \\\\\n\t\\p(Y=5) &= \\frac{4}{36} = 0.0555\n\t\\end{align}\n\t$$\n\nIn this case, since we ran 10,000 trials, the histogram is a very good approximation of the PMF.\n\n\tWe use sum of dice as an example because it is easy to understand. Datasets in the real world often represent more exciting events. \n\n\n\n"}, {"id": "pmf", "title": "Probability Mass Functions", "url": "part2/pmf", "text": "[8, 4, 9, 7, 7, 7, 7, 5, 6, 8, 11, 5, 7, 7, 7, 6, 7, 8, 8, 9, 9, 4, 6, 7, 10, 12, 6, 7, 8, 9, 3, 7, 4, 9, 2, 8, 5, 8, 9, 6, 8, 7, 10, 7, 6, 7, 7, 5, 4, 6, 9, 5, 7, 4, 2, 11, 10, 11, 8, 4, 11, 9, 7, 10, 12, 4, 8, 5, 11, 5, 3, 9, 7, 5, 5, 5, 3, 8, 6, 11, 11, 2, 7, 7, 6, 5, 4, 6, 3, 8, 5, 8, 7, 6, 9, 4, 3, 7, 6, 6, 6, 5, 6, 10, 5, 9, 9, 8, 8, 7, 4, 8, 4, 9, 8, 5, 10, 10, 9, 7, 9, 7, 7, 10, 4, 7, 8, 4, 7, 8, 9, 11, 7, 9, 10, 10, 2, 7, 9, 4, 8, 8, 12, 9, 5, 11, 10, 7, 6, 4, 8, 9, 9, 6, 5, 6, 5, 6, 11, 7, 3, 10, 7, 3, 7, 7, 10, 3, 6, 8, 6, 8, 5, 10, 2, 7, 4, 8, 11, 9, 3, 4, 2, 8, 8, 6, 6, 12, 11, 10, 10, 10, 8, 4, 9, 4, 4, 6, 6, 7, 8, 2, 5, 7, 6, 9, 5, 5, 8, 4, 7, 7, 7, 6, 5, 6, 8, 6, 5, 7, 8, 4, 9, 8, 8, 9, 7, 2, 8, 3, 5, 5, 10, 7, 9, 12, 6, 4, 5, 7, 6, 4, 7, 6, 10, 3, 8, 5, 7, 7, 3, 6, 7, 7, 6, 6, 9, 12, 9, 10, 7, 10, 8, 10, 3, 9, 9, 4, 7, 8, 6, 8, 12, 5, 6, 2, 4, 4, 5, 5, 8, 7, 9, 10, 6, 7, 10, 7, 6, 8, 9, 8, 10, 3, 7, 8, 8, 8, 4, 7, 7, 8, 3, 8, 5, 9, 2, 8, 6, 11, 7, 8, 7, 6, 8, 5, 5, 3, 6, 7, 9, 7, 11, 5, 8, 2, 11, 9, 9, 7, 12, 8, 6, 9, 7, 7, 5, 7, 6, 9, 2, 5, 4, 11, 10, 4, 7, 11, 9, 8, 3, 9, 5, 5, 2, 6, 7, 8, 10, 5, 9, 4, 4, 4, 7, 6, 3, 5, 6, 4, 3, 12, 7, 7, 6, 7, 7, 4, 5, 7, 9, 3, 5, 7, 6, 11, 5, 6, 6, 8, 6, 4, 5, 7, 4, 6, 10, 3, 6, 5, 7, 6, 8, 10, 7, 7, 9, 3, 10, 9, 6, 8, 5, 9, 6, 6, 5, 3, 4, 10, 8, 10, 6, 8, 4, 7, 7, 7, 12, 5, 5, 7, 9, 5, 5, 7, 8, 7, 10, 5, 10, 7, 7, 7, 4, 7, 4, 9, 11, 8, 7, 6, 9, 7, 2, 4, 8, 4, 7, 3, 7, 8, 7, 11, 7, 5, 11, 10, 6, 7, 11, 4, 7, 5, 9, 6, 11, 6, 10, 10, 6, 10, 8, 10, 5, 5, 10, 6, 3, 7, 5, 6, 7, 12, 10, 4, 2, 6, 9, 9, 8, 7, 5, 5, 10, 7, 5, 10, 10, 6, 8, 8, 4, 6, 7, 8, 10, 4, 6, 11, 5, 3, 7, 5, 7, 12, 4, 8, 6, 11, 6, 8, 7, 11, 12, 11, 9, 8, 9, 6, 6, 2, 3, 4, 9, 3, 5, 8, 9, 7, 6, 8, 6, 4, 8, 7, 4, 6, 5, 3, 8, 4, 9, 12, 6, 9, 7, 9, 3, 8, 2, 8, 10, 5, 8, 5, 2, 3, 6, 6, 6, 9, 5, 4, 6, 5, 6, 5, 8, 10, 8, 7, 10, 9, 9, 5, 2, 11, 3, 10, 4, 9, 7, 11, 9, 2, 10, 4, 11, 5, 12, 11, 9, 8, 3, 8, 9, 5, 10, 8, 4, 6, 8, 8, 7, 6, 4, 6, 4, 9, 8, 8, 4, 7, 10, 8, 5, 6, 10, 7, 7, 3, 11, 8, 10, 9, 9, 4, 7, 10, 5, 7, 3, 4, 12, 5, 10, 12, 8, 6, 8, 4, 8, 6, 12, 5, 5, 7, 3, 2, 8, 4, 4, 10, 4, 8, 5, 5, 9, 12, 8, 5, 8, 11, 12, 5, 6, 8, 3, 7, 11, 11, 8, 4, 4, 3, 8, 11, 8, 5, 6, 11, 10, 7, 6, 6, 12, 5, 7, 5, 6, 8, 6, 8, 8, 7, 7, 5, 8, 8, 5, 10, 8, 7, 8, 7, 7, 5, 4, 7, 9, 11, 9, 8, 10, 7, 5, 6, 5, 11, 11, 9, 4, 9, 6, 6, 5, 6, 9, 7, 9, 6, 3, 6, 6, 4, 10, 12, 9, 7, 6, 7, 7, 3, 12, 7, 6, 11, 9, 7, 6, 5, 9, 8, 10, 6, 8, 6, 6, 8, 11, 7, 5, 9, 11, 3, 8, 8, 8, 9, 10, 7, 8, 7, 5, 5, 9, 8, 10, 11, 3, 6, 5, 10, 6, 7, 8, 4, 5, 4, 6, 8, 12, 10, 7, 9, 8, 7, 9, 4, 8, 7, 2, 8, 4, 3, 7, 11, 5, 4, 7, 8, 7, 8, 7, 7, 6, 4, 6, 12, 12, 7, 6, 11, 12, 10, 5, 6, 6, 5, 5, 9, 9, 8, 6, 9, 3, 11, 8, 6, 4, 8, 9, 6, 7, 9, 8, 9, 6, 6, 4, 2, 9, 8, 7, 9, 9, 3, 4, 8, 3, 8, 3, 10, 7, 7, 6, 8, 4, 5, 7, 10, 9, 8, 8, 3, 7, 6, 4, 2, 4, 3, 9, 12, 4, 9, 12, 8, 2, 9, 4, 11, 2, 6, 5, 3, 11, 4, 5, 5, 11, 4, 4, 12, 7, 4, 10, 10, 3, 8, 6, 4, 5, 6, 7, 7, 9, 3, 6, 10, 8, 3, 4, 6, 2, 6, 7, 8, 5, 8, 11, 9, 4, 8, 7, 5, 6, 11, 4, 8, 6, 6, 6, 10, 9, 4, 8, 8, 6, 9, 5, 6, 7, 7, 6, 8, 5, 10, 8, 7, 9, 6, 5, 8, 7, 8, 4, 5, 9, 10, 6, 5, 8, 8, 7, 7, 8, 5, 10, 7, 8, 5, 3, 8, 3, 9, 8, 7, 12, 7, 9, 11, 4, 4, 4, 6, 6, 8, 9, 9, 7, 7, 5, 11, 8, 8, 10, 11, 5, 7, 8, 8, 8, 7, 4, 6, 11, 11, 7, 12, 7, 11, 6, 9, 11, 6, 2, 2, 9, 7, 7, 7, 11, 9, 6, 7, 6, 7, 7, 7, 9, 8, 10, 10, 4, 7, 6, 9, 5, 7, 9, 5, 9, 5, 6, 8, 9, 10, 7, 4, 8, 5, 7, 5, 5, 9, 9, 4, 6, 4, 5, 3, 7, 8, 10, 3, 5, 11, 9, 12, 5, 8, 4, 7, 4, 7, 5, 5, 8, 4, 4, 9, 8, 7, 4, 5, 10, 9, 7, 7, 5, 8, 6, 12, 9, 7, 6, 10, 4, 7, 5, 5, 8, 5, 6, 7, 8, 9, 9, 7, 10, 8, 6, 8, 7, 5, 7, 6, 6, 5, 4, 8, 5, 3, 9, 3, 2, 9, 3, 6, 7, 7, 6, 6, 9, 6, 4, 6, 8, 5, 6, 6, 4, 8, 9, 9, 10, 7, 6, 4, 7, 4, 8, 11, 6, 7, 9, 6, 10, 6, 7, 5, 9, 6, 9, 5, 7, 5, 10, 5, 6, 7, 5, 10, 6, 8, 6, 5, 8, 4, 7, 9, 9, 7, 7, 5, 11, 7, 3, 4, 8, 6, 10, 6, 6, 6, 4, 11, 8, 5, 10, 11, 9, 8, 11, 10, 7, 9, 3, 9, 8, 8, 2, 3, 6, 11, 8, 7, 9, 12, 9, 7, 8, 5, 8, 10, 8, 9, 5, 4, 3, 8, 11, 5, 7, 5, 3, 9, 9, 7, 7, 8, 11, 7, 9, 6, 6, 10, 3, 9, 6, 7, 3, 6, 10, 5, 7, 6, 7, 6, 10, 8, 7, 4, 3, 9, 10, 5, 9, 7, 10, 2, 9, 8, 3, 7, 6, 7, 6, 5, 6, 8, 8, 11, 6, 8, 6, 6, 7, 6, 5, 6, 9, 4, 6, 6, 7, 5, 7, 4, 11, 4, 12, 6, 7, 12, 7, 5, 9, 7, 6, 5, 8, 7, 7, 6, 9, 2, 6, 4, 8, 5, 10, 7, 5, 10, 5, 6, 7, 5, 8, 10, 9, 2, 7, 4, 9, 8, 9, 7, 8, 7, 8, 5, 7, 7, 6, 9, 10, 5, 5, 6, 8, 8, 3, 4, 3, 6, 4, 9, 6, 6, 6, 8, 10, 3, 11, 5, 4, 5, 4, 8, 6, 4, 10, 8, 7, 7, 8, 8, 8, 12, 7, 6, 5, 6, 9, 6, 10, 5, 3, 6, 2, 8, 10, 10, 7, 9, 7, 7, 7, 8, 3, 6, 7, 6, 10, 8, 11, 8, 6, 5, 9, 6, 11, 9, 3, 10, 7, 7, 7, 6, 7, 9, 9, 9, 9, 10, 8, 11, 4, 6, 8, 7, 7, 10, 11, 7, 7, 7, 11, 7, 5, 10, 2, 7, 4, 3, 7, 8, 8, 4, 12, 2, 7, 5, 8, 9, 4, 9, 7, 3, 6, 8, 9, 6, 5, 4, 10, 7, 10, 9, 8, 2, 9, 7, 12, 7, 5, 6, 12, 7, 7, 5, 9, 9, 8, 8, 9, 5, 3, 8, 11, 9, 8, 8, 9, 8, 7, 6, 8, 7, 12, 7, 7, 4, 9, 10, 2, 6, 3, 5, 8, 4, 8, 7, 10, 11, 3, 6, 2, 9, 7, 12, 7, 9, 7, 9, 7, 8, 7, 3, 9, 6, 5, 10, 7, 6, 2, 9, 4, 7, 4, 7, 5, 8, 2, 5, 7, 9, 8, 10, 2, 7, 8, 9, 9, 6, 4, 10, 8, 3, 4, 5, 11, 7, 6, 8, 6, 12, 8, 8, 12, 9, 8, 7, 7, 7, 8, 3, 6, 5, 7, 7, 6, 10, 2, 8, 4, 5, 7, 8, 7, 8, 10, 12, 9, 8, 7, 9, 8, 10, 9, 9, 3, 10, 10, 8, 9, 8, 7, 11, 7, 8, 5, 7, 4, 5, 10, 7, 7, 8, 8, 5, 5, 7, 11, 11, 5, 6, 8, 8, 7, 7, 9, 5, 7, 7, 7, 9, 2, 4, 7, 9, 4, 8, 10, 7, 12, 12, 5, 2, 5, 8, 11, 7, 9, 7, 8, 7, 7, 6, 7, 10, 9, 6, 7, 2, 7, 4, 9, 8, 10, 7, 6, 4, 7, 4, 5, 7, 8, 8, 3, 8, 6, 7, 4, 11, 10, 8, 4, 12, 11, 8, 8, 3, 8, 11, 5, 4, 9, 6, 5, 8, 7, 10, 8, 12, 9, 8, 4, 7, 8, 8, 5, 9, 3, 5, 11, 6, 8, 6, 7, 11, 4, 7, 7, 7, 6, 7, 12, 9, 8, 11, 7, 7, 8, 9, 9, 6, 6, 2, 9, 6, 10, 12, 3, 4, 3, 9, 5, 7, 7, 6, 3, 6, 7, 7, 10, 11, 9, 10, 9, 10, 11, 4, 5, 12, 3, 6, 11, 3, 4, 8, 6, 9, 7, 9, 12, 9, 7, 6, 7, 10, 7, 4, 6, 5, 5, 11, 9, 8, 6, 6, 12, 4, 4, 8, 10, 12, 10, 5, 6, 4, 12, 7, 7, 7, 7, 7, 7, 8, 3, 6, 9, 3, 7, 6, 9, 7, 5, 7, 2, 12, 6, 7, 11, 9, 9, 4, 7, 11, 11, 6, 12, 3, 4, 11, 8, 8, 10, 3, 4, 4, 9, 8, 9, 7, 3, 5, 6, 9, 8, 4, 8, 3, 11, 4, 7, 7, 4, 9, 10, 8, 9, 11, 9, 5, 5, 12, 5, 9, 4, 5, 5, 10, 5, 9, 10, 8, 10, 11, 4, 4, 5, 9, 6, 7, 9, 7, 7, 8, 3, 6, 12, 7, 5, 6, 11, 5, 6, 7, 5, 10, 6, 9, 8, 7, 6, 6, 6, 2, 11, 10, 6, 10, 7, 5, 9, 7, 6, 6, 11, 9, 3, 2, 6, 6, 5, 11, 7, 7, 8, 2, 2, 9, 5, 6, 8, 2, 10, 9, 3, 7, 6, 4, 7, 8, 10, 6, 9, 2, 4, 7, 6, 9, 6, 10, 10, 8, 6, 7, 9, 7, 6, 8, 10, 10, 12, 6, 5, 4, 7, 7, 7, 11, 9, 3, 5, 11, 4, 10, 8, 7, 5, 8, 7, 3, 7, 5, 8, 7, 11, 11, 9, 5, 5, 6, 10, 9, 7, 7, 7, 10, 11, 4, 2, 7, 10, 10, 12, 5, 8, 6, 10, 9, 10, 6, 10, 10, 11, 8, 9, 6, 9, 8, 4, 8, 7, 7, 5, 6, 6, 5, 6, 2, 7, 3, 8, 7, 11, 10, 6, 7, 7, 6, 6, 3, 7, 10, 9, 6, 5, 8, 7, 2, 12, 5, 10, 8, 6, 5, 2, 4, 4, 4, 2, 6, 7, 6, 7, 7, 7, 7, 2, 7, 11, 3, 5, 5, 5, 10, 11, 7, 3, 9, 9, 3, 11, 7, 7, 7, 7, 8, 11, 10, 7, 7, 7, 7, 7, 9, 8, 4, 2, 5, 12, 8, 8, 3, 10, 10, 5, 5, 3, 9, 9, 8, 6, 6, 9, 5, 7, 11, 8, 7, 4, 9, 4, 9, 6, 5, 8, 5, 7, 9, 4, 10, 7, 5, 12, 5, 8, 7, 6, 7, 10, 5, 9, 7, 4, 6, 5, 6, 7, 7, 7, 7, 9, 10, 10, 6, 4, 5, 5, 6, 12, 12, 12, 10, 6, 8, 11, 8, 6, 8, 8, 10, 12, 8, 4, 8, 6, 9, 3, 5, 6, 8, 10, 8, 10, 8, 4, 8, 6, 9, 9, 6, 10, 10, 6, 9, 10, 7, 5, 6, 9, 2, 10, 9, 8, 9, 9, 12, 10, 7, 6, 8, 5, 5, 3, 7, 10, 6, 7, 8, 7, 7, 11, 8, 4, 8, 9, 11, 4, 7, 4, 4, 3, 5, 5, 10, 3, 10, 7, 8, 4, 5, 7, 4, 2, 11, 4, 9, 8, 3, 10, 8, 8, 5, 7, 10, 8, 6, 6, 8, 4, 6, 6, 7, 5, 6, 8, 5, 6, 6, 10, 10, 5, 7, 5, 6, 12, 2, 7, 6, 4, 8, 9, 8, 7, 6, 3, 11, 9, 2, 10, 5, 8, 8, 8, 2, 8, 5, 6, 4, 10, 3, 9, 6, 9, 9, 9, 8, 7, 4, 7, 8, 8, 12, 10, 4, 9, 7, 3, 5, 6, 3, 6, 5, 5, 4, 4, 7, 8, 10, 8, 10, 11, 6, 6, 11, 5, 7, 11, 4, 6, 2, 9, 10, 10, 11, 10, 7, 8, 5, 6, 11, 7, 10, 3, 6, 3, 2, 6, 8, 7, 3, 8, 7, 11, 11, 7, 6, 7, 11, 7, 5, 7, 6, 3, 11, 5, 6, 7, 9, 7, 8, 7, 8, 10, 7, 9, 3, 10, 7, 10, 12, 4, 6, 7, 3, 8, 7, 7, 10, 5, 6, 3, 6, 7, 7, 12, 6, 4, 7, 9, 4, 5, 6, 8, 7, 7, 10, 9, 4, 6, 7, 8, 4, 9, 9, 5, 10, 8, 2, 5, 3, 7, 5, 9, 4, 5, 9, 5, 10, 4, 5, 6, 7, 6, 8, 8, 10, 9, 10, 7, 7, 7, 5, 5, 3, 6, 8, 6, 5, 8, 6, 4, 7, 3, 9, 9, 8, 7, 8, 8, 7, 2, 3, 6, 12, 3, 7, 6, 8, 9, 7, 7, 6, 12, 5, 10, 10, 9, 7, 6, 4, 12, 5, 4, 10, 5, 9, 7, 5, 7, 6, 5, 7, 7, 6, 5, 10, 11, 6, 4, 10, 6, 7, 7, 5, 2, 7, 7, 6, 8, 8, 11, 6, 5, 6, 8, 9, 7, 8, 6, 7, 4, 6, 4, 7, 4, 7, 11, 5, 6, 9, 7, 3, 11, 9, 7, 7, 2, 6, 9, 8, 8, 6, 2, 8, 5, 5, 9, 10, 7, 8, 7, 7, 8, 11, 3, 7, 8, 7, 3, 3, 6, 9, 5, 7, 10, 4, 5, 9, 6, 6, 6, 11, 9, 9, 7, 10, 4, 9, 6, 11, 6, 3, 5, 4, 3, 11, 10, 7, 7, 4, 3, 7, 10, 11, 7, 3, 8, 5, 7, 9, 7, 4, 9, 4, 5, 5, 4, 8, 5, 8, 8, 7, 6, 7, 9, 7, 9, 7, 9, 2, 9, 11, 5, 3, 9, 9, 6, 5, 10, 8, 5, 5, 7, 4, 6, 9, 7, 5, 8, 8, 7, 5, 5, 7, 9, 3, 5, 5, 7, 10, 8, 6, 6, 10, 9, 5, 4, 12, 2, 10, 5, 7, 7, 6, 10, 5, 8, 4, 3, 8, 7, 7, 11, 7, 10, 10, 10, 6, 6, 3, 10, 8, 9, 7, 6, 12, 7, 6, 7, 5, 9, 6, 5, 9, 9, 5, 9, 9, 6, 5, 11, 8, 9, 6, 4, 5, 3, 3, 11, 5, 9, 7, 3, 10, 9, 12, 9, 2, 7, 10, 4, 10, 3, 3, 11, 2, 4, 8, 6, 6, 8, 12, 8, 12, 9, 6, 4, 8, 3, 3, 6, 6, 11, 9, 10, 8, 7, 11, 11, 9, 7, 7, 8, 9, 9, 6, 9, 7, 7, 11, 9, 4, 11, 9, 8, 8, 6, 6, 7, 10, 9, 2, 9, 6, 7, 11, 7, 2, 9, 5, 11, 5, 8, 8, 6, 8, 9, 8, 6, 6, 10, 4, 9, 3, 8, 6, 8, 12, 8, 7, 8, 7, 2, 8, 6, 6, 6, 5, 9, 5, 5, 10, 6, 8, 9, 4, 5, 7, 8, 9, 7, 5, 4, 5, 7, 5, 8, 11, 4, 7, 5, 5, 8, 5, 12, 9, 4, 3, 2, 7, 11, 8, 4, 9, 6, 5, 7, 7, 9, 7, 10, 4, 7, 12, 6, 3, 11, 5, 8, 9, 9, 6, 7, 3, 9, 9, 9, 5, 5, 7, 3, 8, 7, 2, 7, 7, 3, 7, 6, 5, 6, 8, 3, 6, 6, 4, 11, 9, 4, 6, 8, 5, 7, 7, 7, 4, 10, 11, 6, 7, 6, 7, 6, 8, 4, 5, 5, 7, 4, 6, 9, 6, 4, 7, 9, 10, 11, 3, 5, 5, 9, 2, 7, 11, 6, 7, 7, 9, 8, 9, 8, 4, 4, 4, 10, 6, 9, 8, 5, 5, 7, 8, 5, 6, 10, 5, 5, 4, 9, 8, 3, 9, 5, 12, 10, 4, 9, 12, 7, 10, 11, 3, 11, 10, 7, 5, 7, 7, 11, 6, 8, 6, 5, 12, 6, 8, 10, 4, 5, 4, 5, 5, 7, 7, 2, 5, 8, 5, 4, 8, 5, 6, 11, 10, 9, 6, 6, 4, 10, 9, 9, 7, 5, 10, 6, 8, 9, 3, 3, 7, 4, 8, 10, 9, 7, 6, 7, 5, 11, 6, 2, 7, 5, 9, 12, 5, 5, 2, 8, 5, 12, 4, 8, 4, 6, 7, 8, 6, 8, 9, 8, 6, 7, 6, 11, 4, 10, 2, 4, 4, 8, 3, 8, 2, 8, 5, 4, 4, 7, 6, 8, 10, 6, 4, 6, 5, 9, 5, 6, 10, 7, 6, 8, 7, 9, 7, 7, 4, 11, 9, 3, 8, 11, 4, 7, 6, 5, 8, 4, 5, 7, 11, 6, 7, 5, 8, 7, 7, 9, 5, 9, 4, 2, 9, 12, 6, 12, 7, 11, 6, 6, 7, 9, 4, 3, 3, 7, 6, 8, 6, 6, 9, 3, 6, 12, 5, 4, 3, 10, 8, 8, 7, 6, 12, 6, 10, 11, 3, 7, 9, 10, 11, 7, 11, 3, 8, 7, 9, 5, 9, 6, 7, 9, 3, 6, 3, 6, 7, 5, 8, 5, 8, 5, 9, 10, 3, 7, 8, 4, 8, 3, 7, 5, 7, 10, 5, 7, 11, 6, 2, 7, 7, 8, 7, 7, 7, 8, 4, 7, 4, 3, 7, 7, 9, 6, 8, 11, 3, 8, 6, 7, 4, 7, 10, 7, 7, 5, 8, 4, 7, 10, 6, 8, 12, 9, 6, 8, 6, 9, 4, 11, 7, 5, 5, 6, 6, 7, 7, 6, 12, 12, 5, 10, 6, 3, 6, 9, 7, 11, 6, 8, 5, 7, 9, 7, 3, 5, 6, 8, 9, 9, 8, 7, 6, 10, 7, 11, 8, 7, 7, 10, 6, 8, 9, 4, 7, 5, 7, 9, 8, 7, 11, 12, 3, 10, 12, 9, 7, 6, 8, 8, 5, 6, 9, 9, 6, 3, 8, 6, 4, 5, 9, 7, 8, 7, 7, 5, 9, 8, 8, 4, 8, 5, 7, 5, 11, 7, 10, 5, 4, 5, 6, 3, 3, 8, 10, 3, 8, 9, 7, 7, 7, 5, 11, 9, 7, 7, 7, 6, 4, 10, 5, 9, 2, 7, 9, 6, 6, 11, 10, 9, 4, 6, 5, 10, 9, 8, 6, 8, 9, 8, 10, 5, 5, 8, 9, 9, 7, 5, 7, 10, 11, 7, 6, 9, 6, 7, 10, 8, 7, 4, 11, 7, 8, 8, 7, 8, 6, 11, 12, 9, 9, 5, 7, 7, 7, 7, 2, 6, 7, 5, 9, 3, 4, 6, 6, 2, 5, 6, 4, 8, 11, 2, 8, 5, 7, 7, 6, 7, 6, 4, 7, 6, 3, 9, 9, 11, 7, 11, 7, 10, 8, 4, 5, 2, 7, 9, 8, 3, 7, 3, 5, 6, 8, 12, 11, 5, 2, 2, 5, 7, 12, 7, 6, 5, 5, 5, 8, 11, 12, 3, 6, 6, 6, 2, 7, 6, 3, 7, 4, 5, 8, 7, 4, 11, 7, 4, 11, 5, 9, 6, 10, 6, 6, 6, 8, 6, 12, 10, 5, 12, 4, 8, 5, 5, 8, 11, 9, 12, 4, 5, 4, 3, 7, 7, 6, 10, 4, 4, 7, 7, 6, 7, 8, 10, 8, 6, 9, 9, 4, 7, 8, 6, 8, 7, 6, 6, 7, 10, 11, 7, 5, 5, 3, 4, 11, 5, 4, 9, 9, 4, 6, 5, 5, 12, 9, 8, 10, 9, 12, 4, 4, 5, 10, 3, 6, 7, 5, 6, 9, 8, 9, 6, 6, 4, 7, 6, 6, 6, 6, 8, 7, 10, 8, 10, 12, 3, 11, 12, 7, 8, 7, 6, 2, 12, 7, 6, 10, 6, 8, 8, 8, 5, 10, 8, 9, 7, 7, 3, 8, 6, 10, 9, 4, 7, 7, 7, 9, 3, 7, 3, 4, 8, 7, 6, 12, 12, 12, 7, 2, 8, 4, 5, 3, 4, 11, 10, 6, 4, 11, 5, 6, 11, 2, 7, 9, 7, 7, 12, 6, 4, 7, 9, 7, 8, 7, 6, 7, 10, 5, 7, 9, 4, 7, 12, 5, 7, 8, 9, 9, 9, 10, 4, 10, 10, 6, 9, 9, 4, 6, 9, 9, 8, 7, 8, 7, 10, 8, 6, 5, 6, 6, 4, 10, 8, 10, 6, 11, 9, 7, 8, 11, 8, 5, 4, 10, 4, 6, 7, 9, 3, 6, 7, 7, 6, 10, 8, 7, 7, 5, 2, 4, 7, 7, 7, 8, 8, 10, 7, 7, 4, 7, 9, 10, 9, 6, 7, 8, 3, 4, 7, 8, 11, 9, 9, 9, 7, 11, 11, 10, 3, 9, 5, 10, 10, 7, 2, 7, 8, 8, 8, 8, 12, 10, 8, 9, 4, 7, 6, 6, 8, 2, 6, 10, 9, 7, 7, 7, 7, 12, 6, 2, 8, 7, 5, 5, 10, 11, 10, 6, 11, 9, 4, 8, 5, 12, 11, 4, 8, 6, 5, 8, 7, 6, 9, 11, 4, 8, 6, 8, 11, 8, 8, 6, 6, 3, 5, 3, 3, 7, 12, 7, 5, 7, 3, 6, 5, 8, 8, 5, 2, 7, 2, 11, 6, 2, 5, 9, 7, 9, 8, 10, 5, 5, 12, 6, 9, 4, 8, 9, 8, 6, 7, 4, 2, 5, 4, 4, 8, 6, 8, 10, 6, 9, 7, 9, 8, 8, 7, 2, 10, 8, 8, 9, 4, 3, 5, 11, 4, 7, 8, 4, 4, 11, 2, 3, 8, 7, 9, 9, 4, 8, 6, 6, 10, 8, 4, 7, 7, 9, 7, 4, 7, 8, 5, 4, 3, 9, 9, 3, 3, 10, 4, 6, 6, 9, 4, 9, 3, 10, 10, 7, 8, 10, 9, 10, 8, 5, 7, 10, 5, 11, 5, 8, 5, 3, 7, 6, 9, 8, 7, 8, 5, 7, 8, 7, 8, 4, 11, 6, 7, 6, 5, 3, 2, 6, 7, 2, 7, 6, 9, 8, 9, 6, 11, 10, 10, 8, 3, 6, 5, 6, 5, 4, 10, 5, 7, 7, 7, 3, 6, 8, 9, 4, 11, 6, 10, 11, 6, 6, 6, 4, 8, 8, 8, 6, 8, 7, 5, 7, 6, 8, 12, 5, 9, 9, 10, 11, 6, 9, 4, 8, 9, 8, 2, 2, 12, 8, 9, 9, 6, 5, 9, 8, 4, 11, 9, 8, 6, 11, 8, 5, 7, 7, 8, 4, 5, 7, 5, 9, 6, 6, 3, 7, 10, 7, 6, 7, 12, 4, 7, 6, 3, 5, 9, 9, 5, 6, 3, 5, 7, 6, 5, 8, 6, 10, 6, 7, 7, 2, 7, 7, 6, 8, 10, 9, 4, 9, 7, 9, 8, 8, 12, 4, 4, 4, 8, 7, 7, 5, 4, 8, 7, 6, 7, 5, 9, 10, 8, 8, 8, 8, 6, 8, 11, 7, 9, 5, 10, 3, 6, 5, 2, 6, 7, 7, 5, 10, 5, 8, 7, 8, 7, 11, 7, 7, 7, 6, 5, 7, 11, 9, 9, 4, 7, 2, 4, 9, 5, 4, 6, 11, 4, 6, 11, 7, 7, 6, 8, 6, 9, 9, 3, 11, 8, 11, 6, 2, 8, 6, 7, 5, 7, 10, 3, 4, 7, 4, 7, 6, 8, 4, 9, 5, 10, 11, 8, 7, 7, 7, 3, 10, 5, 2, 6, 9, 8, 6, 5, 5, 9, 7, 2, 2, 8, 8, 4, 8, 11, 8, 8, 7, 4, 9, 10, 3, 9, 12, 7, 9, 9, 7, 8, 7, 10, 5, 3, 7, 6, 8, 5, 10, 7, 11, 5, 10, 6, 10, 8, 7, 2, 8, 10, 4, 8, 9, 10, 4, 7, 8, 6, 3, 6, 7, 3, 4, 5, 9, 5, 8, 4, 10, 6, 4, 2, 6, 7, 3, 6, 5, 10, 6, 12, 3, 5, 6, 10, 9, 11, 3, 7, 5, 4, 8, 2, 10, 5, 6, 5, 10, 7, 9, 11, 7, 8, 10, 4, 5, 8, 7, 3, 5, 7, 7, 8, 8, 7, 10, 9, 11, 6, 8, 7, 5, 8, 5, 6, 8, 8, 4, 4, 3, 4, 8, 6, 2, 7, 3, 9, 4, 5, 7, 11, 10, 3, 3, 9, 6, 10, 7, 9, 4, 3, 7, 6, 6, 4, 3, 6, 8, 5, 11, 9, 7, 6, 10, 5, 8, 3, 9, 12, 11, 8, 7, 11, 2, 10, 5, 8, 7, 2, 10, 7, 7, 8, 9, 8, 3, 3, 4, 8, 9, 6, 5, 9, 9, 12, 9, 9, 8, 10, 7, 5, 8, 11, 11, 9, 5, 11, 4, 7, 9, 5, 7, 5, 6, 11, 4, 10, 9, 7, 11, 10, 5, 2, 6, 11, 12, 5, 7, 8, 6, 9, 5, 6, 4, 9, 9, 9, 6, 9, 7, 3, 7, 8, 5, 4, 3, 6, 12, 7, 10, 4, 6, 4, 4, 4, 8, 7, 9, 10, 3, 3, 7, 6, 11, 8, 8, 8, 5, 6, 5, 5, 4, 8, 7, 7, 7, 7, 6, 7, 6, 3, 7, 7, 9, 8, 12, 5, 7, 8, 3, 8, 5, 12, 10, 2, 10, 10, 5, 7, 8, 7, 9, 9, 7, 8, 8, 4, 2, 3, 10, 5, 9, 7, 7, 8, 9, 9, 8, 5, 6, 6, 4, 6, 7, 5, 7, 4, 6, 7, 8, 8, 11, 4, 10, 6, 6, 10, 7, 4, 10, 5, 5, 3, 2, 7, 5, 2, 4, 7, 8, 7, 6, 8, 10, 8, 8, 8, 8, 10, 5, 6, 4, 6, 4, 4, 3, 6, 9, 6, 8, 10, 5, 5, 12, 4, 8, 3, 2, 3, 12, 5, 4, 7, 9, 10, 4, 11, 11, 7, 8, 3, 10, 9, 11, 6, 9, 10, 7, 7, 5, 7, 9, 9, 9, 10, 5, 8, 9, 11, 8, 5, 7, 11, 9, 4, 6, 10, 11, 8, 6, 2, 9, 5, 8, 7, 6, 3, 7, 4, 10, 2, 8, 8, 5, 8, 11, 8, 3, 6, 6, 7, 9, 6, 8, 4, 4, 9, 12, 5, 6, 9, 6, 6, 6, 7, 8, 3, 6, 3, 12, 6, 5, 5, 8, 8, 6, 9, 6, 8, 9, 9, 7, 4, 8, 10, 8, 7, 4, 4, 9, 11, 7, 5, 6, 7, 8, 7, 7, 6, 7, 8, 9, 7, 7, 6, 6, 3, 11, 6, 5, 9, 6, 7, 4, 5, 6, 8, 11, 7, 9, 2, 7, 12, 7, 5, 5, 4, 5, 9, 9, 4, 5, 8, 5, 3, 4, 8, 7, 5, 9, 6, 2, 2, 9, 2, 6, 6, 6, 11, 11, 9, 11, 9, 7, 9, 4, 4, 7, 7, 5, 8, 4, 8, 10, 7, 9, 8, 4, 5, 7, 8, 3, 7, 7, 7, 4, 9, 3, 4, 7, 5, 6, 6, 12, 7, 7, 7, 6, 7, 9, 10, 8, 2, 6, 7, 11, 7, 6, 3, 8, 6, 8, 9, 7, 4, 8, 9, 11, 9, 7, 12, 7, 4, 7, 9, 11, 7, 6, 6, 8, 7, 9, 8, 5, 11, 7, 4, 7, 7, 9, 4, 4, 4, 8, 4, 6, 5, 5, 7, 10, 5, 2, 8, 10, 9, 4, 10, 6, 6, 10, 10, 5, 5, 4, 10, 2, 9, 4, 8, 5, 3, 3, 4, 8, 6, 8, 9, 8, 7, 4, 7, 12, 6, 6, 4, 8, 8, 3, 11, 10, 12, 11, 8, 7, 10, 7, 8, 7, 5, 6, 7, 11, 7, 8, 7, 7, 2, 11, 7, 8, 8, 11, 5, 8, 4, 7, 8, 8, 5, 3, 9, 4, 7, 4, 7, 9, 6, 5, 6, 3, 5, 5, 7, 6, 8, 10, 9, 6, 8, 8, 11, 9, 11, 11, 3, 3, 9, 8, 9, 9, 6, 5, 5, 12, 7, 6, 6, 9, 10, 7, 11, 7, 7, 10, 9, 5, 7, 7, 11, 9, 8, 3, 8, 6, 8, 8, 7, 12, 5, 10, 7, 11, 6, 7, 8, 8, 6, 8, 8, 2, 7, 5, 9, 5, 9, 9, 8, 12, 8, 8, 6, 2, 4, 5, 12, 9, 7, 9, 4, 6, 4, 3, 7, 5, 8, 9, 6, 5, 10, 10, 10, 7, 11, 4, 6, 7, 9, 10, 6, 11, 6, 5, 12, 7, 3, 11, 6, 4, 7, 8, 2, 7, 8, 6, 6, 8, 3, 2, 8, 6, 9, 5, 11, 8, 6, 9, 7, 10, 10, 10, 6, 5, 9, 4, 5, 8, 8, 6, 6, 6, 10, 4, 7, 7, 5, 7, 9, 12, 6, 7, 5, 5, 10, 7, 5, 4, 7, 6, 6, 5, 5, 8, 9, 7, 7, 7, 9, 9, 8, 9, 11, 11, 10, 5, 3, 8, 10, 9, 7, 11, 6, 12, 6, 3, 8, 6, 3, 11, 11, 9, 6, 5, 7, 9, 7, 9, 6, 8, 9, 3, 7, 9, 10, 8, 9, 9, 7, 6, 9, 7, 5, 5, 5, 3, 8, 10, 6, 10, 8, 10, 8, 4, 11, 4, 12, 6, 7, 3, 9, 5, 11, 5, 7, 4, 7, 8, 12, 9, 8, 10, 4, 4, 5, 6, 4, 5, 6, 7, 3, 3, 11, 8, 9, 2, 8, 4, 8, 7, 8, 9, 10, 5, 10, 7, 9, 8, 8, 6, 7, 5, 6, 11, 2, 5, 3, 8, 4, 7, 7, 4, 7, 2, 7, 10, 10, 7, 9, 3, 5, 8, 6, 4, 8, 7, 7, 6, 8, 6, 11, 7, 3, 6, 6, 6, 9, 11, 6, 5, 7, 3, 12, 7, 10, 4, 6, 7, 4, 11, 3, 3, 6, 6, 12, 11, 12, 10, 11, 7, 9, 7, 5, 12, 6, 3, 6, 4, 5, 10, 6, 11, 11, 7, 6, 8, 11, 5, 12, 4, 7, 9, 9, 9, 10, 7, 9, 7, 4, 4, 6, 8, 6, 3, 4, 9, 7, 11, 8, 6, 11, 5, 7, 11, 7, 7, 6, 4, 9, 12, 9, 8, 8, 8, 9, 6, 8, 5, 11, 6, 8, 6, 5, 8, 5, 8, 6, 11, 5, 8, 3, 7, 8, 8, 10, 9, 8, 9, 8, 4, 7, 9, 5, 8, 8, 9, 7, 3, 9, 3, 4, 6, 9, 9, 5, 6, 4, 8, 9, 7, 5, 10, 5, 8, 5, 5, 5, 8, 9, 3, 9, 10, 10, 6, 4, 6, 2, 6, 2, 8, 7, 4, 6, 6, 7, 9, 4, 6, 8, 5, 7, 7, 7, 9, 2, 6, 7, 3, 10, 10, 7, 3, 5, 3, 6, 6, 7, 12, 9, 9, 11, 9, 4, 4, 10, 8, 8, 9, 8, 4, 4, 6, 2, 7, 5, 7, 7, 10, 4, 11, 5, 7, 8, 8, 2, 8, 6, 9, 8, 7, 8, 8, 10, 4, 7, 10, 10, 10, 4, 6, 12, 11, 4, 9, 12, 2, 3, 5, 3, 3, 11, 7, 8, 8, 5, 10, 8, 9, 4, 7, 7, 2, 5, 10, 7, 10, 9, 9, 4, 7, 8, 9, 8, 7, 7, 6, 12, 2, 7, 11, 10, 8, 7, 9, 11, 7, 9, 6, 8, 9, 10, 7, 3, 8, 10, 6, 6, 4, 2, 7, 11, 5, 6, 5, 4, 3, 2, 8, 6, 7, 6, 8, 6, 11, 8, 6, 10, 6, 5, 11, 4, 9, 5, 11, 10, 4, 7, 10, 7, 3, 9, 7, 8, 5, 4, 12, 9, 7, 5, 6, 6, 10, 6, 7, 5, 4, 12, 9, 7, 7, 9, 8, 3, 6, 6, 8, 10, 10, 5, 4, 7, 6, 2, 5, 12, 8, 4, 4, 7, 6, 5, 3, 8, 5, 5, 7, 12, 9, 7, 10, 9, 9, 8, 6, 8, 6, 6, 6, 8, 5, 12, 7, 5, 7, 8, 4, 5, 2, 6, 4, 5, 10, 7, 5, 6, 5, 4, 3, 2, 12, 8, 6, 8, 9, 9, 12, 6, 8, 9, 8, 5, 3, 6, 6, 10, 9, 11, 6, 7, 3, 7, 3, 8, 9, 10, 6, 4, 7, 5, 9, 11, 7, 9, 3, 8, 6, 8, 9, 10, 5, 3, 9, 5, 4, 11, 7, 6, 11, 2, 5, 7, 4, 6, 7, 6, 6, 7, 3, 8, 7, 3, 7, 5, 8, 10, 9, 8, 6, 5, 5, 8, 6, 6, 5, 5, 5, 5, 7, 2, 7, 6, 8, 9, 3, 4, 2, 6, 9, 8, 8, 11, 11, 7, 9, 7, 8, 5, 10, 5, 5, 7, 5, 9, 7, 6, 4, 6, 4, 6, 7, 9, 6, 6, 7, 11, 9, 4, 5, 8, 7, 5, 11, 8, 5, 6, 7, 4, 7, 9, 12, 5, 5, 4, 5, 6, 5, 5, 4, 10, 6, 4, 6, 7, 5, 7, 10, 10, 6, 8, 10, 6, 9, 5, 8, 6, 10, 5, 3, 2, 5, 8, 4, 8, 6, 6, 7, 7, 8, 8, 4, 5, 5, 5, 8, 6, 11, 3, 8, 9, 3, 8, 9, 7, 11, 12, 10, 5, 4, 10, 8, 7, 4, 5, 10, 10, 5, 5, 8, 5, 8, 12, 3, 3, 8, 7, 8, 10, 4, 7, 9, 3, 5, 5, 11, 11, 10, 5, 8, 10, 5, 3, 4, 7, 12, 8, 6, 4, 10, 10, 3, 2, 11, 5, 6, 9, 3, 2, 5, 10, 7, 9, 11, 6, 5, 10, 5, 8, 10, 12, 9, 10, 6, 6, 10, 6, 7, 5, 9, 6, 4, 5, 11, 6, 6, 6, 8, 6, 9, 8, 7, 8, 9, 8, 9, 7, 6, 8, 5, 4, 5, 6, 11, 5, 7, 4, 8, 3, 4, 8, 10, 6, 11, 5, 8, 10, 3, 7, 6, 10, 6, 8, 5, 4, 5, 6, 6, 6, 7, 9, 6, 7, 8, 12, 6, 5, 2, 9, 8, 4, 8, 7, 5, 4, 6, 9, 5, 10, 6, 11, 2, 3, 10, 11, 11, 6, 7, 11, 10, 5, 8, 7, 7, 4, 6, 4, 9, 7, 7, 8, 6, 5, 6, 4, 3, 9, 11, 6, 6, 3, 5, 6, 7, 8, 8, 10, 10, 10, 8, 7, 12, 7, 11, 5, 3, 6, 5, 9, 10, 5, 8, 6, 8, 7, 6, 10, 7, 12, 5, 8, 7, 11, 10, 8, 8, 4, 3, 6, 6, 2, 8, 9, 9, 5, 9, 6, 8, 11, 5, 5, 12, 12, 10, 6, 10, 8, 8, 12, 12, 6, 7, 5, 6, 8, 5, 3, 8, 9, 7, 10, 9, 9, 9, 5, 2, 9, 7, 11, 6, 7, 7, 6, 9, 6, 7, 9, 6, 7, 10, 7, 11, 7, 6, 6, 6, 4, 5, 8, 7, 7, 9, 7, 5, 3, 11, 7, 6, 10, 4, 4, 2, 8, 9, 6, 10, 6, 8, 5, 12, 11, 7, 11, 10, 6, 2, 3, 9, 8, 6, 6, 11, 10, 5, 6, 5, 5, 9, 2, 9, 2, 7, 10, 8, 6, 2, 7, 4, 7, 9, 2, 3, 6, 5, 9, 7, 7, 8, 12, 10, 2, 10, 8, 7, 2, 7, 7, 8, 5, 4, 5, 7, 7, 10, 5, 7, 12, 8, 6, 7, 10, 5, 7, 8, 6, 5, 8, 7, 9, 6, 12, 7, 8, 5, 5, 9, 5, 4, 8, 11, 7, 6, 10, 3, 4, 5, 7, 11, 8, 8, 7, 7, 5, 6, 8, 7, 8, 6, 2, 6, 6, 6, 7, 6, 7, 6, 7, 6, 4, 5, 7, 8, 4, 7, 5, 6, 7, 10, 5, 4, 5, 2, 6, 2, 6, 7, 10, 7, 7, 11, 3, 6, 7, 8, 6, 7, 10, 8, 6, 5, 2, 6, 9, 4, 6, 8, 12, 7, 4, 4, 10, 9, 9, 7, 9, 7, 10, 10, 6, 3, 10, 7, 8, 7, 3, 5, 7, 9, 8, 6, 4, 7, 6, 4, 7, 10, 2, 10, 5, 6, 9, 10, 6, 5, 12, 4, 3, 11, 10, 6, 7, 6, 8, 5, 6, 9, 5, 5, 10, 3, 3, 7, 8, 9, 4, 8, 4, 9, 10, 7, 11, 9, 8, 2, 8, 5, 9, 8, 6, 7, 4, 7, 8, 7, 8, 9, 7, 12, 6, 7, 4, 10, 6, 5, 5, 8, 7, 11, 8, 10, 7, 6, 7, 11, 11, 10, 12, 8, 5, 5, 3, 7, 6, 9, 6, 12, 12, 10, 7, 9, 4, 8, 6, 8, 9, 9, 10, 4, 5, 9, 3, 6, 9, 7, 8, 8, 6, 10, 10, 5, 11, 9, 4, 4, 9, 10, 9, 7, 4, 7, 8, 5, 7, 4, 4, 6, 8, 5, 8, 8, 5, 10, 7, 11, 8, 2, 5, 7, 8, 10, 6, 9, 6, 7, 4, 9, 3, 5, 9, 6, 3, 11, 12, 10, 3, 8, 5, 10, 8, 5, 4, 8, 9, 8, 11, 6, 9, 9, 6, 11, 5, 4, 9, 10, 8, 3, 8, 6, 8, 11, 10, 5, 5, 7, 9, 3, 11, 6, 9, 8, 9, 7, 2, 8, 4, 7, 5, 10, 9, 7, 5, 9, 5, 9, 5, 8, 5, 6, 5, 8, 8, 7, 7, 3, 6, 3, 8, 7, 11, 6, 3, 11, 11, 9, 8, 6, 4, 9, 6, 10, 5, 4, 4, 3, 6, 6, 5, 8, 8, 2, 10, 6, 8, 7, 9, 4, 8, 8, 8, 5, 5, 2, 8, 9, 10, 8, 7, 5, 5, 5, 12, 4, 7, 8, 11, 9, 8, 11, 11, 10, 9, 5, 7, 10, 4, 6, 5, 10, 8, 12, 7, 6, 3, 7, 5, 8, 9, 6, 9, 11, 9, 11, 12, 6, 5, 8, 9, 8, 9, 4, 5, 4, 2, 6, 3, 10, 3, 7, 8, 10, 7, 11, 10, 8, 7, 6, 9, 5, 6, 5, 11, 7, 9, 2, 7, 6, 3, 6, 3, 8, 5, 3, 4, 2, 11, 4, 9, 9, 7, 5, 6, 7, 7, 8, 7, 9, 4, 9, 6, 4, 8, 10, 9, 8, 3, 4, 8, 5, 9, 5, 7, 11, 4, 6, 2, 9, 4, 9, 10, 8, 7, 8, 9, 5, 6, 9, 6, 10, 8, 8, 4, 6, 4, 4, 5, 9, 7, 4, 9, 7, 4, 7, 9, 6, 2, 5, 10, 5, 6, 3, 11, 9, 10, 8, 5, 6, 7, 2, 6, 9, 6, 7, 8, 6, 6, 6, 6, 10, 9, 8, 9, 7, 9, 7, 6, 9, 7, 3, 9, 8, 10, 4, 9, 4, 8, 3, 8, 7, 10, 8, 5, 10, 4, 10, 5, 6, 6, 7, 7, 8, 9, 7, 6, 3, 8, 3, 10, 10, 6, 11, 6, 11, 9, 9, 8, 7, 7, 10, 4, 9, 5, 12, 12, 4, 10, 11, 7, 8, 7, 3, 9, 9, 5, 6, 6, 3, 7, 4, 10, 7, 6, 4, 7, 7, 3, 4, 5, 4, 10, 6, 5, 7, 10, 12, 7, 12, 8, 8, 6, 10, 3, 5, 12, 7, 5, 5, 10, 7, 5, 11, 6, 5, 4, 4, 5, 11, 6, 2, 12, 6, 7, 6, 8, 7, 6, 11, 8, 8, 9, 6, 5, 7, 2, 9, 9, 7, 9, 7, 3, 8, 7, 7, 5, 4, 6, 7, 8, 8, 8, 4, 3, 6, 7, 11, 7, 5, 4, 6, 11, 8, 5, 4, 2, 6, 10, 12, 3, 6, 6, 4, 4, 9, 5, 9, 9, 5, 4, 5, 8, 7, 4, 10, 5, 6, 7, 10, 9, 11, 11, 9, 10, 10, 11, 8, 6, 2, 11, 9, 3, 5, 6, 6, 7, 11, 7, 3, 9, 12, 8, 5, 6, 6, 5, 10, 9, 7, 4, 7, 6, 7, 9, 5, 9, 9, 7, 7, 2, 11, 10, 10, 4, 12, 4, 5, 12, 10, 10, 6, 11, 5, 7, 6, 4, 8, 7, 8, 7, 10, 2, 8, 6, 4, 5, 12, 4, 6, 5, 6, 11, 2, 10, 7, 11, 5, 5, 9, 8, 8, 8, 9, 2, 11, 6, 10, 8, 7, 2, 8, 9, 8, 9, 4, 12, 7, 8, 5, 4, 9, 6, 3, 5, 8, 9, 11, 9, 11, 4, 5, 4, 7, 9, 6, 10, 8, 11, 3, 5, 4, 6, 4, 8, 10, 8, 11, 3, 11, 6, 4, 10, 6, 5, 4, 4, 8, 6, 8, 6, 8, 6, 5, 2, 8, 4, 8, 3, 5, 9, 7, 10, 4, 5, 10, 4, 11, 4, 7, 9, 7, 11, 4, 8, 3, 7, 9, 2, 10, 3, 7, 10, 3, 11, 4, 7, 6, 8, 2, 6, 3, 8, 2, 10, 5, 6, 6, 8, 5, 7, 7, 7, 5, 5, 11, 10, 6, 2, 5, 8, 4, 7, 6, 7, 8, 7, 9, 12, 9, 7, 2, 8, 8, 9, 8, 8, 7, 8, 4, 9, 5, 7, 7, 11, 6, 10, 6, 4, 10, 6, 5, 7, 6, 7, 6, 10, 9, 8, 5, 6, 8, 8, 8, 6, 5, 7, 5, 7, 9, 4, 10, 6, 8, 7, 9, 5, 8, 6, 5, 8, 6, 5, 9, 6, 3, 4, 10, 8, 10, 9, 6, 7, 5, 11, 11, 8, 3, 6, 6, 5, 12, 6, 8, 3, 3, 4, 7, 7, 5, 7, 8, 6, 10, 9, 3, 6, 8, 4, 6, 11, 6, 6, 11, 7, 9, 8, 8, 8, 8, 4, 6, 10, 5, 7, 9, 6, 10, 4, 11, 7, 4, 10, 6, 3, 10, 4, 7, 5, 7, 4, 9, 9, 7, 8, 6, 8, 10, 5, 8, 2, 6, 3, 3, 8, 12, 6, 9, 10, 11, 10, 6, 5, 7, 10, 8, 6, 10, 7, 8, 7, 6, 8, 12, 5, 7, 5, 8, 3, 7, 7, 12, 10, 12, 10, 11, 6, 3, 5, 8, 3, 4, 6, 11, 8, 4, 9, 6, 9, 7, 3, 8, 7, 5, 6, 12, 4, 12, 7, 6, 6, 5, 6, 9, 10, 7, 8, 3, 5, 3, 6, 8, 7, 7, 5, 2, 7, 11, 7, 6, 9, 8, 6, 7, 8, 4, 8, 8, 5, 9, 9, 10, 6, 7, 11, 9, 9, 5, 12, 2, 5, 7, 7, 3, 9, 7, 8, 6, 8, 9, 4, 5, 6, 5, 11, 11, 6, 6, 10, 9, 4, 4, 7, 9, 11, 6, 4, 8, 9, 4, 8, 12, 4, 6, 9, 2, 4, 7, 3, 4, 5, 8, 7, 5, 7, 6, 3, 6, 10, 9, 12, 10, 9, 9, 11, 6, 10, 4, 6, 6, 2, 9, 7, 8, 5, 8, 5, 6, 10, 5, 4, 12, 2, 7, 4, 7, 6, 5, 6, 4, 8, 8, 9, 7, 9, 10, 5, 2, 6, 8, 5, 8, 8, 9, 10, 5, 5, 10, 4, 3, 5, 10, 5, 5, 4, 7, 10, 11, 2, 6, 3, 7, 4, 8, 2, 8, 6, 8, 10, 9, 8, 7, 7, 7, 5, 5, 8, 10, 8, 3, 7, 6, 6, 5, 3, 7, 5, 9, 6, 11, 6, 3, 5, 9, 3, 7, 5, 10, 9, 9, 9, 6, 3, 7, 5, 9, 7, 7, 5, 7, 7, 5, 7, 7, 12, 6, 2, 5, 10, 10, 11, 12, 7, 4, 9, 8, 6, 5, 7, 7, 8, 7, 6, 4, 4, 9, 9, 9, 10, 8, 9, 7, 5, 7, 7, 4, 6, 9, 8, 7, 7, 6, 3, 7, 7, 6, 3, 10, 9, 6, 6, 3, 11, 9, 8, 9, 12, 12, 3, 6, 10, 4, 7, 6, 4, 6, 10, 7, 10, 7, 12, 6, 9, 5, 8, 7, 5, 4, 12, 7, 7, 8, 10, 8, 7, 3, 11, 9, 9, 7, 7, 10, 6, 3, 2, 8, 8, 6, 7, 7, 10, 8, 3, 7, 6, 5, 5, 4, 10, 9, 6, 8, 3, 3, 6, 11, 10, 8, 7, 3, 9, 6, 8, 9, 7, 8, 9, 12, 10, 8, 8, 7, 6, 3, 4, 9, 6, 2, 8, 6, 10, 10, 7, 4, 7, 2, 8, 7, 4, 6, 9, 12, 12, 4, 8, 12, 9, 10, 8, 4, 6, 8, 10, 5, 11, 5, 6, 5, 8, 11, 3, 3, 6, 12, 5, 10, 5, 5, 5, 8, 8, 6, 5, 8, 10, 11, 8, 9, 7, 10, 9, 8, 10, 9, 12, 8, 9, 5, 11, 6, 6, 10, 5, 7, 11, 8, 7, 7, 9, 5, 9, 4, 5, 9, 11, 9, 4, 5, 11, 7, 6, 7, 6, 6, 8, 7, 9, 6, 7, 5, 9, 2, 4, 8, 9, 12, 5, 3, 6, 7, 8, 7, 3, 12, 7, 6, 10, 3, 5, 6, 9, 8, 2, 6, 10, 9, 12, 5, 5, 9, 4, 10, 4, 8, 7, 12, 8, 5, 9, 6, 7, 3, 6, 7, 7, 4, 5, 8, 8, 7, 5, 4, 8, 6, 5, 9, 7, 11, 9, 7, 7, 8, 11, 7, 7, 10, 7, 6, 6, 11, 6, 7, 11, 10, 9, 8, 7, 7, 10, 8, 9, 9, 12, 7, 6, 7, 4, 9, 7, 8, 8, 7, 5, 8, 11, 5, 8, 6, 8, 11, 4, 8, 9, 6, 10, 7, 6, 7, 11, 3, 9, 4, 5, 6, 9, 7, 7, 8, 6, 4, 10, 6, 5, 10, 10, 11, 8, 9, 6, 10, 11, 10, 10, 10, 6, 7, 3, 6, 9, 7, 8, 5, 7, 10, 3, 8, 9, 8, 5, 7, 9, 5, 6, 7, 7, 10, 10, 7, 6, 8, 10, 3, 7, 11, 8, 5, 9, 8, 9, 8, 4, 8, 7, 5, 9, 10, 8, 10, 7, 9, 4, 4, 12, 9, 11, 2, 6, 6, 5, 7, 5, 6, 5, 6, 7, 11, 3, 9, 9, 3, 6, 8, 6, 8, 10, 6, 8, 7, 2, 9, 3, 5, 7, 7, 5, 9, 5, 8, 5, 7, 7, 7, 8, 5, 8, 8, 6, 10, 9, 4, 6, 4, 12, 6, 7, 6, 7, 7, 9, 9, 7, 9, 4, 8, 3, 10, 10, 5, 10, 5, 7, 9, 11, 8, 7, 6, 12, 11, 8, 6, 5, 9, 3, 9, 8, 9, 7, 8, 7, 9, 8, 6, 3, 7, 8, 4, 3, 7, 6, 11, 7, 7, 9, 8, 9, 10, 3, 6, 9, 5, 8, 8, 8, 9, 8, 5, 5, 5, 7, 11, 5, 9, 9, 6, 11, 7, 11, 9, 10, 7, 6, 7, 8, 10, 4, 3, 8, 5, 7, 7, 7, 7, 9, 10, 6, 9, 4, 11, 10, 8, 8, 5, 4, 4, 6, 7, 2, 3, 4, 7, 8, 8, 7, 11, 7, 8, 7, 7, 3, 7, 7, 4, 8, 10, 8, 4, 10, 8, 11, 5, 9, 9, 7, 7, 8, 5, 4, 7, 2, 3, 7, 5, 6, 7, 8, 10, 4, 7, 8, 8, 9, 7, 7, 7, 5, 3, 9, 5, 9, 9, 8, 4, 10, 11, 6, 7, 8, 10, 5, 7, 8, 6, 4, 2, 9, 8, 7, 6, 3, 7, 12, 9, 6, 7, 12, 11, 6, 10, 3, 7, 8, 6, 6, 5, 11, 6, 11, 7, 11, 6, 10, 5, 9, 6, 8, 9, 3, 4, 8, 2, 5, 4, 11, 5, 11, 8, 5, 8, 7, 11, 3, 6, 8, 11, 8, 10, 5, 6, 9, 4, 8, 5, 7, 7, 6, 5, 9, 3, 7, 7, 6, 7, 9, 8, 4, 7, 7, 9, 7, 9, 5, 7, 6, 7, 7, 12, 4, 8, 9, 6, 7, 5, 6, 5, 3, 8, 9, 5, 10, 4, 6, 5, 8, 11, 9, 12, 4, 10, 5, 8, 7, 6, 11, 5, 8, 5, 3, 10, 5, 9, 12, 12, 10, 8, 6, 7, 11, 3, 5, 5, 8, 2, 8, 7, 5, 6, 5, 5, 9, 8, 7, 7, 7, 8, 8, 7, 10, 5, 9, 5, 4, 7, 4, 3, 5, 8, 11, 6, 7, 4, 7, 5, 5, 7, 8, 10, 10, 4, 5, 5, 6, 11, 6, 7, 6, 6, 12, 7, 8, 6, 5, 5, 2, 9, 6, 7, 8, 11, 8, 9, 12, 6, 5, 11, 11, 10, 10, 8, 7, 8, 5, 7, 9, 2, 3, 10, 8, 8, 10, 8, 4, 11, 9, 6, 7, 10, 9, 8, 9, 7, 9, 9, 6, 9, 5, 7, 11, 3, 8, 4, 12, 11, 9, 5, 7, 10, 7, 7, 9, 3, 6, 11, 9, 7, 3, 7, 6, 8, 7, 9, 4, 9, 7, 10, 8, 8, 9, 4, 5, 3, 10, 9, 5, 10, 9, 3, 9, 9, 5, 8, 10, 6, 5, 11, 7, 6, 9, 9, 3, 6, 5, 8, 7, 5, 12, 8, 6, 7, 4, 4, 7, 3, 9, 3, 10, 7, 7, 3, 5, 7, 5, 5, 8, 6, 4, 8, 2, 6, 7, 4, 11, 7, 7, 5, 6, 5, 4, 6, 7, 3, 7, 5, 4, 7, 6, 9, 4, 6, 7, 2, 6, 6, 9, 5, 9, 8, 7, 3, 11, 10, 5, 8, 7, 6, 7, 5, 11, 8, 10, 7, 8, 7, 8, 5, 8, 7, 7, 10, 4, 9, 11, 6, 7, 11, 6, 11, 10, 10, 8, 11, 8, 8, 10, 5, 5, 6, 8, 11, 7, 11, 3, 10, 7, 9, 8, 5, 5, 8, 8, 6, 10, 3, 8, 7, 4, 6, 8, 8, 10, 7, 7, 6, 4, 3, 7, 9, 6, 3, 12, 11, 12, 7, 10, 5, 7, 7, 7, 6, 6, 2, 8, 11, 7, 8, 7, 7, 7, 11, 9, 10, 6, 10, 6, 8, 9, 8, 9, 8, 3, 4, 9, 8, 7, 10, 3, 2, 12, 3, 5, 8, 7, 4, 7, 7, 10, 7, 7, 8, 5, 8, 7, 6, 7, 5, 11, 6, 2, 6, 8, 6, 5, 7, 9, 5, 9, 11, 6, 5, 5, 12, 9, 8, 5, 8, 4, 5, 11, 6, 9, 7, 9, 6, 2, 5, 10, 5, 6, 7, 5, 11, 7, 6, 5, 7, 6, 6, 7, 7, 3, 4, 8, 8, 8, 7, 9, 6, 5, 5, 3, 7, 2, 7, 6, 7, 7, 5, 7, 7, 4, 7, 9, 5, 7, 6, 7, 8, 10, 4, 10, 5, 4, 5, 7, 6, 7, 10, 4, 3, 6, 8, 8, 8, 2, 8, 10, 6, 7, 6, 8, 5, 4, 10, 3, 3, 10, 3, 8, 8, 5, 3, 7, 7, 7, 5, 7, 5, 2, 5, 10, 5, 3, 6, 9, 7, 8, 4, 5, 10, 5, 6, 10, 6, 8, 6, 7, 5, 12, 11, 3, 8, 10, 4, 6, 3, 5, 6, 6, 7, 8, 7, 6, 10, 6, 6, 9, 5, 7, 4, 8, 3, 3, 6, 9, 12, 8, 5, 10, 8, 10, 6, 9, 3, 7, 11, 3, 5, 12, 3, 8, 9, 5, 5, 7, 10, 7, 9, 6, 5, 6, 5, 4, 7, 8, 4, 10, 6, 4, 5, 8, 9, 7, 7, 7, 4, 11, 7, 10, 4, 6, 10, 6, 11, 4, 7, 3, 7, 4, 12, 10, 8, 3, 9, 9, 7, 11, 7, 12, 7, 3, 4, 3, 10, 6, 12, 5, 8, 6, 6, 2, 10, 7, 7, 7, 4, 2, 7, 10, 8, 3, 3, 7, 7, 6, 7, 10, 11, 5, 7, 8, 12, 7, 12, 3, 6, 7, 11, 8, 9, 5, 4, 7, 8, 10, 7, 7, 11, 7, 8, 8, 4, 3, 5, 6, 8, 2, 5, 4, 5, 9, 7, 3, 8, 8, 10, 9, 9, 3, 7, 4, 8, 6, 3, 5, 10, 12, 4, 5, 12, 11, 11, 5, 12, 7, 5, 8, 6, 7, 8, 2, 9, 3, 8, 7, 4, 8, 5, 10, 12, 5, 7, 4, 9, 7, 4, 8, 5, 2, 5, 12, 5, 7, 6, 5, 4, 2, 6, 8, 6, 7, 8, 6, 10, 8, 7, 9, 6, 7, 11, 9, 11, 6, 7, 4, 10, 11, 11, 9, 8, 7, 6, 6, 5, 8, 2, 3, 4, 12, 7, 11, 7, 6, 10, 7, 9, 8, 9, 7, 7, 6, 7, 11, 5, 2, 6, 5, 8, 11, 9, 10, 10, 8, 7, 11, 7, 5, 11, 8, 6, 5, 7, 5, 7, 5, 7, 10, 2, 10, 8, 7, 12, 11, 8, 11, 10, 8, 6, 11, 10, 3, 5, 7, 8, 9, 5, 10, 7, 8, 10, 7, 7, 12, 5, 11, 10, 6, 5, 8, 5, 11, 7, 8, 4, 7, 8, 6, 6, 11, 7, 5, 9, 6, 6, 5, 6, 8, 8, 10, 7, 6, 7, 7, 6, 10, 2, 12, 3, 6, 3, 7, 3, 2, 3, 3, 8, 10, 10, 7, 10, 5, 3, 9, 11, 8, 7, 5, 7, 6, 3, 8, 10, 3, 10, 6, 7, 3, 5, 3, 9, 5, 2, 5, 5, 9, 11, 9, 7, 3, 10, 10, 5, 10, 7, 9, 10, 5, 12, 9, 9, 7, 8, 10, 10, 7, 4, 6, 9, 8, 11, 11, 7, 7, 5, 8, 7, 10, 10, 8, 9, 7, 8, 3, 11, 9, 5, 11, 6, 9, 2, 2, 8, 8, 10, 9, 7, 12, 8, 6, 12, 5, 6, 2, 9, 9, 9, 7, 5, 7, 7, 7, 9, 8, 9, 11, 4, 4, 7, 8, 2, 4, 11, 11, 9, 9, 4, 4, 6, 2, 7, 10, 6, 4, 6, 10, 8, 8, 7, 7, 7, 4, 9, 6, 9, 7, 9, 6, 9, 7, 6, 8, 7, 5, 4, 6, 3, 9, 11, 5, 5, 6, 6, 8, 8, 4, 12, 4, 7, 7, 11, 8, 7, 3, 5, 8, 8, 2, 7, 8, 3, 6, 8, 6, 3, 8, 5, 3, 8, 5, 7, 7, 8, 6, 9, 7, 7, 9, 7, 10, 6, 11, 9, 7, 3, 4, 6, 6, 7, 4, 9, 9, 11, 2, 9, 3, 5, 9, 11, 9, 7, 7, 11, 9, 7, 6, 5, 10, 2, 6, 8, 7, 12, 5, 7, 6, 5, 5, 8, 8, 7, 8, 2, 8, 3, 10, 9, 7, 4, 4, 9, 6, 8, 7, 5, 9, 9, 7, 3, 7, 4, 8, 7, 9, 7, 4, 9, 7, 3, 10, 12, 9, 9, 5, 4, 6, 4, 7, 11, 6, 6, 8, 4, 11, 12, 7, 6, 6, 8, 12, 6, 7, 11, 5, 10, 8, 3, 5, 7, 5, 6, 3, 6, 10, 6, 6, 6, 11, 8, 7, 8, 9, 5, 5, 7, 6, 4, 10, 6, 7, 5, 9, 10, 4, 6, 5, 7, 8, 3, 8, 6, 3, 4, 4, 7, 11, 5, 8, 6, 7, 8, 11, 3, 8, 9, 4, 9, 9, 9, 9, 7, 6, 5, 6, 2, 5, 7, 10, 5, 6, 7, 9, 7, 8, 9, 8, 4, 11, 7, 7, 3, 4, 8, 7, 7, 7, 3, 9, 8, 5, 6, 6, 6, 7, 7, 10, 5, 8, 5, 10, 9, 8, 9, 5, 8, 9, 8, 7, 10, 5, 7, 4, 3, 8, 6, 8, 4, 5, 10, 5, 5, 8, 7, 12, 6, 4, 5, 4, 4, 5, 4, 6, 9, 8, 5, 4, 11, 8, 7, 5, 7, 7, 5, 5, 10, 6, 8, 4, 4, 4, 6, 7, 7, 4, 3, 7, 6, 10, 5, 6, 8, 5, 6, 10, 7, 9, 6, 9, 6, 8, 8, 7, 8, 7, 6, 4, 4, 9, 4, 8, 6, 10, 5, 8, 4, 11, 6, 7, 8, 7, 4, 7, 6, 9, 8, 3, 6, 9, 5, 6, 6, 11, 8, 8, 7, 7, 2, 12, 7, 4, 2, 2, 6, 10, 9, 4, 3, 6, 11, 6, 10, 7, 4, 7, 7, 8, 11, 3, 5, 4, 9, 4, 5, 8, 7, 5, 10, 6, 6, 9, 8, 8, 12, 8, 8, 9, 9, 6, 4, 7, 6, 10, 8, 6, 8, 6, 9, 6, 8, 5, 4, 2, 5, 11, 7, 7, 7, 3, 7, 5, 4, 4, 9, 5, 7, 10, 4, 8, 5, 4, 7, 10, 10, 5, 5, 11, 6, 9, 4, 6, 8, 2, 4, 4, 9, 5, 10, 2, 12, 11, 5, 10, 7, 7, 2, 11, 6, 7, 6, 11, 5, 5, 7, 7, 7, 4, 10, 5, 11, 7, 9, 4, 4, 5, 10, 7, 9, 7, 9, 4, 8, 8, 7, 7, 8, 6, 7, 9, 8, 4, 3, 7, 2, 10, 9, 7, 11, 6, 8, 11, 8, 4, 11, 9, 3, 10, 8, 7, 11, 5, 7, 4, 2, 9, 6, 3, 12, 4, 11, 9, 8, 6, 9, 8, 11, 10, 7, 7, 3, 4, 7, 6, 7, 5, 6, 6, 8, 4, 6, 9, 5, 3, 6, 3, 2, 2, 3, 10, 5, 9, 4, 4, 9, 5, 4, 7, 9, 7, 12, 3, 8, 4, 8, 8, 9, 5, 9, 8, 11, 6, 6, 8, 10, 6, 8, 8, 4, 8, 6, 7, 7, 8, 6, 8, 2, 11, 3, 7, 3, 6, 11, 7, 5, 9, 10, 10, 3, 6, 8, 4, 10, 9, 8, 8, 10, 10, 4, 10, 8, 3, 9, 10, 7, 9, 7, 2, 5, 9, 8, 9, 10, 9, 9, 11, 6, 6, 7, 10, 3, 7, 6, 8, 10, 5, 6, 3, 11, 6, 4, 7, 5, 4, 5, 8, 9, 8, 7, 8, 3, 6, 3, 7, 10, 10, 5, 9, 8, 9, 5, 10, 10, 12, 7, 4, 4, 7, 9, 9, 11, 6, 7, 7, 5, 7, 8, 5, 9, 11, 9, 9, 8, 9, 9, 3, 8, 8, 7, 10, 9, 3, 8, 7, 5, 5, 6, 6, 8, 8, 7, 9, 8, 2, 4, 3, 12, 9, 4, 5, 5, 5, 8, 8, 5, 2, 7, 6, 5, 9, 5, 9, 9, 3, 7, 9, 8, 12, 9, 4, 8, 11, 6, 4, 11, 7, 9, 4, 6, 6, 11, 9, 5, 9, 4, 7, 10, 9, 6, 6, 5, 9, 6, 6, 3, 4, 7, 8, 8, 4, 9, 8, 8, 7, 10, 8, 9, 6, 11, 6, 6, 8, 9, 10, 6, 4, 4, 5, 6, 7, 9, 12, 6, 7, 8, 7, 7, 10, 9, 4, 7, 10, 9, 5, 2, 8, 6, 7, 5, 7, 8, 7, 8, 8, 6, 7, 9, 7, 7, 3, 7, 6, 7, 8, 12, 10, 7, 9, 6, 5, 8, 7, 7, 10, 6, 4, 10, 3, 8, 9, 6, 6, 8, 3, 4, 9, 5, 3, 11, 10, 12, 5, 5, 10, 6, 6, 10, 10, 4, 6, 11, 9, 10]\n\n"}, {"id": "expectation", "title": "Expectation", "url": "part2/expectation", "text": "\n \nExpectation\n\nA random variable is fully prepresented by its probability mass function (PMF), which represents each of the values the random variable can take on, and the corresponding probabilities. A PMF can be a lot of information. Sometimes it is useful to summarize the random variable! The most common, and arguably the most useful, summary of a random variable is its \"Expectation\". \n\n\n\nDefinition: Expectation\nThe expectation of a random variable $X$, writte $\\E[X]$ is the average of all the values the random variable can take on, each weighted by the probability that the random variable will take on that value.\n\n\t$$\n\t\\E[X] = \\sum_x x \\cdot \\p(X=x)\n\t$$\n\n\nExpectation goes by many other names: Mean, Weighted Average, Center of Mass, 1st Moment. All of which are calculated using the same formula.\nRecall that $\\p(X=x)$, also written as $\\p(x)$, is the probability mass function of the random variable $X$. Here is code that calculates the expectation of the sum of two dice, based off the probability mass function:\ndef expectation_sum_two_dice():\n    exp_sum_two_dice = 0\n    # sum of dice can take on the values 2 through 12\n    for x in range(2, 13):\n        pr_x = pmf_sum_two_dice(x) # pmf gives Pr(x)\n        exp_sum_two_dice += x * pr_x\n    return exp_sum_two_dice\nIf we worked it out manually we would get that if $X$ is the sum of two dice, $\\E[X] = 7$:\n\t$$\n\\E[X] = \\sum_x x \\cdot \\p(X=x) = 2 \\cdot \\frac{1}{36} + 2 \\cdot \\frac{2}{36} + \\dots + 12 \\frac{1}{36} = 7\n\t$$\n\n7 is the \"average\" number you expect to get if you took the sum of two dice near infinite times. In this case it also happens to be the same as the mode, the most likely value of the sum of two dice, but this is not always the case!\n\nProperties of expectation\n\n\nProperty: Linearity of Expectation\n\t\t$$E[aX + b] = a\\E[X]+b$$\n\t\t\n\t\n\n\n\nProperty: Expectation of the Sum of Random Variables\n\t\t$$E[X+Y] = E[X] +E[Y]$$\n\t\t\n\t\n\n\n\nProperty: Law of Unconcious Statistician\n\t\t$$E[g(X)] = \\sum_x g(x)\\p(X=x)$$\n\t\tOne can also calculate the expected value of a function g(X) of a random variable X when one knows the probability distribution of X but one does not explicitly know the distribution of g(X). This theorem has the humorous name of \"the Law of the Unconscious Statistician\" (LOTUS), because it is so useful that you should be able to employ it unconciously.\n\n\n\n\nProperty: Expectation of a Constant\n\t\t$$E[a] = a$$\n\t\tSometimes in proofs, you will end up with the expectation of a constant (rather than a random variable). For example what does the $\\E[5]$ mean? Since 5 is not a random variable, it does not change, and will always be 5, $\\E[5] = 5$.\n\t\n\nExpectation from Data\n\n\n"}, {"id": "variance", "title": "Variance", "url": "part2/variance", "text": "\n \nVariance\n\n\n\nDefinition: Variance of a Random Variable\nThe variance is a measure of the \"spread\" of a random variable around the mean. Variance for a random variable, X, with expected value $\\E[X] = \u00b5$ is:\n\t\t\t$$\n\\var(X) = \\E[(X\u2013\u00b5)^2]\n$$\nSemantically, this is the average distance of a sample from the distribution to the mean. When computing the variance often we use a different (equivalent) form of the variance equation:\n$$\n\\begin{align}\n\\var(X) &= \\E[X^2] - \\E[X]^2\n\\end{align}\n$$\n\t\n\n\nIn the last section we showed that Expectation was a useful summary of a random variable (it calculates the \"weighted average\" of the random variable). One of the next most important properties of random variables to understand is variance: the measure of spread.\n\nTo start, lets consider probability mass functions for three sets of graders. When each of them grades an assigment, meant to receive a 70/100, they each have a probability distribution of grades that they could give.   \n\n\n\n\nDistributions of three types of peer graders. Data is from a massive online course.\n\n\n\n\tThe distribution for graders in group $C$ have a different expectation. The average grade that they give when grading an assignment worth 70 is a 55/100. That is clearly not great! But what is the difference between graders $A$ and $B$? Both of them have the same expected value (which is equal to the correct grade). The graders in group $A$ have a higher \"spread\". When grading an assignment worth 70, they have a reasonable chance of giving it a 100, or of giving it a 40. Graders in group $B$ have much less spread. Most of the probability mass is close to 70. You want graders like those in group $B$: in expectation they give the correct grade, and they have low spread. As an aside: scores in group $B$ came from a probabilistic algorithm over peer grades.\n\t\n\n\tTheorists wanted a number to describe spread. They invented variance to be the average of the distance between values that the random variable could take on and the mean of the random variable. There are many reasonable choices for the distance function, probability theorists chose squared deviation from the mean:\n\n\t$$\n\\var(X) = \\E[(X\u2013\u00b5)^2]\n$$\n\n\n\nProof: $\\var(X) = \\E[X^2] - \\E[X]^2$\nIt is much easier to compute variance using $\\E[X^2] - \\E[X]^2$. You certainly don't need to know why its an equivalent expression, but in case you were wondering, here is the proof.\n\t\t\n\t\t\t$$\n\\begin{align}\n\\var(X) \n&= \\E[(X\u2013\u00b5)^2] && \\text{Note: } \\mu = \\E[X]\\\\\n&= \\sum_x(x-\\mu)^2 \\p(x) && \\text{Definition of Expectation}\\\\\n&= \\sum_x (x^2 -2\\mu x + \\mu^2) \\P(x) \n&& \\text{Expanding the square}\\\\\n&= \\sum_x x^2\\P(x)- 2\\mu \\sum_x x \\P(x) + \\mu^2 \\sum_x \\P(x)\n&& \\text{Propagating the sum}\\\\\n&= \\sum_x x^2\\P(x)- 2\\mu \\E[X] + \\mu^2 \\sum_x \\P(x) && \\text{Substitute def of expectation}\\\\\n&= \\E[X^2]- 2\\mu \\E[X] + \\mu^2 \\sum_x \\P(x)\n&& \\text{LOTUS } g(x) = x^2 \\\\\n&= \\E[X^2]- 2\\mu \\E[X] + \\mu^2\n&& \\text{Since }\\sum_x \\P(x) = 1\\\\\n&= \\E[X^2]- 2\\E[X]^2 + \\E[X]^2\n&& \\text{Since }\\mu = \\E[X]\\\\\n&= \\E[X^2]- \\E[X]^2\n&& \\text{Cancelation}\\\\\n\\end{align}\n$$\n\t\n\nStandard Deviation\nVariance is especially useful for comparing the \"spread\" of two distributions and it has the useful property that it is easy to calculate. In general a larger variance means that\nthere is more deviation around the mean \u2014 more spread. However, if you look at the leading example, the units of variance\nare the square of points. This makes it hard to interpret the numerical value. What does it mean that the\nspread is 52 points$^2$\n? A more interpretable measure of spread is the square root of Variance, which we call\nthe Standard Deviation $\\std(X) = \\sqrt{\\var(X)}$. The standard deviation of our grader is 7.2 points. In this example folks find it easier to think of spread in points rather than points $^2$. As an aside, the standard deviation is the average distance of a sample (from the distribution) to the mean, using the euclidean distance function\n\n"}, {"id": "bernoulli", "title": "Bernoulli Distribution", "url": "part2/bernoulli", "text": "\n \nBernoulli Distribution\n\nParametric Random Variables\nThere are some classic random variable abstractions that show up in many problems. At this point in the class you will learn about several of the most significant parametic discrete distributions. When solving problems, if you are able to recognize that a random variable fits one of these formats, then you can use its precalculated probability mass function (PMF), expectation, variance, and other properties. Random variables of this sort are called parametric random variables. If you can argue that a random variable falls under one of the studied parametric types, you simply need to provide parameters. A good analogy is a class in programming. Creating a parametric random variable is very similar to calling a constructor with input parameters.\nBernoulli Random Variable\n\n\tA Bernoulli random variable (also called a boolean or indicator random variable) is the simplest kind of parametric random variable. It can take on\ntwo values, 1 and 0. It takes on a 1 if an experiment with probability $p$ resulted\nin success and a 0 otherwise. Some example uses include a coinflip, a random binary digit, whether a disk drive crashed, and whether someone likes a Netflix movie.  Here $p$ is the parameter, different instances of Bernoulli random variables might have different values of $p$.\n\t\n\n\tHere is a full description of the key properties of a Bernoulli random variable. If $X$ is declared to be a Bernoulli random variable with parameter $p$, denoted $X \u223c \\Ber(p)$:\n\n<%\n  include('templates/rvCards/bernoulli.html')\n\nBecause Bernoulli is a parametric random variable, as soon as you declare a random variable to be of type Bernoulli you automatically can know all of these pre-derived properties! Some of the properties are straightforward to prove for a Bernoulli. For example you could have solved for expectation:\n\n\t\n\nProof: Expectation of a Bernoulli. If $X$ is a Bernoulli with parameter $p$, $X \\sim \\Ber(p)$:\n\t\t\n\n\t$$\n\t\\begin{align} \\E[X] &= \\sum_x x \\cdot \\p(X=x) && \\text{Definition of expectation} \\\\&= 1 \\cdot p + 0 \\cdot (1-p) && X \\text{ can take on values 0 and 1}\\\\&= p  && \\text{Remove the 0 term} \\end{align}$$\n\n\n\n\nProof: Variance of a Bernoulli. If $X$ is a Bernoulli with parameter $p$, $X \\sim \\Ber(p)$:\n\tTo compute variance, first compute $E[X^2]$:\n\t\t$$\n\t\t\\begin{align}\n\t\tE[X^2] \n\t\t&= \\sum_x x^2 \\cdot \\p(X=x) &&\\text{LOTUS}\\\\\n\t\t&= 0^2 \\cdot p + 1^2 \\cdot p\\\\\n\t\t&= p\n\t\t\\end{align}\n\t\t$$\n\t$$\n\t\\begin{align} \n\t\\var(X) \n\t\t&= E[X^2] - E[X]^2&& \\text{Def of variance} \\\\\n\t\t&= p - p^2 && \\text{Substitute }E[X^2]=p, E[X] = p \\\\\n\t\t&= p (1-p) && \\text{Factor out }p\n\t\\end{align}$$\n\n\nBernoulli random variables and indicator variables are two aspects of the same concept. A random variable $I$ is an indicator variable for an event $A$ if $I = 1$ when $A$ occurs and $I = 0$ if $A$ does not occur. $\\P(I=1)=\\P(A)$ and $\\E[I]=\\P(A)$. Indicator random variables are Bernoulli random variables, with $p=\\P(A)$.\n"}, {"id": "binomial", "title": "Binomial Distribution", "url": "part2/binomial", "text": "\n \nBinomial Distribution\n\nConsider $n$ independent trials of an experiment, where each trial is a \"success\" probability $p$. Let $X$ be number of successes in $n$ trials. This situation is truly common in the natural world, and as such there has been a lot of research into such phenomena. The name for random variables like $X$ is a Binomial Random variable. If you can identify that a process fits this discription, you can inherit many already proved properties, such as the PMF formula, expectation and variance!\n\n\n\n\n\n\nHere are a few examples of Binomial random variables:\n\n# of heads in $n$ coin flips\n# of 1\u2019s in randomly generated length $n$ bit string\n# of disk drives crashed in 1000 computer cluster, assuming disks crash independently\n\n\n\n\n<%\n  include('templates/rvCards/binomial.html')\n\nOne way to think of the Binomial is as the sum of $n$ Bernoilli variables. Say that $Y_i \\sim \\Ber(p)$ is an indicator bernoulli variable which is 1 if experiment $i$ is a success. Then if $X$ is the total number of successes in $n$ experiments, $X \\sim \\Bin(n, p)$:\n\t$$\n\tX = \\sum_{i=1}^n Y_i\n\t$$\nRecall that $Y_i$ will be 1 or 0 and as such one way to think of $X$ is the sum of those 1s and 0s.\nBinomial PMF\nThe most important property to know about a Binomial is its PMF function:\n\n\n\n\n\nThe full derivation of this formula is in fact something which we went over in part 1. There is a compelte example on the probability of $k$ heads in $n$ coin flips, where each flip is heads with probability $0.5$: Many Coin Flips. Briefly, if you think of each experiment as being distinct, then there are ${n \\choose k}$ ways of permuting $k$ successes from $n$ experiments. For any of the mututally exclusive permutations, the probability of that permutation is $p^k \\cdot (1-p)^{n-k}$.\nThe name binomial comes from the term ${n \\choose k}$ which is formally called the binomial coefficient.\nExpectation of Binomial\nThere is an easy way to calculate the expectation of a binomial, and a hard way. \n\nThe easy way is to leverage the fact that a Binomial is the sum of Bernoulli random variables. $X = \\sum_{i=1}^{n} Y_i$ where $Y_i \\sim \\Ber(p)$. Since the expectation of the sum of random variables is the sum of expectations we can add the expectation, $\\E[Y_i] = p$, of each of the Bernoulli's :\n$$\n\\begin{align}\n\\E[X] &= \\E\\Big[\\sum_{i=1}^{n} Y_i\\Big] && \\text{Since }X = \\sum_{i=1}^{n} Y_i \\\\\n&=  \\sum_{i=1}^{n}\\E[ Y_i] && \\text{Expectation of sum} \\\\\n&=  \\sum_{i=1}^{n}p && \\text{Expectation of Bernoulli} \\\\\n&=  n \\cdot p && \\text{Sum $n$ times}\n\\end{align}\n$$\n\n\tThe hard way is to use the definition of expectation:\n\t$$\n\t\\begin{align}\n\t\\E[X] &= \\sum_{i=0}^n i \\cdot \\p(X = i) && \\text{Def of expectation} \\\\\n\t&= \\sum_{i=0}^n i \\cdot {n \\choose i} p^i(1-p)^{n-i} && \\text{Sub in PMF} \\\\\n\t& \\cdots && \\text{Many steps later} \\\\\n\t&= n \\cdot p\n\t\\end{align}\n\t$$\n\n\n\n"}, {"id": "poisson", "title": "Poisson Distribution", "url": "part2/poisson", "text": "\n \nPoisson Distribution\n\nA Poisson random variable gives the probability of a given number of events in a fixed interval of time (or space). It make the Poisson assumption that  events occur with a known constant mean rate and independently of the time since the last event.\n\t\n\n<%\n  include('templates/rvCards/poisson.html')\n\nPoisson Intuition\nIn this section we show the intuition behind the Poisson derivation. It is both a great way to deeply understand the Poisson, as well as good practice with Binomial distributions.\nLet's work on the problem of predicting the chance of a given number of events occuring in a fixed time interval \u2014 the next minute. For example, imagine you are working on a ride sharing application and you care about the probability of how many requests you get from a particular area. From historical data, you know that the average requests per minute is $\\lambda = 5$. What is the probability of getting 1, 2, 3, etc requests in a minute?\n: We could approximate a solution to this problem by using a binomial distribution! Lets say we split our minute into 60 seconds, and make each second an indicator Bernoulli variable \u2014 you either get a request or you don't. If you get a request in a second, the indicator is 1. Otherwise it is 0. Here is a visualization of our 60 binary-indicators. In this example imagine we have requests at 2.75 and 7.12 seconds. the corresponding indicator variables are  blue filled in boxes:\n1 minute\n\n\n\n\tThe total number of requests received over the minute can be approximated as the sum of the sixty indicator variables, which conveniently matches the description of a binomial \u2014 a sum of Bernoullis. Specifically define $X$ to be the number of requests in a minute. $X$ is a binomial with $n=60$ trials. What is the probability, $p$, of a success on a single trial? To make the expectation of $X$ equal the observed historical average $\\lambda =5$ we should chose $p$ so that $\\lambda = \\E[X]$. \n\t$$\n\t\\begin{align}\n\t\\lambda &= \\E[X] && \\text{Expectation matches historical average} \\\\\n\t\\lambda &= n \\cdot p && \\text{Expectation of a Binomial is } n \\cdot p \\\\\n\tp &= \\frac{\\lambda}{n} && \\text{Solving for $p$}\n\t\\end{align}\n\t$$\n\tIn this case since $\\lambda=5$ and $n=60$, we should chose $p=5/60$ and state that $X \\sim \\Bin(n=60, p=5/60)$. Now that we have a form for $X$ we can answer probability questions about the number of requests by using the Binomial PMF:\n\n\t$$\\p(X = x) = {n \\choose x} p^x (1-p)^{n-x}$$\n\tSo for example:\n\t$$\\p(X=1) = {60 \\choose 1} (5/60)^1 (55/60)^{60-1} \\approx 0.0295$$\n\t$$\\p(X=2) = {60 \\choose 2} (5/60)^2 (55/60)^{60-2} \\approx 0.0790$$\n\t$$\\p(X=3) = {60 \\choose 3} (5/60)^3 (55/60)^{60-3} \\approx 0.1389$$\n\t\n\n\n\tGreat! But don't forget that this was an approximation. We didn't account for the fact that there can be more than one event in a single second. One way to assuage this issue is to devide our minute into more fine-grained intervals (the choice to split it into 60 seconds was rather arbitrary). Instead lets divide our minute into 600 deciseconds, again with requests at 2.75 and 7.12 seconds:\n\t1 minute\n\n\n\nNow $n=600$, $p=5/600$ and $X \\sim \\Bin(n=600, p=6/600)$. We can repeat our example calculations using this better approximation:\n$$\\p(X=1) = {600 \\choose 1} (5/600)^1 (595/60)^{600-1} \\approx 0.0333$$\n\t$$\\p(X=2) = {600 \\choose 2} (5/600)^2 (595/600)^{600-2} \\approx 0.0837$$\n\t$$\\p(X=3) = {600 \\choose 3} (5/600)^3 (595/600)^{600-3} \\approx 0.1402$$\n\n\nChose any value of $n$, the number of buckets to divide our minute into: \n\n\n\n\n\n\nThe larger $n$ is, the more accurate the approximation. So what happens when $n$ is infinity? It becomes a Poisson!\nPoisson, a Binomial in the limit\n\n\tOr if we really cared about making sure that we don't get two events in the same bucket, we can divide our minute into infinitely small buckets:\n\t1 minute\n\n\n\n\nProof: Derivation of the Poisson\n\n\tWhat does the PMF of $X$ look like now that we have infinite divisions of our minute? We can write the equation and think about it as $n$ goes to infinity. Recall that $p$ still equals $\\lambda/n$:\n\t\n\n\t$$\n\t\\P(X=x) = \\lim_{n \\rightarrow \\infty} {n \\choose x} (\\lambda / n)^x(1-\\lambda/n)^{n-x}\n\t$$\n\n\tWhile it may look intimidating, this expression simplifies nicely. This proof uses a few special limit rules that we haven't introduced in this book:\n\n\n$$\n\\begin{align}\n\t\\P(X=x) \n\t&= \\lim_{n \\rightarrow \\infty} {n \\choose x} (\\lambda / n)^x(1-\\lambda/n)^{n-x}\n\t\t&& \\text{Start: binomial in the limit}\\\\\n\t&= \\lim_{n \\rightarrow \\infty}\n\t\t{n \\choose x} \\cdot\n\t\t\\frac{\\lambda^x}{n^x} \\cdot\n\t\t\\frac{(1-\\lambda/n)^{n}}{(1-\\lambda/n)^{x}} \n\t\t&& \\text{Expanding the power terms} \\\\\n\t&= \\lim_{n \\rightarrow \\infty}\n\t\t\\frac{n!}{(n-x)!x!} \\cdot\n\t\t\\frac{\\lambda^x}{n^x} \\cdot\n\t\t\\frac{(1-\\lambda/n)^{n}}{(1-\\lambda/n)^{x}} \n\t\t&& \\text{Expanding the binomial term} \\\\\n\t&= \\lim_{n \\rightarrow \\infty}\n\t\t\\frac{n!}{(n-x)!x!} \\cdot\n\t\t\\frac{\\lambda^x}{n^x} \\cdot\n\t\t\\frac{e^{-\\lambda}}{(1-\\lambda/n)^{x}} \n\t\t&& \\href{http://www.sosmath.com/calculus/sequence/specialim/specialim.html}{\\text{Rule }} \\lim_{n \\rightarrow \\infty}(1-\\lambda/n)^{n} = e^{-\\lambda}\\\\\n\t&= \\lim_{n \\rightarrow \\infty}\n\t\t\\frac{n!}{(n-x)!x!} \\cdot\n\t\t\\frac{\\lambda^x}{n^x} \\cdot\n\t\t\\frac{e^{-\\lambda}}{1} \n\t\t&& \\href{https://www.youtube.com/watch?v=x1WBTBtfvjM}{\\text{Rule }} \\lim_{n \\rightarrow \\infty}\\lambda/n= 0\\\\\n\t&= \\lim_{n \\rightarrow \\infty}\n\t\t\\frac{n!}{(n-x)!} \\cdot\n\t\t\\frac{1}{x!} \\cdot\n\t\t\\frac{\\lambda^x}{n^x} \\cdot\n\t\t\\frac{e^{-\\lambda}}{1} \n\t\t&& \\text{Splitting first term}\\\\\n\t&= \\lim_{n \\rightarrow \\infty}\n\t\t\\frac{n^x}{1} \\cdot\n\t\t\\frac{1}{x!} \\cdot\n\t\t\\frac{\\lambda^x}{n^x} \\cdot\n\t\t\\frac{e^{-\\lambda}}{1} \n\t\t&& \\lim_{n \\rightarrow \\infty }\\frac{n!}{(n-x)!} = n^x\\\\\n\t&= \\lim_{n \\rightarrow \\infty}\n\t\t\\frac{\\lambda^x}{x!} \\cdot\n\t\t\\frac{e^{-\\lambda}}{1} \n\t\t&& \\text{Cancel }n^x\\\\\n\t&= \n\t\t\\frac{\\lambda^x \\cdot e^{-\\lambda}}{x!} \n\t\t&& \\text{Simplify}\\\\\n\\end{align}\n\t$$\n\n\nThat is a beautiful expression! Now we can calculate the real probability of number of requests in a minute, if the historical average is $\\lambda=5$:\n\n$$\\p(X=1) =  \\frac{5^1 \\cdot e^{-5}}{1!} = 0.03369$$\n\t$$\\p(X=2) = \\frac{5^2 \\cdot e^{-5}}{2!}= 0.08422$$\n\t$$\\p(X=3) =  \\frac{5^3 \\cdot e^{-5}}{3!} = 0.14037$$\n\nThis is both more accurate and much easier to compute!\nChanging time frames\nSay you are given a rate in one unit, but you want to know the number of events in another. For example, you may be given the rate of hits to a website per minute, but you want to know the probability over a 20 minute period.\n\n\n\n\n\n"}, {"id": "continuous", "title": "Continuous Distribution", "url": "part2/continuous", "text": "\n \nContinuous Distribution\n\nExponential Random Variable\n\n<%\n  include('templates/rvCards/exponential.html')\n"}, {"id": "normal", "title": "Normal Distribution", "url": "part2/normal", "text": "\n \nNormal Distribution\n\n\n<%\n  include('templates/rvCards/normal.html')\n\n\n\nExample: The 67% rule of a normal within one standard deviation. What is the probability that a normal variable $X \\sim \\N(\\mu, \\sigma)$ has a value within one standard deviation of its mean?\n\t\t$$\n\t\t\\begin{align}\n\t\t\\p(\\text{Within one }\\sigma \\text{ of } \\mu) \n\t\t\t&= \\p(\\mu - \\sigma < X < \\mu + \\sigma)\n\t\t\t\t \\\\\n\t\t\t&= \\p(X < \\mu + \\sigma) - \\p(X < \\mu - \\sigma)\n\t\t\t\t&& \\text{Prob of a range} \\\\\n\t\t\t&= \\Phi\\Big(\\frac{(\\mu + \\sigma)-\\mu}{\\sigma}\\Big) -\n\t\t\t\t\\Phi\\Big(\\frac{(\\mu - \\sigma)-\\mu}{\\sigma}\\Big)\n\t\t\t\t&& \\text{CDF of Normal} \\\\\n\t\t\t&= \\Phi\\Big(\\frac{\\sigma}{\\sigma}\\Big) -\n\t\t\t\t\\Phi\\Big(\\frac{- \\sigma}{\\sigma}\\Big)\n\t\t\t\t&& \\text{Cancel $\\mu$s} \\\\\n\t\t\t&= \\Phi(1) -\n\t\t\t\t\\Phi(-1)\n\t\t\t\t&& \\text{Cancel $\\sigma$s} \\\\\n\t\t\t&\\approx 0.8413 - 0.1587 \\approx 0.683\n\t\t\t\t&& \\text{Plug into $\\Phi$}\n\n\t\t\\end{align}\n\t\t\n\t\t$$\nWe made no assumption about the value of $\\mu$ or the value of $\\sigma$ so this will apply to every single normal random variable. Since it uses the Normal CDF this doesn't apply to other types of random variables.\n\t\n\n"}, {"id": "all_distributions", "title": "Random Variable Reference", "url": "part2/all_distributions", "text": "\n \nRandom Variable Reference\n\n\n"}, {"id": "prob_baby_delivery", "title": "Probability of Baby Delivery", "url": "examples/prob_baby_delivery", "text": "\n\n \nProbability and Babies\n\nWhat is the probability that Laura gives birth today (given that she hasn't given birth up until today)?\n\n\nToday's Date\n\n\n\n\n\nDue Date\n\n\n\n\n\nProbability of delivery today: \nProbability of delivery in next 7 days: \nCurrent days past due date:  days\nUnconditioned probability mass before today: \n\n\nHow likely is delivery, in humans, relative to the due date? There have been millions of births which gives us a relatively good picture [1]. The length of human pregnancy varies by quite a lot! Have you heard that it is 9 months? That is a rough, point estimate. The mean duration of pregnancy is 278.6 days, and pregnancy length has a standard deviation (SD) of 12.5 days. This distribution is not normal, but roughly matches a \"skewed normal\". This is a general probability mass function for the first pregnancy collected from hundreds of thousands of women (this PMF is very similar across demographics, but changes based on whether the woman has given birth before):\n\n\n\n\nOf course, we have more information. Specifically, we know that Laura hasn't given birth up until today (we will update this example when that changes). We also know that babies which are over 14 days late are \"induced\" on day 14. How likely is delivery given that we haven't delivered up until today? Note that the y-axis is scalled differently:\n\n\n\n\n\n\tImplementation notes: this calculation was performed by storing the PDF as a list of (day, probability) points. These values are sometimes called weighted samples, or \"particles\" and are the key component to a \"particle filtering\" approach. After we observe no-delivery, we set the probability of every point which has a day before today to be 0, and then re-normalize the remaining points (aka we \"filter\" the \"particles\"). This is convenient because the \"posterior\" belief doesn't follow a simple equation -- using particles means we never have to write that equation down in our code.\n\t\n\n\nThree friends have the exact same due date (Really! this isn't a hypothetical) What is the probability that all three couples deliver on the exact same day?\n\n\n\t\t\n\nProbability of three couples on the same day: \n\nHow did we get that number? Let $p_i$ be the probability that one baby is delivered on day $i$ -- this number can be read off the probability mass function.  Let $D_i$ be the event that all three babies are delivered on day $i$. Note that the event $D_i$ is mutually exclusive with the event that all three babies are born on another day (So for example, $D_1$ is mutually exclusive with $D_2$, $D_3$ etc). Let $N=3$ be the event that all babies are born on the same day:\n\n\t$$\n\\begin{align}\n\\p(N=3) &= \\sum_i \\p(D_i) && \\text{Since days are mutually exclusive} \\\\\n&= \\sum_i p_i^3 && \\text{Since the three couples are independent} \n\\end{align}\n\t$$\n\n\n\n[1] Predicting delivery date by ultrasound and last menstrual period in early gestation\n\nAcknowledgements: This problem was first posed to me by Chris Gregg.\n\n\n\n"}, {"id": "joint", "title": "Joint Probability", "url": "part3/joint", "text": "\n \nJoint Probability\n\n\n\n\tMany interesting problems involve not one random variable, but rather several interacting with one another. In order to create interesting probabilistic models and to reason in real world situations, we are going to need to learn how to consider several random variables jointly.\n\nIn this section we are going to use disease prediction as a working example to introduce you to the concepts involved in probabilistic models. The general question is: a person has a set of observed symptops. Given the symptoms what is the probability over each possible disease? \nWe have already considered events that co-occur and covered concepts such as independence and conditional probability. What is new about this section is (1) we are going to cover how to handle random variables which co-occur and (2) we are going to talk about how computers can reason under large probabilistic models.\n\nJoint Probability Functions\n\n    For single random variables, the most important information was the PMF or, if the variable was continuous, the PDF. When dealing with two or more variables, the equivalent function is called the Joint function. For discrete random variables, it is a function which takes in a value for each variable and returns the probability (or probability density for continuous variables) that each variable takes on its value. For example if you had two discrete variables the Joint function is:\n    $$\n    \\begin{align}\n    \\p(X=x,Y=y) && \\text{Joint function for $X$ and $Y$}\n    \\end{align}\n    $$\n    You should read the comma as an \"and\" and as such this is saying the probability that $X=x$ and $Y=y$. Again like for single variables, as shorthand, we often write just the values and it implies that we are talking about the probability of the random variables taking on those values. This notation is convenient because it is shorter, and it makes it explicit that the function is operating over two parameters. It requires to to recall that the event is a random variable taking on the given value.\n    $$\n    \\begin{align}\n    \\p(x,y) && \\text{Shorthand for }\\p(X=x,Y=y)\n    \\end{align}\n    $$\n    If any of the variables are continuous we use different notation to make it clear that we need a probability density function, something we can integrate over to get a probability. We will cover this in detail:\n    $$\n    \\begin{align}\n    f(X=x,Y=y) && \\text{Joint density function if $X$ or $Y$ are continuous}\n    \\end{align}\n    $$\n    The same idea extends to as many variables as you have in your model. For example if you had three discrete random variables $X$, $Y$, and $Z$, the joint probability function would state the likelihood of an assignment to all three: $\\p(X=x,Y=y,Z=z)$.\n\n   \n\n\tJoint Probability Tables\n\n\n\nDefinition: Joint Probability Table\n\t\tA joint probability table is a way of specifying the \"joint\" distribution between multiple random variables. It does so by keeping a multi-dimensional lookup table (one dimension per variable) so that the probability mass of any assignment, eg $\\p(X=x,Y=y, \\dots$), can be directly looked up.\n\t\n\nLet us start with an example. In 2020 the Covid-19 pandemic disrupted lives around the world. Many people were unable to get tested and had to determine whether or not they were sick based on home diagnosis. Lets build a very simple probabilistic model to enable us to make a tool which can predict the probability of having the illness given observed symptoms. To make it clear that this is a pedagogical example, lets consider a made up illness called Determinitis. The two main symptoms are fever and loss of smell.\n\n\nVariable\nSymbol\nType\n\n\nHas Determinitis\n$D$\nBernoulli (1 indicates has Determinitis)\n\n\nFever\n$F$\nCategorical (none, low, high)\n\n\nCan Smell\n$S$\nBernoulli (1 indicates can smell)\n\n\nA joint probability table is a brute force way to store the probability mass of a particular assignment of values to our variables. Here is a probabilistic model for our three random variables (aside: the values in this joint are realistic and based on reasearch, but are primarily for teaching. Consult a doctor before making medical decisions).\n\n\n\n\n$D=0$\n\t<%\n\tinclude('templates/jointGrid.html', data = [\n\t\t\t[0.024, 0.783],\n\t\t\t[0.003,0.092],\n\t\t\t[0.001,0.046]\n\t\t],\n\t\tkey ='covid',\n\t\trows = ['$F = \\\\text{none}$', '$F=\\\\text{low}$', '$F=\\\\text{high}$'],\n\t\tcols = ['$S=0$', '$S=1$'],\n\t)\n\t\n\n$D=1$\n\t<%\n\tinclude('templates/jointGrid.html', data = [\n\t\t\t[0.006, 0.014],\n\t\t\t[0.005,0.011],\n\t\t\t[0.004,0.011]\n\t\t],\n\t\tkey ='noCovid',\n\t\trows = ['$F = \\\\text{none}$', '$F=\\\\text{low}$', '$F=\\\\text{high}$'],\n\t\tcols = ['$S=0$', '$S=1$'],\n\t)\n\n\n\n\tA few key observations:\n\t\nEach cell in this table represents the probability of one assignment of variables. For example the probability that someone cant smell, $S=0$, has a low fever, $F=\\text{low}$, and has the illness, $D=1$, can be directly read off the table: $P(D=1,S=0,F=\\text{low}) = 0.005$. \n\t\tThese are joint probabilities not conditional probabilities. The value 0.005 is the value of illness, no smell and low fever. It is not the probability of no smell and low fever given illness. A table which stored conditional probabilities would be called a conditional probability table, this is a joint probability table.\n\t\tIf you sum over all cells, the total will be 1. Each cell is a mutually exclusive combination of events and the cells are meant to span the entire space of possible outcomes.\n\t\t\tThis table is large! We can count the number of cells using the step rule of counting. If $n_i$ is the number of different values that random variable $i$ can take on, the number of cells in the joint table is $\\prod_i n_i$.\n\t\n\nProperties of Joint Distributions\nThere are many properties of a random variable of any random variable some of which we will dive into extensively. Here is a brief summary. Each random variable has:\n\n\n\n\n\nProperty\nNotation Example\nDescription\n\n\n\nDistribution Function (PMF or PDF)\n$\\P(X=x,Y=y,\\dots)$ or $f(X=x,Y=y,\\dots)$\nA function which maps values the RV can take on to likelihood.\n\n\nCumulative Distribution Function (CDF)\n$F(X < x,Y < y, \\dots)$\nProbability that each variable is less than its corresponding parameter\n\n\nCovariance\n$\\sigma_{X,Y}$\nA measure of how much two random variables vary together.\n\n\nCorrelation\n$\\rho_{X,Y}$\nNormalized co-variance\n\n\n\n\n"}, {"id": "joint", "title": "Joint Probability", "url": "part3/joint", "text": "\nLet us start with a humble example: imagine you care about the sort of music that a person likes. Spotify, a popular music application breaks all songs into a set of features. There are 9 different features but for now lets focus on three: Acousticness, Danceability and Popularity. All features are scored in a range 0 to 1, so for example if a song has a danceability rating of 1, it is a straight up bop.\nIf you want to understand a person's music taste you could look at the probability distribution over any of those features on their own. For example here is one person's estimated distribution of Danceability after they listened to 10,000 songs (recall each song has a Danceability score):\n\n<%\ninclude('templates/barGraph.html', params={\n\t'key':'singleSong',\n\t'data':[\n\t\t[0.1, 0.15],\n\t\t[0.2, 0.05],\n\t\t[0.3, 0.05],\n\t\t[0.4, 0.07],\n\t\t[0.5, 0.10],\n\t\t[0.6, 0.50],\n\t\t[0.7, 0.70],\n\t\t[0.8, 0.80],\n\t\t[0.9, 0.40],\n\t\t[1.0, 0.20]\n\t],\n\t'normalize':'True',\n\t'height':400,\n\t'xLabel':'Danceability Score'\n})\nIn the PMF chapter we covered how you can create a distribution like this from data. This graph of a single variable relating to a person's music taste does not tell the whole picture. \n\n<%\ninclude('templates/jointGrid.html', data = [\n\t\t[0.1, 0.15,0.99, 0.1,0.1],\n\t\t[0.5,0.5,0.5, 0.1,0.1],\n\t\t[0.1,0.9,0.8, 0.1,0.1],\n\t\t[0.5,0.5,0.5, 0.1,0.1],\n\t\t[0.1,0.9,0.8, 0.1,0.1]\n\t],\n\tkey ='songJoint',\n\trows = ['1', '2', '3', '4', '5'],\n\tcols = ['1', '2', '3', '4', '5'],\n\tnormalize = True\n)\n"}, {"id": "fairness", "title": "Fairness in AI", "url": "examples/fairness", "text": "\n \nFairness in Artificial Intelligence\n\nArtificial Intelligence often gives the impression that it is objective and \"fair\". However, algorithms are made by humans and trained by data which may be biased. There are several examples of AI algorithms, deployed, have been shown to make decisions that were biased based on gender, race or other protected demographics --  even when\nthere is no intention for it.\nThese examples have also led to a necessary research into a growing field of algorithmic fairness. How can we demonstrate, or proove, that an algorithm is behaving in a way that we think is appropriate? What is fair? Clearly these are complex questions and are deserving of a complete conversation. This example is simple for the purpose of giving an introduction to the topic.\n\n\n\nML stands for Machine Learning. Solon Barocas and Moritz Hardt, \"Fairness in Machine Learning\", NeurIPS 2017\n\nWhat is Fairness?\nAn artificial intelligence algorithm is going to be used to make a binary prediction ($G$ for guess) for whether a person will repay a loan.  The question has come up:  is the algorithm \"fair\" with respect to a binary protected demographic ($D$ for demographic)? To answer this question we are going to analyze predictions the algorithm made on historical data. We are then going to compare the predictions to the true outcome ($T$ for truth). Consider the following joint probability table from the history of the algorithm\u2019s predictions:\n\n\n$D=0$\n\n\n\n\n\t\t\t\t\t$G=0$\n\t\t\t\t\n\n\t\t\t\t\t$G=1$\n\t\t\t\t\n\n\n\n\t\t\t\t\t$T=0$\n\t\t\t\t\n\n\t\t\t\t\t0.21\n\t\t\t\t\n\n\t\t\t\t\t0.32\n\t\t\t\t\n\n\n\n\t\t\t\t\t$T=1$\n\t\t\t\t\n\n\t\t\t\t\t0.07\n\t\t\t\t\n\n\t\t\t\t\t0.28\n\t\t\t\t\n\n\n\n\n$D=1$\n\n\n\n\n\t\t\t\t\t$G=0$\n\t\t\t\t\n\n\t\t\t\t\t$G=1$\n\t\t\t\t\n\n\n\n\t\t\t\t\t$T=0$\n\t\t\t\t\n\n\t\t\t\t\t0.01\n\t\t\t\t\n\n\t\t\t\t\t0.01\n\t\t\t\t\n\n\n\n\t\t\t\t\t$T=1$\n\t\t\t\t\n\n\t\t\t\t\t0.02\n\t\t\t\t\n\n\t\t\t\t\t0.08\n\t\t\t\t\n\n\n\n\nRecall that cell $D=i,G=j,T=k$ contains the probability $\\P(D=i,G=j,T=k)$. A joint probability table gives the probability of all combination of events. Recall that since each cell is mutually exclusive, the $\\sum_i \\sum_j \\sum_k \\P(D=i,G=j,T=k) = 1$. Note that this assumption of mutual exclusion could be problematic for demographic variables (some people are mixed ethnicity, etc) which gives you a hint that we are just scratching the surface in our conversation about fairness. Lets use this joint probability to learn about some of the common definitions of fairness. \nPractice with joint marginalizationWhat is $\\p(D=0)$? What is $\\p(D=1)$? \nProbabilities with assignments to a subset of the random variables in the joint distribution can be calculated by a process called marginalization: sum the probability from all cells where that assignment is true.\n$$\n\\begin{align}\n\\p(D=1) &= \\sum_{j \\in \\{0, 1\\}} \\sum_{k \\in \\{0, 1\\}} \\p(D= 1, G= j, T = k)\\\\\n&= 0.01 + 0.01 + 0.02 + 0.08 = 0.12\n\\end{align}\n$$\n\n$$\n\\begin{align}\n\\p(D=0) &= \\sum_{j \\in \\{0, 1\\}} \\sum_{k \\in \\{0, 1\\}} \\p(D= 0, G= j, T = k)\\\\\n&= 0.21 + 0.32 + 0.07 + 0.28 = 0.88\n\\end{align}\n$$\n\nNote that $\\p(D=0) + \\p(D=1) = 1$. That implies that the demographics are mututally exclusive.\nFairness definition #1: ParityAn algorithm satisfies \u201cparity\u201d if the probability that the algorithm makes a positive prediction ($G$ = 1) is the same regardless of begin conditioned on demographic variable.\nDoes this algorithm satisfy parity?\n$$\n\\begin{align}\nP(G=1|D=1) \n    &= \\frac{P(G = 1, D = 1)}{P(D=1)}\n    \t&& \\text{Cond. Prob.}\\\\\n    &= \\frac{P(G = 1, D = 1, T= 0) + P(G=1, D = 1, T=1)}{P(D=1)}\n    \t&& \\text{Prob or}\\\\\n    &= \\frac{0.01 + 0.08}{0.12} = 0.75\n    \t&& \\text{From joint}\n\\end{align}\n$$\n\n$$\n\\begin{align}\nP(G=1|D=0) \n    &= \\frac{P(G = 1, D = 0)}{P(D=0)}\n    \t&& \\text{Cond. Prob.}\\\\\n    &= \\frac{P(G = 1, D = 0, T= 0) + P(G=1, D = 0, T=1)}{P(D=0)}\n    \t&& \\text{Prob or}\\\\\n    &= \\frac{0.32 + 0.28}{0.88} \\approx 0.68\n    \t&& \\text{From joint}\n\\end{align}\n$$\nNo. Since $P(G=1|D=1) \\neq P(G=1|D=0)$ this algorithm does not satisfy parity. It is more likely to guess 1 when the demographic indicator is 1.\n\n\nFairness definition #2: Calibration\n\tAn algorithm satisfies \u201ccalibration\u201d if the probability that the algorithm is correct ($G=T$) is the same regardless of demographics. \n\nDoes this algorithm satisfy calibration?\nThe algorithm satisfies calibration if $P(G = T | D = 0) = P(G = T | D = 1)$ \n$$\n\\begin{align}\n    P(G = T | D = 0)\n    &= P(G = 1, T = 1 | D = 0) + P(G = 0, T = 0 | D = 0)\\\\\n    &= \\frac{0.28 + 0.21}{0.88} \\approx 0.56 \\\\\n     P(G = T | D = 1)\n    &= P(G = 1, T = 1 | D = 1) + P(G = 0, T = 0 | D = 1)\\\\\n    &= \\frac{0.08 + 0.01}{0.12} = 0.75\n\\end{align}\n$$\nNo: $P(G = T | D = 0) \\neq  P(G = T | D = 1)$\n\n\n\nFairness definition #3: Equality of Odds\nAn algorithm satisfies \"equality of odds\" if the probability that the algorithm predicts a positive outcome ($G=1$) is the same regardless of demographics given that the outcome will occur ($T=1$).\n Does this algorithm satisfy equality of odds?\n\nThe algorithm satisfies equality of odds if $P(G = 1 | D = 0, T = 1) = P(G = 1 | D = 1, T = 1)$ \n$$\n\\begin{align*}\n    P(G = 1 | D = 1, T = 1)\n    &= \\frac{P(G = 1 , D = 1, T = 1)}{P(D = 1, T = 1)}\\\\\n    &= \\frac{0.08}{0.08 + 0.02} = 0.8 \\\\\n    P(G = 1 | D = 0, T = 1)\n    &= \\frac{P(G = 1 , D = 0, T = 1)}{P(D = 0, T = 1)}\\\\\n    &= \\frac{0.28}{0.28 + 0.07} = 0.8\n\\end{align*}\n$$\nYes: $P(G = 1 | D = 0, T = 1) = P(G = 1 | D = 1, T = 1)$\n\nWhich of these definitions seems right to you? One can prove that you cant satisfy all of the above simultaneously. For a deeper treatment of the subject, here is a useful summary of the latest research Pessach et al. Algorithmic Fairness.\n\n\tGender Shades\n\n\t\tIn 2018, Joy Buolamwini and Timnit Gebru had a breakthrough result called \"gender shades\" published in the first conference on Fairness, Accountability and Transparency in ML [1]. They showed that facial recognition algorithms, which had been deployed to be used by Facebook, IBM and Microsoft, were substantially better at making predicitons (in this case classifying gender) when looking at lighter skinned men than darker skinned women. Their work exposed several shortcomings in production AI: biased datasets, optimizing for average accuracy (which means that the majority demographic gets most weight) lack of awarness of intersectionality, and more. Let's take a look at some of their results.\n\t\n\n\n\nFigure by Joy Buolamwini and Timnit Gebru. Facial recognition algorithms perform very differently depending on who they are looking at. [1]\n\t\n\nTimnit and Joy looked at three classifiers trained to predict gender, and computed several statistics. Lets take a look at one statistic, accuracy, for one of the facial recognition classifiers, IBMs:\n\n\t\n\n\n\n\nWomen\nMen\nDarker\nLighter\n\n\n\nAccuracy\n\n79.7\n94.4\n77.6\n96.8\n\n\nUsing the language of fairness, accuracy measures $\\p(G=T)$. The cell in the table above under \"Women\" says the accuracy when looking at photos of women $\\p(G=T|D = \\text{Women})$. It is easy to show that these production level systems are terribly \"uncalibrated\":\n\t\t$$\\p(G=T|D = \\text{Woman}) \\neq \\p(G=T|D = \\text{Man})$$\n\t\t$$\\p(G=T|D = \\text{Lighter}) \\neq \\p(G=T|D = \\text{Darker})$$\n\n\t\tWhy should we care about callibration and not the other definitions of fairness? In the case the classifier was making a prediction of gender where a positive prediction (say predicting women) doesn't have directly associated reward as in our above example, where we were predicting if someone should receive a loan. As such the most salient idea is: is the algorithm just as accurate for different genders (callibration)?\nThe lack of callibration between men/women and lighter/darker skined photos is an issue. What Joy and Timnit showed next was that the problem becomes even worse when you look at intersectional demographics.\n\n\n\n\nDarker Men\nDarker Women\nLighter Men\nLighter Women\n\n\n\nAccuracy\n88.0\n65.3\n99.7\n92.9\n\n\n\n\t\tIf the algorithms were \"fair\" according to the callibration you would expect the accuracy to be the same regardness of demographics. Instead there is alomst a 34.2 percentage point difference! $\\p(G=T|D = \\text{Darker Woman})$ = 65.3 compared to $\\p(G=T|D = \\text{Ligher Man}) = 99.7$\n\t\n[1]  Buolamwini, Gebru. Gender Shades. 2018\nWays Forward?\nWadsworth et al. Achieving Fairness through Adversarial Learning\n"}, {"id": "bridge_distribution", "title": "Bridge Distribution", "url": "examples/bridge_distribution", "text": "\n \nBridge Card Game\n\n\n\nDistribution of Suit Splits\n\n\tImagine that randomly shuffled cards are split between two equal sized hands. Across the two hands there are a known number of cards of a particular suit (eg spades), and you want to know how many are in one hand and how many are in the other. What is the probability of the split? This problem comes up in the game of bridge, one of the most popular card games. You do not need to know the rules of bridge to follow this example.\n\n\n\n$k$, the number of cards in each player's hand: \n\n\n$n$, the number of cards of particular suit among the two hands: \n\nA few notes: If there are $k$ cards in each of the 2 hands there are $2 k$ cards total. At the start of a game of bridge $k=13$. It must be the case that $n \\leq 2  k$ because you can't have more cards of the suit left than number of cards! If there are $n$ of a suit, then there are $2k -n$ of other suits. This problem assumes that the cards are properly shuffled.\n\n\nProbability of different splits of the suit:\nLet $Y$ be a random variable representing the number of the suit in hand one. We can calculate the probability that $Y$ equals different values $i$ by counting equally likely outcomes.\n$$\\p(Y = i) = \\frac\n\t{ {n \\choose i} \\cdot {2\\cdot k-n \\choose k-i} }\n\t{ {2\\cdot k \\choose k}}$$\n\n\n\tIf we want to think about the probability of a given split, it is sufficient to chose one hand (call it \"hand one\") and think about the probability of the number of the given suit in that hand. Though there are two hands, if I tell you how many of a suit are in one hand, you can automatically figure out how many of the suit are in the other hand: recall that the number of the suit sums to $n$. \n\t\n\nProbability that either hand has at least $j$ cards of suit\nLet $X$ be a random variable representing the highest number of cards of the suit in either hand. We can calculate the probability by using probability of or.\n$$\\p(X \\geq j) = 1 - \\sum_{i=n-j+1}^{j - 1}\\p(Y= i)$$\n\n\n\n\n\nDistribution of Hand Strength\n\nYou might notice that at first blush this looks a lot like a poisson with rate $\\lambda = 10$. First, lets consider why the rate might be 10. Let $X_i$ be the points of a given card $i$.  Since each card value is equally likely $\\p(X_i=x) = \\frac{1}{13}$. The expectation of points for each card is $\\E[X] = \\sum_x x \\cdot \\p(X_i=x) = (1+2+3+4)\\frac{1}{13}$. Let $H$ be the value of a hand. The value of a hand is the sum of the value of each card: \n\t$$\n\t\\begin{align}\\E[H] &= \\sum_{i\\in \\{1 \\dots 13\\}} \\E[X_i] \\\\&= 13 \\cdot \\E[X_i] \\\\&= 13 \\cdot (1+2+3+4)\\frac{1}{13} = 10\\end{align}$$\nSaying that $H$ is approximately $\\sim \\Poi(\\lambda=10)$ is an interesting claim. It suggests that points in a hand come at a constant rate, and that the next point in your hand is independent of when you got your last point. Of course this second part of the assumption is mildly violated. There are a fixed set of cards so getting one card changes the probabilities of others. For this reason the poisson is a close, but not perfect approximation.\n\nJoint distribution of the score of each of two hands\nIn most card games it doesn't just matter how strong your hand is, but the relative strength of your hand and another hand. In bridge, you play with a partner. We know that the two hands are not independent of each other. If I tell you that your partner has a strong hand, that means there are fewer \"high value\" cards that can be in your hand, and as such by belief in your strength has changed. \n\n\n\n\n\nYour points: \n\n\n\n\n"}, {"id": "clt", "title": "Central Limit Theorem", "url": "part4/clt", "text": "\n \nCentral Limit Theorem\n\n\n"}, {"id": "bootstrapping", "title": "Bootstrapping", "url": "part4/bootstrapping", "text": "\n \nBootstrapping\n\n\n"}, {"id": "parameters", "title": "Uncertainty in Parameters", "url": "part4/parameters", "text": "\n \nUncertainty in Parameters\n\n\n"}, {"id": "beta", "title": "Beta Distribution", "url": "part4/beta", "text": "\n \nBeta Distribution\n\n\n"}, {"id": "bounds", "title": "Probability Bounds", "url": "part4/bounds", "text": "\n \nProbability Bounds\n\n\n"}, {"id": "thompson", "title": "Thompson Sampling", "url": "examples/thompson", "text": "\n \nThompson Sampling\n\n\n\n\n\nLet me present you with a seemingly simple problem that has a suprisingly complex solution. Imagine that you have two brand new drugs for a serious illness. You don't know how effective each drug is. You want to know which drug is the most effective, but at the same time, there are costs to exploration \u2014 there are high stakes.\n"}, {"id": "mle", "title": "Maximum Likelihood Estimation", "url": "part5/mle", "text": "\n \nMaximum Likelihood Estimation\n\n\n"}, {"id": "map", "title": "Maximum A Posteriori", "url": "part5/map", "text": "\n \nMaximum A Posteriori\n\n\n"}, {"id": "naive_bayes", "title": "Na\u00efve Bayes", "url": "part5/naive_bayes", "text": "\n \nNa\u00efve Bayes\n\n\n"}, {"id": "optimization", "title": "Gradient Ascent Optimization", "url": "part5/optimization", "text": "\n \nGradient Ascent Optimization\n\n\n"}, {"id": "linear_regression", "title": "Linear Regression", "url": "part5/linear_regression", "text": "\n \nLinear Regression\n\n\n"}, {"id": "log_regression", "title": "Logistic Regression", "url": "part5/log_regression", "text": "\n \nLogistic Regression\n\n\n"}, {"id": "neural_nets", "title": "Artificial Neural Networks", "url": "part5/neural_nets", "text": "\n \nArtificial Neural Networks\n\n\n"}, {"id": "vision_test", "title": "Vision Test", "url": "examples/vision_test", "text": "\n \nVision Test\n\n\n"}]