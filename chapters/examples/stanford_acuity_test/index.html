
% rebase('templates/chapter.html', title="Vision Test")
 
<center><h1>Stanford Vision Test</h1></center>
<hr/>

<div class="alert alert-primary"><b>History</b>: Did you know that an algorithm was invented <i>in</i> CS109? Back in Spring quarter 2017 there was a problem on the final exam which challenged students to use probability to do a better job of measuring how well someone can see. This grew into a collaboration with a former student, Ali Malik, as well as a Stanford eye doctor Charles Lin. The algorithm improved a few times, and now is one of the best algorithms (in theory if not in practice) for measuring how well someone can see!</div>

<p>
    <img class="mainFigureFull" src="{{pathToRoot}}img/chapters/stat/overview.png" />
</p>

<h3>How to Represent Ability to See?</h3>

<p>Ability is a random variable!</p>

<h3>Infering Ability</h3>

<p>One of the major tasks that we have to accomplish is to update</p>

$$
\begin{align*}
P(A=a|Y=0) &= \frac{P(Y=0|A=a)P(A=a)}{P(Y=0)} \\
&= \frac{P(Y=0|A=a)P(A=a)}{\sum_a P(Y=0, A=a)} \\
&= \frac{P(Y=0|A=a)P(A=a)}{\sum_a P(Y=0 | A=a)P(A=a)}
\end{align*}
$$

<p>We can make this equation more general, so that we update a belief for a correct, $Y=1$ or incorrect, $Y=0$. To do so lets let $y \in \{0, 1\}$ be a variable:</p>

$$
P(A=a|Y=y) = \frac{P(Y=y|A=a)P(A=a)}{\sum_a P(Y=y | A=a)P(A=a)}
$$

<p>Since all the terms in the denominator are repeats of terms that show up in the numerator, we can focus on understanding the two terms: $P(A = a)$ and $P(Y=y|A=a$.</p>

<pre class="language-python"><code>def update(belief, obs):
    """
    Take in a prior belief (stored as a dictionary) for a random 
    variable representing how well someone can see. Update the
    belief based on an observation using Bayes' Theorem for RVs
    """

    # loop over every value in the support of the belief RV
    for a in belief:
        # the prior belief P(A = a)
        prior_a = belief[a]
        # the obs probability P(Y = y | A = a)
        likelihood = calc_likelihood(a, obs)
        # numerator of Bayes' Theorem
        belief[a] = prior_a * likelihood
    # calculate the denominator of Bayes' Theorem
    normalize(belief)</code></pre>

<h3>Chosing the Next Font Size</h3>

<p>Optimistic sampling, just like Thompson Sampling.</p>
