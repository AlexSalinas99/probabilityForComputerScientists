
% rebase('templates/chapter.html', title="Bayes' Theorem")
 
 <center><h1>Bayes' Theorem</h1></center>
<hr/>

<p>Bayes Theorem is one of the most ubiquitous results in probability for computer scientists. Very often we
know a conditional probability in one direction, say P(E|F), but we would like to know the conditional
probability in the other direction. Bayes Theorem provides a way to convert from one to the other. We can
derive Bayes Theorem by starting with the definition of conditional probability:


$$
\begin{align}
\p(E|F) 
&= \frac{\p(E \and F)}{\p(F)} && \text{Def of conditional probability}  \\
&= \frac{\p(F | E) \cdot \p(E)}{\p(F)} && \text{Substitute the chain rule}
\end{align}
$$

</p>

<p>
<div class="bordered">
	<b><i>Definition</i></b>: Bayes Theorem <br/>

	<p>The most common form of Bayes Theorem is:
		$$
		\p(E|F) = \frac{\p(F | E) \cdot \p(E)}{\p(F)} 
		$$
	</p>

	<p>There are names for the different terms in the Bayes Rule formula. The term $\p(E|F)$  is often called the
"posterior". The term $\p(E)$ is often called the "prior". The term $\p(F|E)$ is called the update and $\p(F)$ is
often called the normalization constant.</p>

<p>There are several techniques for handling the case where the denominator is not know. One technique is to use the law of total probability to expand out the term, resulting in another formula, also called Bayes' Theorem:
$$
\p(E|F) = \frac{\p(F | E) \cdot \p(E)}{\p(F|E)\cdot \p(E) + \p(F|E\c) \cdot \p(E\c)} 
$$
</p>
Recall the law of total probability which is responsible for our new denominator:
$$
\begin{align}
\p(F) &= \p(F \and E) + \p(F \and E\c)\\
&= \p(F|E)\cdot \p(E) + \p(F|E\c) \cdot \p(E\c)
\end{align}
$$
</div>
</p>

<p>A common scenario for applying the Bayes Rule formula is when you want to know the probability of
something “unobservable” given an “observed” event. For example, you want to know the probability that a
student understands a concept, given that you observed them solving a particular problem. It turns out it is
much easier to first estimate the probability that a student can solve a problem given that they understand the
concept and then to apply Bayes Theorem. Intuitively, you can think about this as updating a belief given
evidence.</p>

<h2>Unknown normalization constant</h2>

<p>There are times when we would like to use Bayes Theorem to update a belief, but there is no way to calculate
the probability of the event observed, P(F). All hope is not lost. In such situations we can still calculate
the relative probability of events. For example, imagine we would like to answer the question, is even A
or event B more likely given an observation F. We can express this mathematically as calculating whether
P(A|F)/P(B|F) is greater than or equal to 1. Both of those terms can be expanded using Bayes, and when
they are expanded the P(F) term cancels out:</p>