
<!DOCTYPE html>
<html>

<head>
    

<title>Bayes&#039; Theorem</title>

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta http-equiv="content-type" content="text/html; charset=UTF8">

<!-- jQuery CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

<!-- Firebase CDN -->
<script src='https://cdn.firebase.com/js/client/2.2.1/firebase.js'></script>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="../../../css/style.css">
   

<!-- Java Script -->
<script src="../../../plugins/moment.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

<!-- Python highlighting -->
<script src="../../../plugins/prism/prism.js"></script>
<link href="../../../plugins/prism/prism.css" rel="stylesheet" />

<!-- Probability Packages -->
<script src="../../../js/probabilityUtils.js"></script>
<script src="../../../plugins/probability/gaussian.js"></script>
<script src="../../../plugins/color.js"></script>

<!-- font awesome -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css" integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">

<!-- SWAL -->
<script src="https://cdn.jsdelivr.net/npm/sweetalert2@10"></script>


<!-- Stanford -->
<link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Source+Serif+Pro:400,600,700' rel='stylesheet' type='text/css'>
<link href="https://fonts.googleapis.com/css?family=Crimson+Text" rel="stylesheet">

<!-- Math Jax -->
<!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script> -->
<script type="text/javascript">
  MathJax = {
    config: ["MMLorHTML.js"],
    jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML"],
    extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js"],
    TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js", "action.js"]
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    },
	"fast-preview": {
	  disabled: true
	}
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>



<script src="../../../plugins/math.min.js"></script>



    <!-- Popper.JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js" integrity="sha384-cs/chFZiN24E4KMATLdqdvsezGxaGsi4hLGOzlXwp5UZB1LY//20VyM2taTB4QvJ" crossorigin="anonymous"></script>
    <!-- Bootstrap JS -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js" integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm" crossorigin="anonymous"></script>

 <!-- Scrollbar Custom CSS -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/malihu-custom-scrollbar-plugin/3.1.5/jquery.mCustomScrollbar.min.css">
    <script src="../../../plugins/jquery.mCustomScrollbar.js"></script>

</head>


<!-- I declare a few math operators I often use in equations -->
<div style="display:none">
  $\DeclareMathOperator{\p}{Pr}$
  $\DeclareMathOperator{\P}{Pr}$
  $\DeclareMathOperator{\c}{^C}$
  $\DeclareMathOperator{\or}{  or}$
  $\DeclareMathOperator{\and}{  and}$
  $\DeclareMathOperator{\var}{Var}$
  $\DeclareMathOperator{\E}{E}$
  $\DeclareMathOperator{\std}{Std}$
</div>

<body class="greyBackground">


    <div class="wrapper">
        <!-- Sidebar  -->
<nav id="sidebar">
    <div class="sidebar-header">
        <!-- <div></div> -->
        <a style="text-align:center" href="../../"><h3><i class="fas fa-book-open"></i><br/> Probability for a <br/>Digital World<br/></h3></a>
    </div>

    <div> 
        <div class="searchCol" style="font-family: 'Source Sans Pro', sans-serif;">
            <!-- This adds a search bar! -->
            <input type="text" class="form-control bookSearch" id="probability-for-digital-world-search" aria-describedby="search box" placeholder="üîç Search book..."/>
        </div>
        <!-- The magnifying glass icon -->
        
    </div>

<!-- intro -->
<ul class="list-unstyled components">
<li>
<a id=sidebar-intro href="../../intro/intro">Introduction</a>
<a id=sidebar-notation href="../../intro/notation">Notation</a>
<a id=sidebar-prob_code href="../../intro/prob_code">Probability in Code</a>
</li>
</ul>

<!-- part1 -->
<ul class="list-unstyled components">
<li><p href="{pathToLang}part1">Part 1: Core Probability</p></li>
<li>
<a id=sidebar-counting href="../../part1/counting">Counting</a>
<a id=sidebar-combinatorics href="../../part1/combinatorics">Combinatorics</a>
<a id=sidebar-probability href="../../part1/probability">Definition of Probability</a>
<a id=sidebar-equally_likely href="../../part1/equally_likely">Equally Likely Outcomes</a>
<a id=sidebar-prob_or href="../../part1/prob_or">Probability of <b>or</b></a>
<a id=sidebar-cond_prob href="../../part1/cond_prob">Conditional Probability</a>
<a id=sidebar-independence href="../../part1/independence">Independence</a>
<a id=sidebar-prob_and href="../../part1/prob_and">Probability of <b>and</b></a>
<a id=sidebar-law_total href="../../part1/law_total">Law of Total Probability</a>
<a id=sidebar-bayes_theorem href="../../part1/bayes_theorem">Bayes' Theorem</a>
<a id=sidebar-log_probabilities href="../../part1/log_probabilities">Log Probabilities</a>
</li>
</ul>

<!-- part2 -->
<ul class="list-unstyled components">
<li><p href="{pathToLang}part2">Part 2: Random Variables</p></li>
<li>
<a id=sidebar-rvs href="../../part2/rvs">Random Variables</a>
<a id=sidebar-pmf href="../../part2/pmf">Likelihood Functions</a>
<a id=sidebar-expectation href="../../part2/expectation">Expectation</a>
<a id=sidebar-variance href="../../part2/variance">Variance</a>
<a id=sidebar-binomial href="../../part2/binomial">Bernoulli and Binomial</a>
<a id=sidebar-poisson href="../../part2/poisson">Poisson Distribution</a>
<a id=sidebar-continuous href="../../part2/continuous">Continuous Distribution</a>
<a id=sidebar-normal href="../../part2/normal">Normal Distribution</a>
<a id=sidebar-convolution href="../../part2/convolution">Convolution</a>
<a id=sidebar-all_distributions href="../../part2/all_distributions">Random Variable Reference</a>
</li>
</ul>

<!-- part3 -->
<ul class="list-unstyled components">
<li><p href="{pathToLang}part3">Part 3: Probabilistic Models</p></li>
<li>
<a id=sidebar-joint href="../../part3/joint">Joint Probability</a>
<a id=sidebar-independent_vars href="../../part3/independent_vars">Independence in Variables</a>
<a id=sidebar-cond_distributions href="../../part3/cond_distributions">Conditional Distributions</a>
<a id=sidebar-variable_bayes href="../../part3/variable_bayes">Bayes Theorem Revisited</a>
<a id=sidebar-continuous_joint href="../../part3/continuous_joint">Continuous Joint</a>
<a id=sidebar-multivariate_gaussian href="../../part3/multivariate_gaussian">Multivariate Gaussian</a>
<a id=sidebar-bayesian_networks href="../../part3/bayesian_networks">Bayesian Networks</a>
<a id=sidebar-sampling_revisited href="../../part3/sampling_revisited">Sampling Revisited</a>
<a id=sidebar-computational_inference href="../../part3/computational_inference">Computational Inference</a>
</li>
</ul>

<!-- part4 -->
<ul class="list-unstyled components">
<li><p href="{pathToLang}part4">Part 4: Uncertainty Theory</p></li>
<li>
<a id=sidebar-clt href="../../part4/clt">Central Limit Theorem</a>
<a id=sidebar-bootstrapping href="../../part4/bootstrapping">Bootstrapping</a>
<a id=sidebar-parameters href="../../part4/parameters">Uncertainty in Parameters</a>
<a id=sidebar-beta href="../../part4/beta">Beta Distribution</a>
<a id=sidebar-bounds href="../../part4/bounds">Probability Bounds</a>
</li>
</ul>

<!-- part5 -->
<ul class="list-unstyled components">
<li><p href="{pathToLang}part5">Part 5: Machine Learning</p></li>
<li>
<a id=sidebar-mle href="../../part5/mle">Maximum Likelihood Estimation</a>
<a id=sidebar-map href="../../part5/map">Maximum A Posteriori</a>
<a id=sidebar-naive_bayes href="../../part5/naive_bayes">Na√Øve Bayes</a>
<a id=sidebar-optimization href="../../part5/optimization">Gradient Ascent Optimization</a>
<a id=sidebar-linear_regression href="../../part5/linear_regression">Linear Regression</a>
<a id=sidebar-log_regression href="../../part5/log_regression">Logistic Regression</a>
<a id=sidebar-neural_nets href="../../part5/neural_nets">Artificial Neural Networks</a>
</li>
</ul>



    <ul class="list-unstyled components">
        
         <li>
            <p>Part ?: Misfits</p>
        </li>
        <li>
            
             <a href="../../">Sampling from a likelihood function</a>
             <a href="../../">Law of Total Expectation</a>
            
        </li>
    </ul>



    <ul class="list-unstyled CTAs">
        <li>
            ‚í∏ Chris Piech, Stanford University
            <!-- <a href="https://compedu.stanford.edu/codeinplace/v1/#/course" class="download">Back to Code in Place</a> -->
        </li>
    </ul>
</nav>
        <!-- Page Content  -->
        <div id="content">

<button type="button" id="sidebarCollapse" class="mobile-only btn btn-dark">
    <i class="fas fa-align-left"></i>
    <span></span>
</button>
            <button id="curiosityButton" onclick = "onCuriosity()" type="button" class="btn btn-primary btn-sm">
              <i class="fas fa-question-circle" style="font-size:200%"></i>
              <span></span>
          </button>
            
            <div class="container-fluid">
                <div class="row d-flex justify-content-center">
                    <div class="col handout" >
              
                        
 
 <center><h1>Bayes' Theorem</h1></center>
<hr/>

<p>Bayes' Theorem is one of the most ubiquitous results in probability for computer scientists. Very often we
know a conditional probability in one direction, say $\p(E|F)$, but we would like to know the conditional
probability in the other direction $\p(F |E)$. Bayes' Theorem provides a way to convert from one to the other. We can
derive Bayes' Theorem by starting with the definition of conditional probability and then expanding the and term using the chain rule:


$$
\begin{align}
\p(F|E) 
&= \frac{\p(F \and E)}{\p(E)} && \text{Def of }
\href{ ../../part1/cond_prob/}{\text{conditional probability}}

  \\
&= \frac{\p(E | F) \cdot \p(F)}{\p(E)} && \text{Substitute the }
\href{ ../../part1/cond_prob/#chain_rule}{\text{chain rule}}
\end{align}
$$

<p>
This theorem makes no assumptions about $E$ or $F$ so it will apply for any two events. Bayes' theorem allows you to use knowledge of a conditional probability in one direction, $\p(E | F$), to calculate the probability of the condional in the other direction $\p(F | E)$. It turns out to be exceptionally useful because it is the ubiquitous way to answer the question, how can I update a belief about something which is not directly observable given evidence. For many "noisy evidence measures" it is much easier to calculate out the probability of the evidence given the true state of the world, but what you would really like to know is the conditional probability the other way around: what is the probability of the true state of the world given evidence.  There are countless real world situations that fit this situation:
</p>
<p>
	<div class="purpleBox">
	<b>Example 1: Medical tests</b><br/>
<i>What you want to know:</i> Probability of a disease given a test result<br/>
<i>What is easy to know:</i> Probability of a test result given the true state of disease<br/>
<i>Causality:</i> We believe that diseases influences test results
</p>

<p>
	<b>Example 2: Student ability</b><br/>
<i>What you want to know:</i> Student knowledge of a subject given their answers<br/>
<i>What is easy to know:</i> Likelihood of answers given a student's knowledge of a subject<br/>
<i>Causality:</i> We believe that ability influences answers 
</p>

<p>
	<b>Example 3: Cell phone location</b><br/>
<i>What you want to know:</i> Where is a cell phone, given noisy measure of distance to tower<br/>
<i>What is easy to know:</i> Error in noisy measure, given the true distance to tower<br/>
<i>Causality:</i> We believe that cell phone location influences distance measure
</div>
</p>


<p>
	There is a pattern here: in each example we care about knowing some unobservable -- or hard to observe -- state of the world. This state of the world "causes" some easy-to-observe evidence. For example: having the flu (something we would like to know) <b><i>causes</i></b> a fever (something we can easily observe), not the other way around. We often call the unobservable state the "belief" and the observable state the "evidence". For that reason lets rename the events! Lets call the unobservable thing we want to know $B$ for belief. Lets call the thing we have evidence of $E$ for evidence. This makes is clear that Bayes' theorem allows us to calculate an updated belief given evidence: $\p(B | E)$
</p>

</p>

<p>
<div class="bordered">
	<b><i>Definition</i></b>: Bayes' Theorem <br/>

	<p> The most common form of Bayes' Theorem is 
		<b>Bayes' Theorem Classic</b>:
		$$
		\p(B|E) = \frac{\p(E | B) \cdot \p(B)}{\p(E)} 
		$$
	</p>

	<p>There are names for the different terms in the Bayes' Rule formula. The term $\p(B|E)$  is often called the
"posterior": it is your updated belief of $B$ after you take into account evidence $E$. The term $\p(B)$ is often called the "prior": it was your belief before seeing any evidence. The term $\p(E|B)$ is called the update and $\p(E)$ is
often called the normalization constant.</p>

<p>There are several techniques for handling the case where the denominator is not know. One technique is to use the law of total probability to expand out the term, resulting in another formula, called <b>Bayes' Theorem with Law of Total Probability</b>:
$$
\p(B|E) = \frac{\p(E | B) \cdot \p(B)}{\p(E|B)\cdot \p(B) + \p(E|B\c) \cdot \p(B\c)} 
$$
</p>
Recall the law of total probability which is responsible for our new denominator:
$$
\begin{align}
\p(E) = \p(E|B)\cdot \p(B) + \p(E|B\c) \cdot \p(B\c)
\end{align}
$$
</div>
</p>

<p>A common scenario for applying the Bayes' Rule formula is when you want to know the probability of
something ‚Äúunobservable‚Äù given an ‚Äúobserved‚Äù event. For example, you want to know the probability that a
student understands a concept, given that you observed them solving a particular problem. It turns out it is
much easier to first estimate the probability that a student can solve a problem given that they understand the
concept and then to apply Bayes' Theorem. Intuitively, you can think about this as updating a belief given
evidence.</p>

<h2>Bayes' Theorem Applied</h2>

<p>Sometimes the (correct) results from Bayes' Theorem can be counter intuitive. Here we work through a classic result: Bayes' applied to medical tests. We show a dynamic solution and present a visualization for understanding what is happening.</p>


<p>

<div class="purpleBox">
	<p><b><i>Example:</i></b> Probability of a disease given a noisy test</p>
<p>In this problem we are going to calculate the probability that a patient has an illness given test-result for the illness. A positive test result means the test thinks the patient has the illness. Things that we neeed to know: The  percent of the population that has the illness. The probability the test returns a positive test for a patient with the disease. The probability the test returns a positive test for a patient who does not have the disease.
</p>

<div class="form-group">
				    <label for="exampleInputEmail1">Natural % of population with illness</label>
				    <input type="number" class="form-control" id="priorInput" value="8">
				  </div>
				  <div class="form-group">
				    <label for="exampleInputPassword1">Probability of a positive result given the patient has illness</label>
				    <input type="number" class="form-control" id="condInput" value="0.95">
				  </div>
				  <div class="form-group">
				    <label for="exampleInputPassword1">Probability of a positive result given the patient does not have illness</label>
				    <input type="number" class="form-control" id="condNegInput" value="0.07">
				  </div>

				  <p><button id="calcButton" class="btn btn-success" onclick="recalculate();">Recalculate probability of disease given positive test result</button></p>
				  
<p>The numbers in this example are from the Mamogram test for breast cancer. The seriousness of cancer underscores the potential for bayesian probability to be applied to important contexts. The natural occurence of breast cancer is 8%. The mamogram test returns a positive result 95% of the time for patients who have breast cancer. The test resturns a positive result 7% of the time for people who do not have breast cancer. In this demo you can enter different probabilities and calculate the corresponding chance of disease given a positive test result.</p>

 <hr/> 

				  
<p><b><i>Answer</i></b></p>

<p>

</p>

				  <p>
				  	The probability that the patient has the illness given a positive test result is: <span class="ansValue"></span>
				  </p>
				 
				  <div id="explination" >
				  	
					  
					  <div id="answer">
					  	<p>
					  		<b>Terms:</b><br/>
					  				Let $I$ be the event that the patient has the illness<br/>
					  				Let $E$ be the event that the test result is positive<br/>
					  				$\p(I|E)$ = probability of the illness given a positive test. This is the number we want to calculate.<br/>
					  				$\p(E|I)$ = probability of a positive result given illness = <span class="condValue"></span><br/>
					  				$\p(E|I\c)$ = probability of a positive result given no illness = <span class="condNegValue"></span><br/>
					  				$\p(I)$ = natural probability of the illness = <span class="priorValue"></span>
					  	</p>
					  	<p><b>Bayes Theorem:</b><br/>
					  	
					  		In this problem we know $\p(E|I)$ and $\p(E|I\c)$ but we want to know $\p(I|E)$. We can apply Bayes Theorem to turn our knowledge of one conditional into knowledge of the reverse.
					  	</p>

					  	<p >
					  		$$\begin{align}\p(I|E) &= \frac{\p(E|I)P(I)}{\p(E|I)\p(I) + \p(E|I\c)\p(I\c)} && \text{Bayes' Theorem with Total Prob.}\end{align}$$
					  	</p>
					  		Now all we need to do is plug values into this formula. The only value we don't explicitly have is $\p(I\c)$. But we can simply calculate it since $\p(I\c) = 1 - \p(I)$. Thus:
						</p>

						<p id="bayesApplied">
					  		
					  	</p>
					  </div>
				</div>
			</div>

			<h2>Natural Frequency Intuition</h2>
				<p>
							One way to build intuition for Bayes Theorem is to think about "natural frequences". Let's take another approach at answer the probability question in the above example on belief of illness given a test. In this take, we are going to imagine we have a population of 1000 people. Let's think about how many of those have the illness and test positive and how many don't have the illness and test positive. This visualization is based off the numbers in the fields above. Feel free to change them!
						</p>

						<p>
							There are many possibilities for how many people have the illness, but one very plaussible number is 1000, the number of people in our population, multiplied by the probability of the disease.</p>
						<p class="indent">
							$1000 \times \p(\text{Illness})$ people have the illness<br/>
							$1000 \times (1- \p(\text{Illness}))$ people do not have the illness.
						</p>
						<p>
							We are going to color people who <span style="color:LightSkyBlue"><b>have the illness</b></span> in blue and those <span style="color:LightPink"><b>without the illness</b></span> in pink (those colors do not imply gender!). 
						</p>
						
						<p>
							A certain number of people <span style="color:DodgerBlue"><b>with the illness will test positive</b></span> (which we will draw in Dark Blue) and a certain number of people <span style="color:HotPink"><b>without the illness will test positive</b></span> (which we will draw in Dark Pink):
						</p>
						<p class="indent">
							$1000 \times \p(\text{Illness}) \times \p(\text{Positive}|\text{Illness})$ people have the illness and test positive<br/>
							$1000 \times \p(\text{Illness}\c) \times \p(\text{Positive}|\text{Illness}\c)$ people do not have the illness and test positive.
						</p>
						<p>
							Here is the whole population of 1000 people:
						</p>

						<p>
							<canvas style="width:100%; height:370px;" id="naturalFrequencyCanvas"></canvas>
						</p>
						<p>
							
							The number of people who <span style="color:DodgerBlue"><b>test positive and have the illness</b></span> is <span class="naturalTruePosValue">?</span>. <br/>
							The number of people who <span style="color:HotPink"><b>test positive and don't have the illness</b></span> is <span class="naturalFalsePosValue">?</span>. <br/>
							The total number of people who test positive is <span class="naturalPosValue">?</span>. 

						</p>
						<p>
							Out of the subset of people who test positive, the fraction that have the illness is <span class="naturalTruePosValue">?</span>/<span class="naturalPosValue">?</span> = <span class="naturalAprox">?</span> which is a close approximation of the answer. If instead of using 1000 imaginary people, we had used more, the approximation would have been even closer to the actual answer (which we calculated using Bayes Theorem).
						</p>





		
		
		
				
		<script>
			function recalculate() {
				calculate()
				MathJax.typeset()
			}

			function calculate() {
				$("#calcButton").html('Re-calculate probability of disease given positive test result')
				var cond = $("#condInput").val() 
				var condNeg = $("#condNegInput").val()
				var prior = $("#priorInput").val() / 100

				/*if(cond > 1 || cond < 0 || condNeg > 1 || condNeg < 0) {
					alert("all probabilities must be between 0 and 1");
					return;
				}*/

				

				var ans = (cond * prior) / (cond * prior + condNeg * (1 - prior))
				ans = ans.toFixed(4)

				$(".condValue").html(cond)
				$(".condNegValue").html(condNeg)
				$(".priorValue").html(prior)
				$(".ansValue").html(ans)

				$("#bayesApplied").html('$$P(I|E) = \\frac{('+ cond +')('+ prior +')}{('+cond+')('+prior+') + ('+condNeg+')(1 - ' + prior+')} = '+ans+'$$');

				
				$("#explination").show()

				drawNaturalFrequencies(prior, cond, condNeg);
			}

			function drawNaturalFrequencies(prior, cond, condNeg){
				var width = $("#naturalFrequencyCanvas").outerWidth();
				var height =  0.6* width;
				$("#naturalFrequencyCanvas").height(height);
				console.log($("#naturalFrequencyCanvas").height())
				console.log()
				var canvas = document.getElementById('naturalFrequencyCanvas');
				canvas.width = width;
				canvas.height = height;
				var ctx = canvas.getContext('2d');

				var N_ROWS = 20
				var N_COLS = 50
				var SPACING = 5

				var ICON_WIDTH = (width - (N_COLS - 1)*SPACING) / N_COLS
				var ICON_HEIGHT = (height - (N_ROWS - 1) * SPACING) / N_ROWS
				console.log(ICON_WIDTH)
				console.log(ICON_HEIGHT)

				var numSick = prior * 1000
				var numSickPos = numSick * cond
				var numHealthPos = (1-prior) * 1000 * condNeg
				

				var index = 0
				for (var c = 0; c < N_COLS; c++) {
			    	for(var r = 0; r < N_ROWS; r++) {
			    		if(index < numSickPos){
			    			ctx.fillStyle = "DodgerBlue";
			    		} else if(index < numSick){
			    			ctx.fillStyle = "LightSkyBlue";
			    		} else if(index < numSick + numHealthPos) {
			    			ctx.fillStyle = "HotPink";
			    		} else {
			    			ctx.fillStyle = "LightPink";
			    		}
			    		var x = c * (SPACING + ICON_WIDTH)
			    		var y = r * (SPACING + ICON_HEIGHT)
			    		drawPerson(ctx, x, y, ICON_WIDTH, ICON_HEIGHT)
			    		index++
			    		
			    	}
			    }

			    var numPos = Math.ceil(numSickPos) + Math.ceil(numHealthPos)
			    var naturalAprox = (Math.ceil(numSickPos) / numPos).toFixed(4)
			    $(".naturalPosValue").html(numPos);
			    $(".naturalTruePosValue").html(Math.ceil(numSickPos));
			    $(".naturalFalsePosValue").html(Math.ceil(numHealthPos));
			    $(".naturalAprox").html(naturalAprox)
			}

			function drawPerson(ctx, x, y, width, height) {
				// head
				var headRadius = height * 0.15
				filledCircle(ctx, x + width * 0.5, y + headRadius, headRadius);

				// arms
				ctx.fillRect(x, y + height * 0.3, width, height *.4)	

				// body
				ctx.fillRect(x + width *.15, y + height * 0.3, width*.7, height *.8)
			}

			function filledCircle(ctx, x, y, r) {
				ctx.beginPath();
				ctx.arc(x, y, r, 0, Math.PI*2, true); 
				ctx.closePath();
				ctx.fill();
			}

			calculate()
			drawNaturalFrequencies(0.08, 0.95, 0.07)
			
			
		</script>
</p>

<h2>Unknown Normalization Constant, $\p(E)$</h2>

<p>There are times when we would like to use Bayes' Theorem to update a belief, but we don't know the probability of $E$, $\p(E)$. All hope is not lost. This term is called the "normalization constant" because it is the same regardless of whether or not the event $B$ happens. The most traditional solution is to use the law of total probability: $\p(E) = \p(E |B) \p(B) + \p(E|B\c)\p(B\c)$. Here are some other useful "tricks" for dealing with $\p(E)$. </p>




<p>
	We can make the normalization cancel out by calculating the ratio of $\frac{\p(B|E)}{\p(B\c|E)}$. This fraction tells you how many times more likely it is that $B$ will happen given $E$ than not $B$:
$$
\begin{align}
\frac{\p(B|E)}{\p(B\c|E)} 
&= \frac{
	\frac{\p(E|B)\p(B)}{\p(E)}
}{
	\frac{\p(E|B\c)\p(B\c)}{\p(E)}
}
&& \text{Apply Bayes' Theorm to both terms} \\
&= \frac{
	\p(E|B)\p(B)
}{
	\p(E|B\c)\p(B\c)
}
&& \text{The term $\p(E)$ cancels}
\end{align}
$$
	</p>

	<p>
We can always use the fact that either $B$ will happen or it won't when consistently conditioned on $E$:  $\p(B |E) + \p(B\c|E) =1$ to compute $\p(E)$. Note that this is the simply the <a href="../../part1/cond_prob/#cond_paradigm">first identity of probability</a>, consistently conditioning:
$$
\begin{align}
1 &= \p(B|E) + \p(B\c|E) 
&& \text{Either $B$ occurs or it doesn't} \\

1 &= \frac{\p(E|B)\p(B)}{\p(E)}
 + 
\frac{\p(E|B\c)\p(B\c)}{\p(E)}
&& \text{Apply Bayes' Theorem to both terms}
\\

1 &= \frac{1}{\p(E)} \cdot \big[\p(E|B)\p(B) + \p(E|B\c)\p(B\c)\big]
&& \text{Factor out $1/ \p(E)$} \\

\p(E) &= \p(E|B)\p(B) + \p(E|B\c)\p(B\c)
&& \text{Rearrange terms}
\end{align}
$$
If you look closely at the last line, you will notice that we have simply found a new way to derive the total law of probability for $E$. The law of total probability is truly a great way of dealing with $\p(E)$.
	</p>

	<h2>Bayes with the General Law of Total Probability</h2>

	<p>The way to work around not directly knowing $P(B)$ employed by the expanded version of Bayes was to
use the simple case of the law of total probability. In other contexts you may want to use the more general
version of the law. For example say we are trying to track a phone which could be in any one of $n$ discrete
locations and we have prior beliefs $\p(B_1) \dots \p(B_n)$ as to whether the phone is in location $B_i$. Now we gain
some evidence (such as a particular signal strength from a particular cell tower) that we call $E$ and we need
to update all of our probabilities to be $\p(B_i
|E)$. We should use Bayes' Theorem!</p>

<p>The probability of the observation, assuming that the the phone is in location $B_i$, $\p(E|B_i)$, is something that
can be given to you by an expert. In this case the probability of getting a particular signal strength given a
location $B_i$ will be determined by the distance between the cell tower and location $B_i$
.</p>
<p>Since we are assuming that the phone must be in <i>exactly</i> one of the locations, we can find the probability of
any of the event $B_i$ given $E$ by first applying Bayes' Theorem and then applying the general version of the law of
total probability:</p>
$$
\begin{align}
\p(B_i | E) &= \frac{\p(E|B_i) \cdot \p(B_i)}{\p(E)}
&& \text{Bayes Theorem. What to do about $\p(E)$?} \\
 &= \frac{\p(E|B_i) \cdot \p(B_i)}{\sum_{i=1}^n \p(E|B_i) \cdot \p(B_i)}
&& \text{Use General Law of Total Probability for $\p(E)$} \\
\end{align}
$$




<!-- <p>
	If you compute: 
	$$
	\begin{align}
	\p(B | E) &\propto \p(E|B)\p(B) \\
	\p(B\c | E) &\propto \p(E|B\c)\p(B\c) 
	\end{align}
	$$
</p> -->

	
<!-- 
	<h2>Unknown Prior, $\p(B)$</h2> -->

               

<!-- Firebase App (the core Firebase SDK) is always required and must be listed first -->
  <script src="https://www.gstatic.com/firebasejs/8.1.2/firebase-app.js"></script>

  <!-- If you enabled Analytics in your project, add the Firebase SDK for Analytics -->
  <script src="https://www.gstatic.com/firebasejs/8.1.2/firebase-analytics.js"></script>

  <!-- Add Firebase products that you want to use -->
  <script src="https://www.gstatic.com/firebasejs/8.1.2/firebase-auth.js"></script>
  <script src="https://www.gstatic.com/firebasejs/8.1.2/firebase-firestore.js"></script>


<script type="text/javascript">
    // const firebase = require("firebase");
    // Required for side-effects
    // require("firebase/firestore");

    $(document).ready(function () {

        const hasStorage = typeof(Storage) !== "undefined"
        const scrollTop = getScrollTop()
        console.log(scrollTop)
        $("#sidebar").mCustomScrollbar({
            theme: "minimal",
            mouseWheel: {preventDefault: true},
            advanced:{
             autoScrollOnFocus: false,
             updateOnContentResize: true
            },
            scrollInertia:0,
            setTop:scrollTop + 'px',
            callbacks:{
                onScroll:function(){
                    if(hasStorage) {

                        localStorage.scrollTop = this.mcs.top;
                        console.log(localStorage.scrollTop)
                    }
                }
            } 
        });

        $('#sidebarCollapse').on('click', function () {
            $('#sidebar, #content').toggleClass('active');
            $('.collapse.in').toggleClass('in');
            $('a[aria-expanded=true]').attr('aria-expanded', 'false');
        });

        
        let lastPart = getUrlKey()

        // $(".scroller-back").mCustomScrollbar("scrollTo", $("#" +scrollKey), {
        //     scrollInertia:0
        // });

        // addExampleToFirebase()
    });

    function getScrollTop() {
        if(typeof(Storage) !== "undefined") {
            return Number(localStorage.scrollTop)
        }
        return 0;
    }

    function getUrlKey() {
        var pathname = window.location.pathname;
        
        let parts = pathname.split('/')
        var currIndex = parts.length - 1
        while(currIndex >= 0) {
            let nextPart = parts[currIndex]
            if(nextPart) {
                return nextPart
            }
            currIndex -= 1
        }
        return ''
    }

    function submitQuestion() {
        firebase.initializeApp({
          apiKey: "AIzaSyBqZVV7Qrp0DT3aBCCTCTMUCrPJO0pb3tY",
          authDomain: "probability-digital-world.firebaseapp.com",
          projectId: "probability-digital-world"
        });

        var db = firebase.firestore();

        db.collection("questions").add({
            email: $("#question-email").val(),
            question: "Lovelace",
            page: getUrlKey()
        })
        .then(function(docRef) {
            console.log("Document written with ID: ", docRef.id);
            alert('success')
        })
        .catch(function(error) {
            console.error("Error adding document: ", error);
        });
        // // // Generate a new push ID for the new post
        // var questionListRef = db.child("questions")
        // var newQuestionRef = questionListRef.push();
        // newQuestionRef.set({
        //     'title':'test'
        // });
        
    }

    function onCuriosity() {
        Swal.fire({
          title: 'Curious?',
          position: 'bottom-end',
          allowOutsideClick:false,
          backdrop:false,
          confirmButtonText: 'Submit',
          input: 'textarea',
          html:
            '<p>We are trying to make this book better. Let us know if you find something confusing. If you ask a question we will try to answer it. If you find a mistake we will fix it. </p>' +
            '<input placeholder="Your email (optional)..." id="question-email" class="swal2-input">',
          inputPlaceholder: 'Type your question or message here...',
          inputAttributes: {
            'aria-label': 'Type your question or message here'
          },
          showCancelButton: true,
          preConfirm: () => submitQuestion()
        })
    }
</script>

<script src="sweetalert2.all.min.js"></script>
<!-- Optional: include a polyfill for ES6 Promises for IE11 -->
<script src="https://cdn.jsdelivr.net/npm/promise-polyfill"></script>                
                    </div>
                </div>
            </div>
        </div>
    </div>

</body>




</html>