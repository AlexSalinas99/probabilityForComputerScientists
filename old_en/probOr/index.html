
<!DOCTYPE html>
<html>

<head>
    

<title>Probability of or</title>

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta http-equiv="content-type" content="text/html; charset=UTF8">

<!-- jQuery CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>



<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="../../css/style.css">
   

<!-- Java Script -->
<script src="../../plugins/moment.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

<!-- Python highlighting -->
<script src="../../plugins/prism/prism.js"></script>
<link href="../../plugins/prism/prism.css" rel="stylesheet" />

<!-- Probability Packages -->
<script src="../../js/probabilityUtils.js"></script>
<script src="../../plugins/probability/gaussian.js"></script>
<script src="../../plugins/color.js"></script>

<!-- font awesome -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css" integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">

<!-- SWAL -->
<script src="https://cdn.jsdelivr.net/npm/sweetalert2@9"></script>


<!-- Stanford -->
<link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Source+Serif+Pro:400,600,700' rel='stylesheet' type='text/css'>

<!-- Math Jax -->
<!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script> -->
<script type="text/javascript">
  MathJax = {
    config: ["MMLorHTML.js"],
    jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML"],
    extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js"],
    TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js", "action.js"]
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    },
	"fast-preview": {
	  disabled: true
	}
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>



<script src="../../plugins/math.min.js"></script>



    <!-- Popper.JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js" integrity="sha384-cs/chFZiN24E4KMATLdqdvsezGxaGsi4hLGOzlXwp5UZB1LY//20VyM2taTB4QvJ" crossorigin="anonymous"></script>
    <!-- Bootstrap JS -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js" integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm" crossorigin="anonymous"></script>

 <!-- Scrollbar Custom CSS -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/malihu-custom-scrollbar-plugin/3.1.5/jquery.mCustomScrollbar.min.css">
    <script src="../../plugins/jquery.mCustomScrollbar.js"></script>

</head>


<!-- I declare a few math operators I often use in equations -->
<div style="display:none">
  $\DeclareMathOperator{\p}{Pr}$
  $\DeclareMathOperator{\c}{^C}$
  $\DeclareMathOperator{\or}{  or}$
  $\DeclareMathOperator{\and}{  and}$
</div>

<body class="greyBackground">

    <div class="wrapper">
        <!-- Sidebar  -->
<nav id="sidebar">
    <div class="sidebar-header">
        <a href="../"><h3><i class="fas fa-home"></i> Probability for CS</h3></a>
    </div>

    <ul class="list-unstyled components">
       <!--  <p>Chris Piech</p> -->

       <li>
            <a href="../freeBook">A Free Online Textbook</a>
        </li>
        
        <li>
            <a href="../intro">Introduction</a>
            <a href="../notation">Notation</a>
            <a href="../python">Probability in Python</a>
        </li>
    </ul>

    <ul class="list-unstyled components">
        <li>
            <p>Part I: Core Probability</p>
        </li>

        <li>
            <a href="../notation">Notation</a>
        </li>

         <li>
            <a href="../">Combinatorics</a>
        </li>

        <li>
            <a href="../probability">Definition of Probability</a>
        </li>

        

        

        <!-- <li><a><b>Part 1: Analytic Probability</b></a></li> -->

        <li>
            <a href="../counting">Counting</a>
        </li>

        

        <li>
            <a href="../equallyLikely">Equally Likely Outcomes</a>
        </li>

        <li>
            <a href="../probOr">Probability of <b><i>or</i></b></a>
        </li>

        <li>
            <a href="../probAnd">Probability of <b><i>and</i></b></a>
        </li>

        <li>
            <a href="../conditional">Conditional Probability</a>
        </li>

        <li>

            <a href="../totalProbability">Law of Total Probability</a>
        </li>

        <li>
            <a href="../bayesTheorem">Bayes' Theorem</a>

            <a href="../probability">Randomness in Computers</a>
        </li>

        <li>
            <a href="../probability">Log Probabilities</a>
        </li>

         <!-- <li><a><b>Part 2: Random Variables</b></a></li> -->

        


        

    </ul>

    <ul class="list-unstyled components">
        
         <li>
            <p>Part II: Random Variables</p>
        </li>
        <li>
             
             <a href="../">Likelihood Functions</a>
             <a href="../">Expectation</a>
             <a href="../">Variance</a>

             <a href="../">Bernoulli and Binomial</a>
             <a href="../">Poisson</a>
             <a href="../">Continuous Distributions</a>
             <a href="../">Normal Disribution</a>
             <a href="../">Convolution</a>
             <a href="../">Parametric Variable List</a>

              
        </li>
    </ul>


    <ul class="list-unstyled components">
        
         <li>
            <p>Part III: Probabilistic Models</p>
        </li>
        <li>
             <a href="../">Joint Probability</a>
             <a href="../">Independence in Variables</a>
             <a href="../">Conditional Distributions</a>
             <a href="../">Inference</a>
             <a href="../">Bayesian Networks</a>
             <a href="../">Continuous Joint</a>
             <a href="../">Multivariate Gaussian</a>
             
              <a href="../">Computational Inference</a>
              
             
             
        </li>
    </ul>

       <ul class="list-unstyled components">
        
         <li>
            <p>Part IV: Uncertainty Theory</p>
        </li>
        <li>
             <a href="../">Central Limit Theorem</a>
             <a href="../">Bootstrapping</a>
             <a href="../">Parameters</a>
             <a href="../">Beta Distributions</a>
             <a href="../">Probability Bounds</a>              
        </li>
    </ul>

    <ul class="list-unstyled components">
        
         <li>
            <p>Part V: Machine Learning</p>
        </li>
        <li>
            <a href="../">Maximum Likelihood Estimation</a>
             <a href="../">Maximum A Posteriori</a>
              <a href="../">Naïve Bayes</a>
              <a href="../">Gradient Ascent Optimization</a>
              <a href="../">Logistic Regression</a>
              <a href="../">Artificial Neural Networks</a>
        </li>
    </ul>

    <ul class="list-unstyled components">
        
         <li>
            <p>Part ?: Misfits</p>
        </li>
        <li>
            
             <a href="../">Sampling from a likelihood function</a>
             <a href="../">Law of Total Expectation</a>
            
        </li>
    </ul>



    <ul class="list-unstyled CTAs">
        <li>
            Ⓒ Chris Piech, Stanford University
            <!-- <a href="https://compedu.stanford.edu/codeinplace/v1/#/course" class="download">Back to Code in Place</a> -->
        </li>
    </ul>
</nav>
        <!-- Page Content  -->
        <div id="content">

<button type="button" id="sidebarCollapse" class="mobile-only btn btn-dark">
    <i class="fas fa-align-left"></i>
    <span></span>
</button>            
            <div class="container-fluid">
                <div class="row d-flex justify-content-center">
                    <div class="col handout" >
              
                         
<center><h1>Probability of <b><i>or</i></b></h1></center>
<hr/>

<p>The equation for calculating the probability of either event E <b><i>or</i></b> event F happening, written  $\p(E \or F)$ or equivalently as $\p(E ∪ F)$, is deeply analogous
to counting the size of two sets. As in counting, the equation that you can use  depends on whether or not the events are "mutually exclusive". If events are mutually exclusive, it is very straightforward to calculate the probability of either event happening. Otherwise, you need the more complex "inclusion exclusion" formula.</p>

<h2>Mutually Exclusive Events</h2>

<p>Two, events $E$ and $F$ are considered to be mutually exclusive (in set notation $E ∩ F = ∅$) if there are no outcomes that are
in both events (recall that an event is a set of outcomes which is a subset of the sample
space). In English, mutually exclusive means that two events can't both happen.</p>

<p>Mutual exclusion can be visualized. Consider the following visual sample space where each outcome is a
hexagon. The set of all the fifty hexagons is the full sample space:</p>

<p>
<center>
	<img style="max-width: min(400px,100%)" src="../../img/probOr/mutuallyExclusive.png"></img><br/>
	<i>Example of two events, $E$ and $F$, which are mutually exclusive.</i>
</center>
</p>

<p>Both events $E$ and $F$ are subsets of the same sample space. Visually, we can note that
the two sets do not overlap. They are mutually exclusive: there is no outcome that is in both sets.</p>

<p>
	<div class="bordered">
		<b><i>Definition</i></b>: Probability of <b><i>or</i></b> for mututally exclusive events<br/>
		<p>If two events, $E$ and $F$ are mutually exclusive then the probability of $E$ <b><i>or</i></b> $F$ occuring is:
			$$
			\p(E \or F) = \p(E) + \p(F)
			$$
		</p>
		<p>This property applies regardless of how you calculate the probability of $E$ or $F$.
Moreover, the idea extends to more than two events. Lets say you have $n$ events $E_1, E_2, \dots E_n$ where each
event is mutually exclusive of one another (in other words, no outcome is in more than one event). Then:
$$
			\p(E_1 \or E_2 \or \dots \or E_n) = \p(E_1) + \p(E_2) + \dots + \p(E_n) = \sum_{i=1}^n \p(E_i)
			$$</p>
	</div>
	</p>

	<p>You may have noticed that this is one of the axioms of probability. Though it might seem intuitive, it is one of three rules that we accept without proof.</p>

	<p>
		<div class="alert alert-warning"><b>Caution</b>: Mutual exclusion only makes it easier to calculate the probability of $E \or F$ not other ways of combining events, such as $E \and F$. </div>
	</p>

	<p>At this point we know how to compute the probability of the "or" of events if and only if they have the mutual exclusion property. What if they don't?</p>

<h2>Non-mutually Exclusive Events</h2>

<p>Unfortunately, not all events are mutually exclusive. If you want to calculate $\p(E \or F)$ where the events $E$
and F are <b><i>not</i></b> mutually exclusive you can <b><i>not</i></b> simply add the probabilities. As a simple sanity check, consider the event $E$: getting heads on a coin flip, where $\p(E) = 0.5$. Now imagine the sample space $S$, getting either a heads or a tails on a coin flip. These events are not mutually exclusive (the outcome heads is in both). If you incorrectly assumed they were mutually exclusive and tried to calculate $\p(E \or S)$ you would get this buggy derivation:

<div class="alert alert-warning">
	<p><b>Buggy derivation</b>: Incorrectly assuming mutual exclusion</p>
	<p>Calculate the probability of $E$, getting a heads on a coin flip, or $S$.
	$$
	\begin{align}
	\p(E \or S) &= \p(E) + \p(S) && \text{Incorrectly assumes mutual exclusion} \\
	&= 0.5 + 1 && \text{substitute the probabilities of $E$ and $S$} \\
	&= 1.5 && \text{uh oh!}
	\end{align}
	$$
	<p>No probability should be greater than one! We incorrectly assumed mutual exclusion.</p>
</div>

<p>What went wrong? If two events are not mutually exclusive, simply adding their probabilities double counts the probability of any outcome which is in both events. There is a formula for calculating <b><i>or</i></b> of two non-mutually exclusive events: it is called the "inclusion exclusion" principle.
</p>

<p>
<div class="bordered">
<b><i>Definition</i></b>: Inclusion Exclusion principle<br/>
<p>For any two events: E, F:
$$
\p(E \or F) = \p(E) + \p(F) − \p(E \and F)
$$</p>
<p>This formula does have a version for more than two events, but it gets rather complex. For three events, $E$, $F$, and $G$ the formula is:
	$$
	\begin{align}
	\p(E \or F \or G) =& \text{ }\p(E) + \p(F) + \p(G) \\
& −\p(E \and F) − \p(E \and G)−P(F \and G) \\
& +\p(E \and F \and G)
	\end{align}
	$$
</p>
<p>For $n$ events, $E_1, E_2, \dots E_n$: build a running sum. Add all the probabilities of the events on their own. Then subtract all pairs of events. Then add all subsets of 3 events. Then subtract all subset of 4 events. Continue this process, up until $n$, adding the subsets if the size of subsets is odd, else subtracting them. The alternating addition and subtraction is where the name inclusion exclusion comes from. This is a complex process and you should first check if there is an easier way to calculate your probability.
</div>
</p>

<p>Note that the inclusion exclusion principle also applies for mutually exclusive events. If two events are mutually exclusive $\p(E \and F) = 0$ since its not possible for both $E$ and $F$ to occur. As such the formula $\p(E) + \p(F) - \p(E \and F)$ reduces to $\p(E) + \p(F)$.</p>

<p>
	The formulas for calculating the <b><i>or</i></b> of events that are not mutually exclusive often requires calculating the probability of the <b><i>and</i></b> of events. Learn more in the next section:
	</p>
               

               


<script type="text/javascript">
    $(document).ready(function () {
        $("#sidebar").mCustomScrollbar({
            theme: "minimal",
            mouseWheel: {preventDefault: true},
            scrollInertia: 60
        });

        $('#sidebarCollapse').on('click', function () {
            $('#sidebar, #content').toggleClass('active');
            $('.collapse.in').toggleClass('in');
            $('a[aria-expanded=true]').attr('aria-expanded', 'false');
        });
    });
</script>                
                    </div>
                </div>
            </div>
        </div>
    </div>

</body>


</html>